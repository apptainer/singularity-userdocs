%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}


\title{Singularity Container Documentation}
\date{Aug 20, 2018}
\release{2.6.0}
\author{User Docs}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{logo.png}\par}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Quick Start}
\label{\detokenize{quick_start:quick-start}}\label{\detokenize{quick_start:id1}}\label{\detokenize{quick_start::doc}}\phantomsection\label{\detokenize{quick_start:sec-quickstart}}
This guide is intended for running Singularity on a computer where you
have root (administrative) privileges. If you are learning about
Singularity on a system where you lack root privileges, you can still
complete the steps that do not require the sudo command. If you need to
request an installation on your shared resource, check out our requesting an installation help page for information to send to your
system administrator.


\section{Installation}
\label{\detokenize{quick_start:installation}}\label{\detokenize{quick_start:id2}}
There are many ways to {\hyperref[\detokenize{quick_start:installation}]{\sphinxcrossref{\DUrole{std,std-ref}{install Singularity}}}} but this quick start guide will only cover one.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git clone https://github.com/singularityware/singularity.git

cd singularity

./autogen.sh

./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local

make

sudo make install
\end{sphinxVerbatim}

Singularity must be installed as root to function properly.


\section{Overview of the Singularity Interface}
\label{\detokenize{quick_start:overview-of-the-singularity-interface}}
Singularity’s {\hyperref[\detokenize{appendix:command-usage}]{\sphinxcrossref{\DUrole{std,std-ref}{command line interface}}}} allows you to build and interact with containers
transparently. You can run programs inside a container as if they were
running on your host system. You can easily redirect IO, use pipes,
pass arguments, and access files, sockets, and ports on the host
system from within a container.
The \sphinxcode{\sphinxupquote{-{-}help}} option gives an overview of Singularity options and subcommands as
follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}help

USAGE: singularity [global options...] \PYGZlt{}command\PYGZgt{} [command options...] ...


GLOBAL OPTIONS:

    \PYGZhy{}d\textbar{}\PYGZhy{}\PYGZhy{}debug    Print debugging information

    \PYGZhy{}h\textbar{}\PYGZhy{}\PYGZhy{}help     Display usage summary

    \PYGZhy{}s\textbar{}\PYGZhy{}\PYGZhy{}silent   Only print errors

    \PYGZhy{}q\textbar{}\PYGZhy{}\PYGZhy{}quiet    Suppress all normal output

       \PYGZhy{}\PYGZhy{}version  Show application version

    \PYGZhy{}v\textbar{}\PYGZhy{}\PYGZhy{}verbose  Increase verbosity +1

    \PYGZhy{}x\textbar{}\PYGZhy{}\PYGZhy{}sh\PYGZhy{}debug Print shell wrapper debugging information


GENERAL COMMANDS:

    help       Show additional help for a command or container

    selftest   Run some self tests for singularity install


CONTAINER USAGE COMMANDS:

    exec       Execute a command within container

    run        Launch a runscript within container

    shell      Run a Bourne shell within container

    test       Launch a testscript within container


CONTAINER MANAGEMENT COMMANDS:

    apps       List available apps within a container

    bootstrap  *Deprecated* use build instead

    build      Build a new Singularity container

    check      Perform container lint checks

    inspect    Display a container\PYGZsq{}s metadata

    mount      Mount a Singularity container image

    pull       Pull a Singularity/Docker container to \PYGZdl{}PWD


COMMAND GROUPS:

    image      Container image command group

    instance   Persistent instance command group


CONTAINER USAGE OPTIONS:

    see singularity help \PYGZlt{}command\PYGZgt{}

For any additional help or support visit the Singularity

website: https://github.com/singularityware/singularity
\end{sphinxVerbatim}

For any additional help or support visit the Singularity website:
\sphinxurl{https://www.sylabs.io/contact/}
Singularity uses positional syntax. Global options follow the \sphinxcode{\sphinxupquote{singularity}}
invocation and affect the way that Singularity runs any command. Then
commands are passed followed by their options.
For example, to pass the \sphinxcode{\sphinxupquote{-{-}debug}} option to the main \sphinxcode{\sphinxupquote{singularity}} command and run
Singularity with debugging messages on:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}debug run shub://GodloveD/lolcow
\end{sphinxVerbatim}

And to pass the \sphinxcode{\sphinxupquote{-{-}containall}} option to the \sphinxcode{\sphinxupquote{run}} command and run a Singularity image in an
isolated manner:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}containall shub://GodloveD/lolcow
\end{sphinxVerbatim}

To learn more about a specific Singularity command, type one of the
following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity help \PYGZlt{}command\PYGZgt{}

\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}help \PYGZlt{}command\PYGZgt{}

\PYGZdl{} singularity \PYGZhy{}h \PYGZlt{}command\PYGZgt{}

\PYGZdl{} singularity \PYGZlt{}command\PYGZgt{} \PYGZhy{}\PYGZhy{}help

\PYGZdl{} singularity \PYGZlt{}command\PYGZgt{} \PYGZhy{}h
\end{sphinxVerbatim}

Users can also {\hyperref[\detokenize{container_recipes:help}]{\sphinxcrossref{\DUrole{std,std-ref}{write help docs specific to a container}}}} or for an internal module called an \sphinxcode{\sphinxupquote{app}}. If those help
docs exist for a particular container, you can view them like so.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity help container.simg            \PYGZsh{} See the container\PYGZsq{}s help, if provided

\PYGZdl{} singularity help \PYGZhy{}\PYGZhy{}app foo container.simg  \PYGZsh{} See the help for foo, if provided
\end{sphinxVerbatim}


\section{Download pre-built images}
\label{\detokenize{quick_start:download-pre-built-images}}
You can use the {\hyperref[\detokenize{appendix:pull-command}]{\sphinxcrossref{\DUrole{std,std-ref}{pull}}}} and {\hyperref[\detokenize{appendix:build-command}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}} commands to download pre-built images from an
external resource like \sphinxhref{https://singularity-hub.org/}{Singularity Hub} or \sphinxhref{https://hub.docker.com/}{Docker Hub}. When called
on a native Singularity images like those provided on Singularity Hub, \sphinxcode{\sphinxupquote{pull}}
simply downloads the image file to your system.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity pull shub://vsoch/hello\PYGZhy{}world   \PYGZsh{} pull with default name, vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.simg

\PYGZdl{} singularity pull \PYGZhy{}\PYGZhy{}name hello.simg shub://vsoch/hello\PYGZhy{}world   \PYGZsh{} pull with custom name
\end{sphinxVerbatim}

Singularity images can also be pulled and named by an associated
GitHub commit or content hash.
You can also use \sphinxcode{\sphinxupquote{pull}} with the \sphinxcode{\sphinxupquote{docker://}} uri to reference Docker images served from a
registry. In this case \sphinxcode{\sphinxupquote{pull}} does not just download an image file. Docker
images are stored in layers, so \sphinxcode{\sphinxupquote{pull}} must also combine those layers into a
usable Singularity file.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity pull docker://godlovedc/lolcow  \PYGZsh{} with default name

\PYGZdl{} singularity pull \PYGZhy{}\PYGZhy{}name funny.simg docker://godlovedc/lolcow \PYGZsh{} with custom name
\end{sphinxVerbatim}

Pulling Docker images reduces reproducibility. If you were to pull a
Docker image today and then wait six months and pull again, you are
not guaranteed to get the same image. If any of the source layers has
changed the image will be altered. If reproducibility is a priority
for you, try building your images from Singularity Hub.
You can also use the \sphinxcode{\sphinxupquote{build}} command to download pre-built images from an
external resource. When using \sphinxcode{\sphinxupquote{build}} you must specify a name for your
container like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build hello\PYGZhy{}world.simg shub://vsoch/hello\PYGZhy{}world

\PYGZdl{} singularity build lolcow.simg docker://godlovedc/lolcow
\end{sphinxVerbatim}

Unlike \sphinxcode{\sphinxupquote{pull}}, \sphinxcode{\sphinxupquote{build}} will convert your image to the latest Singularity image format
after downloading it.

\sphinxcode{\sphinxupquote{build}} is like a “Swiss Army knife” for container creation. In addition to
downloading images, you can use \sphinxcode{\sphinxupquote{build}} to create images from other images or
from scratch using a \sphinxtitleref{recipe file \textless{}container-recipes\textgreater{}}. You can also use \sphinxcode{\sphinxupquote{build}} to convert an image between the
3 major container formats supported by Singularity. We discuss those
image formats below in the {\hyperref[\detokenize{quick_start:build-images-from-scratch}]{\sphinxcrossref{\DUrole{std,std-ref}{Build images from scratch}}}} section.


\section{Interact with images}
\label{\detokenize{quick_start:interact-with-images}}
Once you have an image, you can interact with it in several ways. For
these examples we will use a \sphinxcode{\sphinxupquote{hello-world.simg}} image that can be downloaded from
Singularity Hub like so.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity pull \PYGZhy{}\PYGZhy{}name hello\PYGZhy{}world.simg shub://vsoch/hello\PYGZhy{}world
\end{sphinxVerbatim}


\subsection{Shell}
\label{\detokenize{quick_start:shell}}
The {\hyperref[\detokenize{appendix:shell-command}]{\sphinxcrossref{\DUrole{std,std-ref}{shell}}}} command allows you to spawn a new shell within your container and
interact with it as though it were a small virtual machine.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell hello\PYGZhy{}world.simg

Singularity: Invoking an interactive shell within container...


\PYGZsh{} I am the same user inside as outside!

Singularity hello\PYGZhy{}world.simg:\PYGZti{}/Desktop\PYGZgt{} whoami

vanessa


Singularity hello\PYGZhy{}world.simg:\PYGZti{}/Desktop\PYGZgt{} id

uid=1000(vanessa) gid=1000(vanessa) groups=1000(vanessa),4(adm),24,27,30(tape),46,113,128,999(input)
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{shell}} also works with the \sphinxcode{\sphinxupquote{shub://}} and \sphinxcode{\sphinxupquote{docker://}} URIs. This creates an ephemeral container that
disappears when the shell is exited.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell shub://vsoch/hello\PYGZhy{}world
\end{sphinxVerbatim}


\subsection{Executing Commands}
\label{\detokenize{quick_start:executing-commands}}
The \DUrole{xref,std,std-ref}{exec} command allows you to execute a custom command within a container by
specifying the image file. For instance, to list the root (/) of our
hello-world.simg image, we could do the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec hello\PYGZhy{}world.simg ls /

anaconda\PYGZhy{}post.log  etc   lib64       mnt   root  singularity  tmp

bin        home  lost+found  opt   run   srv          usr

dev        lib   media       proc  sbin  sys          var
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{exec}} also works with the \sphinxcode{\sphinxupquote{shub://}} and \sphinxcode{\sphinxupquote{docker://}} URIs. This creates an ephemeral container that
executes a command and disappears.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec shub://singularityhub/ubuntu cat /etc/os\PYGZhy{}release
\end{sphinxVerbatim}


\subsection{Running a container}
\label{\detokenize{quick_start:running-a-container}}
Singularity containers contain {\hyperref[\detokenize{container_recipes:runscript}]{\sphinxcrossref{\DUrole{std,std-ref}{runscripts}}}}. These are user defined scripts that
define the actions a container should perform when someone runs it. The
runscript can be triggered with the run command, or simply by calling
the container as though it were an executable.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run hello\PYGZhy{}world.simg

\PYGZdl{} ./hello\PYGZhy{}world.simg
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{run}} also works with \sphinxcode{\sphinxupquote{shub://}} and \sphinxcode{\sphinxupquote{docker://}} URIs. This creates an ephemeral container that runs
and then disappears.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run shub://GodloveD/lolcow
\end{sphinxVerbatim}


\subsection{Working with Files}
\label{\detokenize{quick_start:working-with-files}}
Files on the host are reachable from within the container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} echo \PYGZdq{}Hello World\PYGZdq{} \PYGZgt{} \PYGZdl{}HOME/hello\PYGZhy{}kitty.txt

\PYGZdl{} singularity exec vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.simg cat \PYGZdl{}HOME/hello\PYGZhy{}kitty.txt

Hello World
\end{sphinxVerbatim}

This example works because \sphinxcode{\sphinxupquote{hello-kitty.txt}} exists in the user’s home directory. By
default singularity bind mounts \sphinxcode{\sphinxupquote{/home/\$USER}}, \sphinxcode{\sphinxupquote{/tmp}}, and \sphinxcode{\sphinxupquote{\$PWD}} into your container at
runtime.
You can specify additional directories to bind mount into your
container with the {\hyperref[\detokenize{bind_paths_and_mounts:bind-paths-and-mounts}]{\sphinxcrossref{\DUrole{std,std-ref}{- -bind}}}} option. In this example, the \sphinxcode{\sphinxupquote{data}} directory on the host
system is bind mounted to the \sphinxcode{\sphinxupquote{/mnt}} directory inside the container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} echo \PYGZdq{}I am your father\PYGZdq{} \PYGZgt{}/data/vader.sez

\PYGZdl{} \PYGZti{}/sing\PYGZhy{}dev/bin/singularity exec \PYGZhy{}\PYGZhy{}bind /data:/mnt hello\PYGZhy{}world.simg cat /mnt/vader.sez

I am your father
\end{sphinxVerbatim}


\section{Build images from scratch}
\label{\detokenize{quick_start:build-images-from-scratch}}\label{\detokenize{quick_start:id3}}\phantomsection\label{\detokenize{quick_start:sec-buildimagesfromscratch}}
As of Singularity v2.4 by default \sphinxcode{\sphinxupquote{build}} produces immutable images in the
squashfs file format. This ensures reproducible and verifiable images.
However, during testing and debugging you may want an image format
that is writable. This way you can \sphinxcode{\sphinxupquote{shell}} into the image and install software
and dependencies until you are satisfied that your container will
fulfill your needs. For these scenarios, Singularity supports two
other image formats: a \sphinxcode{\sphinxupquote{sandbox}} format (which is really just a chroot
directory), and a \sphinxcode{\sphinxupquote{writable}} format (the ext3 file system that was used in
Singularity versions less than 2.4).

For more details about the different build options and best practices,
read about the {\hyperref[\detokenize{singularity_flow:singularity-flow}]{\sphinxcrossref{\DUrole{std,std-ref}{singularity flow}}}}.


\subsection{Sandbox Directory}
\label{\detokenize{quick_start:sandbox-directory}}
To build into a \sphinxcode{\sphinxupquote{sandbox}} (container in a directory) use the \sphinxcode{\sphinxupquote{build -{-}sandbox}} command and option:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}sandbox ubuntu/ docker://ubuntu
\end{sphinxVerbatim}

This command creates a directory called \sphinxcode{\sphinxupquote{ubuntu/}} with an entire Ubuntu
Operating System and some Singularity metadata in your current working
directory.
You can use commands like \sphinxcode{\sphinxupquote{shell}}, \sphinxcode{\sphinxupquote{exec}} , and \sphinxcode{\sphinxupquote{run}} with this directory just as you
would with a Singularity image. You can also write files to this
directory from within a Singularity session (provided you have the
permissions to do so). These files will be ephemeral and will
disappear when the container is finished executing. However if you use
the \sphinxcode{\sphinxupquote{-{-}writable}} option the changes will be saved into your directory so that you
can use them the next time you use your container.


\subsection{Writable Image}
\label{\detokenize{quick_start:writable-image}}
If you prefer to have a writable image file, you can \sphinxcode{\sphinxupquote{build}} a container with
the \sphinxcode{\sphinxupquote{-{-}writable}} option.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}writable ubuntu.img docker://ubuntu
\end{sphinxVerbatim}

This produces an image that is writable with an ext3 file system.
Unlike the sandbox, it is a single image file. Also by convention this
file name has an “.img” extension instead of “.simg” .
When you want to alter your image, you can use commands like \sphinxcode{\sphinxupquote{shell}}, \sphinxcode{\sphinxupquote{exec}}, \sphinxcode{\sphinxupquote{run}},
with the \sphinxcode{\sphinxupquote{-{-}writable}} option. Because of permission issues it may be necessary to
execute the container as root to modify it.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell \PYGZhy{}\PYGZhy{}writable ubuntu.img
\end{sphinxVerbatim}


\subsection{Converting images from one format to another}
\label{\detokenize{quick_start:converting-images-from-one-format-to-another}}
\begin{DUlineblock}{0em}
\item[] The \sphinxcode{\sphinxupquote{build}} command allows you to build a container from an existing
container. This means that you can use it to convert a container from
one format to another. For instance, if you have already created a
sandbox (directory) and want to convert it to the default immutable
image format (squashfs) you can do so:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build new\PYGZhy{}squashfs sandbox
\end{sphinxVerbatim}

Doing so may break reproducibility if you have altered your sandbox
outside of the context of a recipe file, so you are advised to
exercise care.
You can use \sphinxcode{\sphinxupquote{build}} to convert containers to and from \sphinxcode{\sphinxupquote{writable}}, \sphinxcode{\sphinxupquote{sandbox}}, and default
(squashfs) file formats via any of the six possible combinations.


\subsection{Singularity Recipes}
\label{\detokenize{quick_start:singularity-recipes}}
For a reproducible, production-quality container, we recommend that
you build a container with the default (squashfs) file format using a
Singularity recipe file. This also makes it easy to add files,
environment variables, and install custom software, and still start
from your base of choice (e.g., Singularity Hub).
A recipe file has a header and a body. The header determines what kind
of base container to begin with, and the body is further divided into
sections (called scriptlets) that do things like install software,
setup the environment, and copy files into the container from the host
system.
Here is an example of a recipe file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: shub

From: singularityhub/ubuntu


\PYGZpc{}runscript

    exec echo \PYGZdq{}The runscript is the containers default runtime command!\PYGZdq{}


\PYGZpc{}files

   /home/vanessa/Desktop/hello\PYGZhy{}kitty.txt        \PYGZsh{} copied to root of container

   /home/vanessa/Desktop/party\PYGZus{}dinosaur.gif     /opt/the\PYGZhy{}party\PYGZhy{}dino.gif \PYGZsh{}


\PYGZpc{}environment

    VARIABLE=MEATBALLVALUE

    export VARIABLE


\PYGZpc{}labels

   AUTHOR vsochat@stanford.edu


\PYGZpc{}post

    apt\PYGZhy{}get update \PYGZam{}\PYGZam{} apt\PYGZhy{}get \PYGZhy{}y install python3 git wget

    mkdir /data

    echo \PYGZdq{}The post section is where you can install, and configure your container.\PYGZdq{}
\end{sphinxVerbatim}

To build a container from this definition file (assuming it is a file
named Singularity), you would call build like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build ubuntu.simg Singularity
\end{sphinxVerbatim}

In this example, the header tells singularity to use a base Ubuntu
image from Singularity Hub. The \sphinxcode{\sphinxupquote{\%runscript}} section defines actions for the
container to take when it is executed (in this case a simple message).
The \sphinxcode{\sphinxupquote{\%files}} section copies some files into the container from the host system
at build time. The \sphinxcode{\sphinxupquote{\%environment}} section defines some environment variables that
will be available to the container at runtime. The \sphinxcode{\sphinxupquote{\%labels}} section allows for
custom metadata to be added to the container. And finally the \sphinxcode{\sphinxupquote{\%post}} section
executes within the container at build time after the base OS has been
installed. The \sphinxcode{\sphinxupquote{\%post}} section is therefore the place to perform installations
of custom apps.
This is a very small example of the things that you can do with a {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{recipe file}}}} . In
addition to building a container from Singularity Hub, you can start
with base images from Docker Hub, use images directly from official
repositories such as Ubuntu, Debian, Centos, Arch, and BusyBox, use an
existing container on your host system as a base, or even take a
snapshot of the host system itself and use that as a base image.
If you want to build Singularity images without having singularity
installed in a build environment, you can build images using
\sphinxhref{https://github.com/singularityhub/singularityhub.github.io/wiki}{Singularity Hub}
instead. If you want a more detailed rundown and examples for
different build options, see our {\hyperref[\detokenize{singularity_flow:singularity-flow}]{\sphinxcrossref{\DUrole{std,std-ref}{singularity flow}}}} page.


\chapter{Introduction}
\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction::doc}}
This document will introduce you to Singularity, and the links in the
bar to the left will give you more detail on using the software. If you
want to get a quick rundown, see our {\hyperref[\detokenize{quick_start:quick-start}]{\sphinxcrossref{\DUrole{std,std-ref}{quickstart}}}}. If you want to
understand which commands are best fit for your usecase, see our build
flow page. There is also a separate Singularity Administration Guide
that targets system administrators, so if you are a service provider, or
an interested user, it is encouraged that you read that document as
well.


\section{Welcome to Singularity!}
\label{\detokenize{introduction:welcome-to-singularity}}
Singularity is a container solution created by necessity for
scientific and application driven workloads.
Over the past decade and a half, virtualization has gone from an
engineering toy to a global infrastructure necessity and the evolution
of enabling technologies has flourished. Most recently, we have seen
the introduction of the latest spin on virtualization… “containers”.
People tend to view containers in light of their virtual machine
ancestry and these preconceptions influence feature sets and expected
use cases. This is both a good and a bad thing…
For industry and enterprise-centric container technologies this is a
good thing. Web enabled cloud requirements are very much in alignment
with the feature set of virtual machines, and thus the preceding
container technologies. But the idea of containers as miniature
virtual machines is a bad thing for the scientific world and
specifically the high performance computation (HPC) community. While
there are many overlapping requirements in these two fields, they
differ in ways that make a shared implementation generally
incompatible. Some groups have leveraged custom-built resources that
can operate on a lower performance scale, but proper integration is
difficult and perhaps impossible with today’s technology.
Many scientists could benefit greatly by using container technology,
but they need a feature set that differs somewhat from that available
with current container technology. This necessity drives the creation
of Singularity and articulated its four primary functions:


\subsection{Mobility of Compute}
\label{\detokenize{introduction:mobility-of-compute}}
Mobility of compute is defined as the ability to define, create and
maintain a workflow and be confident that the workflow can be executed
on different hosts, operating systems (as long as it is Linux) and
service providers. Being able to contain the entire software stack,
from data files to library stack, and portably move it from system to
system is true mobility.
Singularity achieves this by utilizing a distributable image format
that contains the entire container and stack into a single file. This
file can be copied, shared, archived, and standard UNIX file
permissions also apply. Additionally containers are portable (even
across different C library versions and implementations) which makes
sharing and copying an image as easy as \sphinxcode{\sphinxupquote{cp}} or \sphinxcode{\sphinxupquote{scp}} or \sphinxcode{\sphinxupquote{ftp}}.


\subsection{Reproducibility}
\label{\detokenize{introduction:reproducibility}}
As mentioned above, Singularity containers utilize a single file which is the complete
representation of all the files within the container. The same
features which facilitate mobility also facilitate reproducibility.
Once a contained workflow has been defined, the container image can be
snapshotted, archived, and locked down such that it can be used later
and you can be confident that the code within the container has not
changed.


\subsection{User Freedom}
\label{\detokenize{introduction:user-freedom}}
System integrators, administrators, and engineers spend a lot
of effort maintaining their systems, and tend to take a cautious
approach. As a result, it is common to see hosts installed with
production, mission critical operating systems that are “old” and have
few installed packages. Users may find software or libraries that are
too old or incompatible with the software they must run, or the
environment may just lack the software stack they need due to
complexities with building, specific software knowledge,
incompatibilities or conflicts with other installed programs.

Singularity can give the user the freedom they need to install the
applications, versions, and dependencies for their workflows without
impacting the system in any way. Users can define their own working
environment and literally copy that environment image (single file) to
a shared resource, and run their workflow inside that image.


\subsection{Support on Existing Traditional HPC}
\label{\detokenize{introduction:support-on-existing-traditional-hpc}}
Replicating a virtual machine cloud like environment within an
existing HPC resource is not a reasonable goal for many
administrators. There are a lots of container systems available which
are designed for enterprise, as a replacement for virtual machines,
are cloud focused, or require unstable or unavailable kernel features.
Singularity supports existing and traditional HPC resources as easily
as installing a single package onto the host operating system. Custom
configurations may be achieved via a single configuration file, and
the defaults are tuned to be generally applicable for shared
environments.
Singularity can run on host Linux distributions from RHEL6 (RHEL5 for
versions lower than 2.2) and similar vintages, and the contained
images have been tested as far back as Linux 2.2 (approximately 14
years old). Singularity natively supports InfiniBand, Lustre, and
works seamlessly with all resource managers (e.g. SLURM, Torque, SGE,
etc.) because it works like running any other command on the system.
It also has built-in support for MPI and for containers that need to
leverage GPU resources.


\section{A High Level View of Singularity}
\label{\detokenize{introduction:a-high-level-view-of-singularity}}

\subsection{Security and privilege escalation}
\label{\detokenize{introduction:security-and-privilege-escalation}}\label{\detokenize{introduction:security-and-priviledge-escalation}}
A user inside a Singularity container
is the same user as outside the container
This is one of Singularities defining characteristics. It allows a
user (that may already have shell access to a particular host) to
simply run a command inside of a container image as themselves. Here
is a scenario to help articulate this:

\%SERVER and \%CLUSTER are large expensive systems with resources far
exceeding those of my personal workstation. But because they are
shared systems, no users have root access. The environments are
tightly controlled and managed by a staff of system administrators.
To keep these systems secure, only the system administrators are
granted root access and they control the state of the operating
systems and installed applications. If a user is able to escalate to
root (even within a container) on \%SERVER or \%CLUSTER, they can do
bad things to the network, cause denial of service to the host (as
well as other hosts on the same network), and may have unrestricted
access to file systems reachable by the container.

To mitigate security concerns like this, Singularity limits one’s
ability to escalate permission inside a container. For example, if I
do not have root access on the target system, I should not be able to
escalate my privileges within the container to root either. This is
semi-antagonistic to Singularity’s 3rd tenant; allowing the users to
have freedom of their own environments. Because if a user has the
freedom to create and manipulate their own container environment,
surely they know how to escalate their privileges to root within that
container. Possible means could be setting the root user’s password,
or enabling themselves to have sudo access. For these reasons,
Singularity prevents user context escalation within the container, and
thus makes it possible to run user supplied containers on shared
infrastructures.
This mitigation dictates the {\hyperref[\detokenize{singularity_flow:singularity-flow}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity workflow}}}}. If a user needs to be root
in order to make changes to their containers, then they need to have
an endpoint (a local workstation, laptop, or server) where they have
root access. Considering almost everybody at least has a laptop, this
is not an unreasonable or unmanageable mitigation, but it must be
defined and articulated.


\subsection{The Singularity container image}
\label{\detokenize{introduction:the-singularity-container-image}}
Singularity makes use of a container image
file, which physically contains the container. This file is a physical
representation of the container environment itself. If you obtain an
interactive shell within a Singularity container, you are literally
running within that file.
This simplifies management of files to the element of least surprise,
basic file permission. If you either own a container image, or have
read access to that container image, you can start a shell inside that
image. If you wish to disable or limit access to a shared image, you
simply change the permission ACLs to that file.
There are numerous benefits for using a single file image for the
entire container:
\begin{itemize}
\item {} 
Copying or branching an entire container is as simple as \sphinxcode{\sphinxupquote{cp}}

\item {} 
Permission/access to the container is managed via standard file
system permissions

\item {} 
Large scale performance (especially over parallel file systems) is
very efficient

\item {} 
No caching of the image contents to run (especially nice on clusters)

\item {} 
Containers are compressed and consume very little disk space

\item {} 
Images can serve as stand-alone programs, and can be executed like
any other program on the host

\end{itemize}


\subsubsection{\sphinxstyleemphasis{Copying, sharing, branching, and distributing your image}}
\label{\detokenize{introduction:copying-sharing-branching-and-distributing-your-image}}
A primary goal of Singularity is mobility. The single file image
format makes mobility easy. Because Singularity images are single
files, they are easily copied and managed. You can copy the image to
create a branch, share the image and distribute the image as easily as
copying any other file you control!

If you want an automated solution for building and hosting your image,
you can use our container registry \sphinxhref{https://singularity-hub.org/}{Singularity Hub}. Singularity Hub
can automatically build {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity recipe files}}}} from
a GitHub repository each time that you push. It provides a simple cloud
solution for storing and sharing your image. If you want to host your own
Registry, then you should check out \sphinxhref{https://www.github.com/singularityhub/sregistry}{Singularity Registry}.
If you have ideas or suggestions for how Singularity can better support
reproducible science, please \sphinxhref{https://www.sylabs.io/contact/}{reach out!}.


\subsubsection{\sphinxstyleemphasis{Supported container formats}}
\label{\detokenize{introduction:supported-container-formats}}\begin{itemize}
\item {} 
\sphinxstylestrong{squashfs}: the default container format is a compressed read-only
file system that is widely used for things like live CDs/USBs and
cell phone OS’s

\item {} 
\sphinxstylestrong{ext3}: (also called \sphinxcode{\sphinxupquote{writable}}) a writable image file containing an ext3
file system that was the default container format prior to
Singularity version 2.4

\item {} 
\sphinxstylestrong{directory}: (also called \sphinxcode{\sphinxupquote{sandbox}}) standard Unix directory containing a
root container image

\item {} 
\sphinxstylestrong{tar.gz}: zlib compressed tar archive

\item {} 
\sphinxstylestrong{tar.bz2}: bzip2 compressed tar archive

\item {} 
\sphinxstylestrong{tar}: uncompressed tar archive

\end{itemize}


\subsubsection{\sphinxstyleemphasis{Supported URIs}}
\label{\detokenize{introduction:supported-uris}}
Singularity also supports several different mechanisms for obtaining the
images using a standard URI format.
\begin{itemize}
\item {} 
\sphinxstylestrong{shub://} Singularity Hub is our own registry for Singularity
containers. If you want to publish a container, or give easy access
to others from their command line, or enable automatic builds, you
should build it on \sphinxhref{https://singularity-hub.org/}{Singularity Hub}.

\item {} 
\sphinxstylestrong{docker://} Singularity can pull Docker images from a Docker
registry, and will run them non-persistently (e.g. changes are not
persisted as they can not be saved upstream). Note that pulling a
Docker image implies assembling layers at runtime, and two subsequent
pulls are not guaranteed to produce an identical image.

\item {} 
\sphinxstylestrong{instance://} A Singularity container running as service, called an
instance, can be referenced with this URI.

\end{itemize}


\subsection{Name-spaces and isolation}
\label{\detokenize{introduction:name-spaces-and-isolation}}
When asked, “What namespaces does Singularity virtualize?”, the most
appropriate response from a Singularity use case is “As few as
possible!”. This is because the goals of Singularity are mobility,
reproducibility and freedom, not full isolation (as you would expect
from industry driven container technologies). Singularity only
separates the needed namespaces in order to satisfy our primary goals.

Coupling incomplete isolation with the fact that a user inside a
container is the same user outside the container, allows Singularity
to blur the lines between a container and the underlying host system.
Using Singularity feels like running in a parallel universe, where
there are two timelines. In one timeline, the system administrators
installed their operating system of choice. But on an alternate
timeline, we bribed the system administrators and they installed our
favorite operating system and apps, and gave us full control but
configured the rest of the system identically. And Singularity gives
us the power to pick between these two timelines.
In other words, Singularity allows you to virtually swap out the
underlying operating system for one that you’ve defined without
affecting anything else on the system and still having all of the host
resources available to us.
It’s like ssh’ing into another identical host running a different
operating system. One moment you are on Centos-6 and the next minute
you are on the latest version of Ubuntu that has Tensorflow installed,
or Debian with the latest OpenFoam, or a custom workflow that you
installed. But you are still the same user with the same files running
the same PIDs.
Additionally, the selection of name-space virtualization can be
dynamic or conditional. For example, the PID namespace is not
separated from the host by default, but if you want to separate it,
you can with a command line (or environment variable) setting. You can
also decide you want to contain a process so it can not reach out to
the host file system if you don’t know if you trust the image. But by
default, you are allowed to interface with all of the resources,
devices and network inside the container as you are outside the
container.


\subsection{Compatibility with standard work-flows, pipes and IO}
\label{\detokenize{introduction:compatibility-with-standard-work-flows-pipes-and-io}}
Singularity abstracts the complications of running an application in
an environment that differs from the host. For example, applications
or scripts within a Singularity container can easily be part of a
pipeline that is being executed on the host. Singularity containers
can also be executed from a batch script or other program (e.g. an HPC
system’s resource manager) natively.
Some usage examples of Singularity can be seen as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec dummy.img xterm  \PYGZsh{} run xterm from within the container

\PYGZdl{} singularity exec dummy.img python script.py  \PYGZsh{} run a script on the host system using container\PYGZsq{}s python

\PYGZdl{} singularity exec dummy.img python \PYGZlt{} /path/to/python/script.py  \PYGZsh{} do the same via redirection

\PYGZdl{} cat /path/to/python/script.py \textbar{} singularity exec dummy.img python  \PYGZsh{} do the same via a pipe
\end{sphinxVerbatim}

You can even run MPI executables within the container as simply as:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mpirun \PYGZhy{}np X singularity exec /path/to/container.img /usr/bin/mpi\PYGZus{}program\PYGZus{}inside\PYGZus{}container (mpi program args)
\end{sphinxVerbatim}


\subsection{The Singularity Process Flow}
\label{\detokenize{introduction:the-singularity-process-flow}}
When executing container commands, the Singularity process flow can be
generalized as follows:
\begin{enumerate}
\item {} 
Singularity application is invoked

\item {} 
Global options are parsed and activated

\item {} 
The Singularity command (subcommand) process is activated

\item {} 
Subcommand options are parsed

\item {} 
The appropriate sanity checks are made

\item {} 
Environment variables are set

\item {} 
The Singularity Execution binary is called (\sphinxcode{\sphinxupquote{sexec}})

\item {} 
Sexec determines if it is running privileged and calls the \sphinxcode{\sphinxupquote{SUID}} code if
necessary

\item {} 
Namespaces are created depending on configuration and process
requirements

\item {} 
The Singularity image is checked, parsed, and mounted in the
namespace

\item {} 
Bind mount points are setup so that files on the host are visible in
the \sphinxcode{\sphinxupquote{CLONE\_NEWNS}} container

\item {} 
The namespace \sphinxcode{\sphinxupquote{CLONE\_FS}} is used to virtualize a new root file system

\item {} 
Singularity calls \sphinxcode{\sphinxupquote{execvp()}} and Singularity process itself is replaced by the
process inside the container

\item {} 
When the process inside the container exits, all namespaces collapse
with that process, leaving a clean system

\end{enumerate}

All of the above steps take approximately 15-25 thousandths of a second
to run, which is fast enough to seem instantaneous.


\section{The Singularity Usage Workflow}
\label{\detokenize{introduction:the-singularity-usage-workflow}}
The security model of Singularity (as described above, \DUrole{xref,std,std-ref}{“A user inside a Singularity container is the same user as outside the container”}) defines the
Singularity workflow. There are generally two groups of actions you
must implement on a container; management (building your container)
and usage.

In many circumstances building containers require root administrative
privileges just like these actions would require on any system,
container, or virtual machine. This means that a user must have access
to a system on which they have root privileges. This could be a
server, workstation, a laptop, virtual machine, or even a cloud
instance. If you are using OS X or Windows on your laptop, it is
recommended to setup Vagrant, and run Singularity from there (there
are recipes for this which can be found at Once you have Singularity
installed on your endpoint of choice, this is where you will do the
bulk of your container development. This workflow can be described
visually as follows:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{flow}.png}
\caption{Singularity workflow}\label{\detokenize{introduction:id3}}\end{figure}

On the left side, you have your build environment: a laptop,
workstation, or a server that you control. Here you will (optionally):
\begin{enumerate}
\item {} 
develop and test containers using \sphinxcode{\sphinxupquote{-{-}sandbox}} (build into a writable directory)
or \sphinxcode{\sphinxupquote{-{-}writable}} (build into a writable ext3 image)

\item {} 
build your production containers with a squashfs filesystem.

\end{enumerate}

Once you have the container with the necessary applications, libraries
and data inside it can be easily shared to other hosts and executed
without requiring root access. A production container should be an
immutable object, so if you need to make changes to your container you
should go back to your build system with root privileges, rebuild the
container with the necessary changes, and then re-upload the container
to the production system where you wish to run it.


\subsection{Singularity Commands}
\label{\detokenize{introduction:singularity-commands}}
How do the commands work?

Here is where to look for more information:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:build-command}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}} : Build a container on your user endpoint or build environment

\item {} 
{\hyperref[\detokenize{appendix:exec-command}]{\sphinxcrossref{\DUrole{std,std-ref}{exec}}}} : Execute a command to your container

\item {} 
{\hyperref[\detokenize{appendix:inspect-command}]{\sphinxcrossref{\DUrole{std,std-ref}{inspect}}}} : See labels, run and test scripts, and environment variables

\item {} 
{\hyperref[\detokenize{appendix:pull-command}]{\sphinxcrossref{\DUrole{std,std-ref}{pull}}}} : pull an image from Docker or Singularity Hub

\item {} 
{\hyperref[\detokenize{appendix:run-command}]{\sphinxcrossref{\DUrole{std,std-ref}{run}}}} : Run your image as an executable

\item {} 
{\hyperref[\detokenize{appendix:shell-command}]{\sphinxcrossref{\DUrole{std,std-ref}{shell}}}} : Shell into your image

\end{itemize}

\sphinxstylestrong{Image Commands}
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:image-import}]{\sphinxcrossref{\DUrole{std,std-ref}{image.import}}}} : import layers or other file content to your image

\item {} 
{\hyperref[\detokenize{appendix:image-export}]{\sphinxcrossref{\DUrole{std,std-ref}{image.export}}}} : export the contents of the image to tar or stream

\item {} 
{\hyperref[\detokenize{appendix:image-create}]{\sphinxcrossref{\DUrole{std,std-ref}{image.create}}}} : create a new image, using the old ext3 filesystem

\item {} 
{\hyperref[\detokenize{appendix:image-expand}]{\sphinxcrossref{\DUrole{std,std-ref}{image.expand}}}} : increase the size of your image (old ext3)

\end{itemize}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{Instance Commands}
\item[] Instances were added in 2.4. This list is brief, and likely to expand
with further development.
\end{DUlineblock}
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:instance-command-group}]{\sphinxcrossref{\DUrole{std,std-ref}{instances}}}} : Start, stop, and list container instances

\end{itemize}

\sphinxstylestrong{Deprecated Commands} The following commands are deprecated in 2.4 and
will be removed in future releases.
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:bootstrap}]{\sphinxcrossref{\DUrole{std,std-ref}{bootstrap}}}} : Bootstrap a container recipe

\end{itemize}


\section{Support}
\label{\detokenize{introduction:support}}
Have a question, or need further information? \sphinxhref{https://www.sylabs.io/contact/}{Reach out to us}.


\section{About}
\label{\detokenize{introduction:about}}

\subsection{Overview}
\label{\detokenize{introduction:overview}}
While there are many container solutions being used commonly in this day and age, what makes Singularity different stems from it’s primary design features and thus it’s architecture:
\begin{enumerate}
\item {} 
\sphinxstylestrong{Reproducible software stacks:} These must be easily verifiable via checksum or cryptographic signature in such a manner that does not change formats (e.g. splatting a tarball out to disk). By default Singularity uses a container image file which can be checksummed, signed, and thus easily verified and/or validated.

\item {} 
\sphinxstylestrong{Mobility of compute:} Singularity must be able to transfer (and store) containers in a manner that works with standard data mobility tools (rsync, scp, gridftp, http, NFS, etc..) and maintain software and data controls compliancy (e.g. HIPAA, nuclear, export, classified, etc..)

\item {} 
\sphinxstylestrong{Compatibility with complicated architectures:} The runtime must be immediately compatible with existing HPC, scientific, compute farm and even enterprise architectures any of which maybe running legacy kernel versions (including RHEL6 vintage systems) which do not support advanced namespace features (e.g. the user namespace)

\item {} 
\sphinxstylestrong{Security model:} Unlike many other container systems designed to support trusted users running trusted containers we must support the opposite model of untrusted users running untrusted containers. This changes the security paradigm considerably and increases the breadth of use cases we can support.

\end{enumerate}


\subsection{Background}
\label{\detokenize{introduction:background}}
A Unix operating system is broken into two primary components, the kernel space, and the user space. The Kernel supports the user space by interfacing with the hardware, providing core system features and creating the software compatibility layers for the user space. The user space on the other hand is the environment that most people are most familiar with interfacing with. It is where applications, libraries and system services run.

Containers are shifting the emphasis away from the runtime environment by commoditizing the user space into swappable components. This means that the entire user space portion of a Linux operating system, including programs, custom configurations, and environment can be interchanged at runtime. Singularity emphasis and simplifies the distribution vector of containers to be that of a single, verifiable file.

Software developers can now build their stack onto whatever operating system base fits their needs best, and create distributable runtime encapsulated environments and the users never have to worry about dependencies, requirements, or anything else from the user space.

Singularity provides the functionality of a virtual machine, without the heavyweight implementation and performance costs of emulation and redundancy!


\subsubsection{The Singularity Solution}
\label{\detokenize{introduction:the-singularity-solution}}
Singularity has two primary roles:
\begin{enumerate}
\item {} 
\sphinxstylestrong{Container Image Generator:} Singularity supports building different container image formats from scratch using your choice of Linux distribution bases or leveraging other container formats (e.g. Docker Hub). Container formats supported are the default compressed immutable (read only) image files, writable raw file system based images, and sandboxes (chroot style directories).

\item {} 
\sphinxstylestrong{Container Runtime:} The Singularity runtime is designed to leverage the above mentioned container formats and support the concept of untrusted users running untrusted containers. This counters the typical container runtime practice of trusted users running trusted containers and as a result of that, Singularity utilizes a very different security paradigm. This is a required feature for implementation within any multi-user environment.

\end{enumerate}

The Singularity containers themselves are purpose built and can include a simple application and library stack or a complicated work flow that can interface with the hosts resources directly or run isolated from the host and other containers. You can even launch a contained work flow by executing the image file directly! For example, assuming that \sphinxcode{\sphinxupquote{\textasciitilde{}/bin}} is in the user’s path as it is normally by default:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mkdir \PYGZti{}/bin

\PYGZdl{} singularity build \PYGZti{}/bin/python\PYGZhy{}latest docker://python:latest

Docker image path: index.docker.io/library/python:latest

Cache folder set to /home/gmk/.singularity/docker

Importing: base Singularity environment

Importing: /home/gmk/.singularity/docker/sha256:aa18ad1a0d334d80981104c599fa8cef9264552a265b1197af11274beba767cf.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:15a33158a1367c7c4103c89ae66e8f4fdec4ada6a39d4648cf254b32296d6668.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:f67323742a64d3540e24632f6d77dfb02e72301c00d1e9a3c28e0ef15478fff9.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:c4b45e832c38de44fbab83d5fcf9cbf66d069a51e6462d89ccc050051f25926d.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:b71152c33fd217d4408c0e7a2f308e66c0be1a58f4af9069be66b8e97f7534d2.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:c3eac66dc8f6ae3983a7f37e3da84a8acb828faf909be2d6649e9d7c9caffc28.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:494ffdf1660cdec946ae13d6b726debbcec4c393a7eecfabe97caf3961f62c36.tar.gz

Importing: /home/gmk/.singularity/docker/sha256:f5ec737c23de3b1ae2b1ce3dce1fd20e0cb246e4c73584dcd4f9d2f50063324e.tar.gz

Importing: /home/gmk/.singularity/metadata/sha256:5dd22488ce22f06bed1042cc03d3efa5a7d68f2a7b3dcad559df4520154ef9c2.tar.gz

WARNING: Building container as an unprivileged user. If you run this container as root

WARNING: it may be missing some functionality.

Building Singularity image...

Cleaning up...

Singularity container built: /home/gmk/bin/python\PYGZhy{}latest


\PYGZdl{} which python\PYGZhy{}latest

/home/gmk/bin/python\PYGZhy{}latest


\PYGZdl{} python\PYGZhy{}latest \PYGZhy{}\PYGZhy{}version

Python 3.6.3


\PYGZdl{} singularity exec \PYGZti{}/bin/python\PYGZhy{}latest cat /etc/debian\PYGZus{}version

8.9

\PYGZdl{} singularity shell \PYGZti{}/bin/python\PYGZhy{}latest

Singularity: Invoking an interactive shell within container...


Singularity python\PYGZhy{}latest:\PYGZti{}\PYGZgt{}
\end{sphinxVerbatim}

Additionally, Singularity blocks privilege escalation within the container and you are always yourself within a container! If you want to be root inside the container, you first must be root outside the container. This simple usage paradigm mitigates many of the security concerns that exists with containers on multi-user shared resources. You can directly call programs inside the container from outside the container fully incorporating pipes, standard IO, file system access, X11, and MPI. Singularity images can be seamlessly incorporated into your environment.


\subsubsection{Portability and Reproducibility}
\label{\detokenize{introduction:portability-and-reproducibility}}
Singularity containers are designed to be as portable as possible, spanning many flavors and vintages of Linux. The only known limitation is binary compatibility of the kernel and container. Singularity has been ported to distributions going as far back as RHEL 5 (and compatibles) and works on all currently living versions of RHEL, Debian, Arch, Alpine, Gentoo and Slackware. Within the container, there are almost no limitations aside from basic binary compatibility.

Inside the container, it is also possible to have a very old version of Linux supported. The oldest known version of Linux tested was a Red Hat Linux 8 container, that was converted by hand from a physical computer’s hard drive as the 15 year old hardware was failing. The container was transferred to a new installation of Centos7, and is still running in production!

Each Singularity image includes all of the application’s necessary run-time libraries and can even include the required data and files for a particular application to run. This encapsulation of the entire user-space environment facilitates not only portability but also reproducibility.


\subsection{Features}
\label{\detokenize{introduction:features}}

\subsubsection{Encapsulation of the environment}
\label{\detokenize{introduction:encapsulation-of-the-environment}}
Mobility of Compute is the encapsulation of an environment in such a manner to make it portable between systems. This operating system environment can contain the necessary applications for a particular work-flow, development tools, and/or raw data. Once this environment has been developed it can be easily copied and run from any other Linux system.

This allows users to BYOE (Bring Their Own Environment) and work within that environment anywhere that Singularity is installed. From a service provider’s perspective we can easily allow users the flexibility of “cloud”-like environments enabling custom requirements and workflows.

Additionally there is always a misalignment between development and production environments. The service provider can only offer a stable, secure tuned production environment which in many times will not keep up with the fast paced requirements of developers. With Singularity, you can control your own development environment and simply copy them to the production resources.


\subsubsection{Containers are image based}
\label{\detokenize{introduction:containers-are-image-based}}
Using image files have several key benefits:

First, this image serves as a vector for mobility while retaining permissions of the files within the image. For example, a user may own the image file so they can copy the image to and from system to system. But, files within an image must be owned by the appropriate user. For example, ‘/etc/passwd’ and ‘/’ must be owned by root to achieve appropriate access permission. These permissions are maintained within a user owned image.

There is never a need to build, rebuild, or cache an image! All IO happens on an as needed basis. The overhead in starting a container is in the thousandths of a second because there is never a need to pull, build or cache anything!

On HPC systems a single image file optimizes the benefits of a shared parallel file system! There is a single metadata lookup for the image itself, and the subsequent IO is all directed to the storage servers themselves. Compare this to the massive amount of metadata IO that would be required if the container’s root file system was in a directory structure. It is not uncommon for large Python jobs to DDOS (distributed denial of service) a parallel meta-data server for minutes! The Singularity image mitigates this considerably.


\subsubsection{No user contextual changes or root escalation allowed}
\label{\detokenize{introduction:no-user-contextual-changes-or-root-escalation-allowed}}
When Singularity is executed, the calling user is maintained within the container. For example, if user ‘gmk’ starts a Singularity container, the same user ‘gmk’ will end up within the container. If ‘root’ starts the container, ‘root’ will be the user inside the container.

Singularity also limits a user’s ability to escalate privileges within the container. Even if the user works in their own environment where they configured ‘sudo’ or even removed root’s password, they will not be able to ‘sudo’ or ‘su’ to root. If you want to be root inside the container, you must first be root outside the container.

Because of this model, it becomes possible to blur the line of access between what is contained and what is on the host as Singularity does not grant the user any more access than they already have. It also enables the implementation on shared/multi-tenant resources.


\subsubsection{No root owned daemon processes}
\label{\detokenize{introduction:no-root-owned-daemon-processes}}
Singularity does not utilize a daemon process to manage the containers. While daemon processes do facilitate certain types of workflows and privilege escalation, it breaks all resource controlled environments. This is because a user’s job becomes a subprocess of the daemon (rather than the user’s shell) and the daemon process is outside of the reach of a resource manager or batch scheduler.

Additionally, securing a root owned daemon process which is designed to manipulate the host’s environment becomes tricky. In currently implemented models, it is possible to grant permissions to users to control the daemon, or not. There is no sense of ACL’s or access of what users can and can not do.

While there are some other container implementations that do not leverage a daemon, they lack other features necessary to be considered as reasonable user facing solution without having root access. For example, there has been a standing unimplemented patch to RunC (already daemon-less) which allows for root-less usage (no root). But, user contexts are not maintained, and it will only work with chroot directories (instead of an image) where files must be owned and manipulated by the root user!


\subsection{Use Cases}
\label{\detokenize{introduction:use-cases}}

\subsubsection{BYOE: Bring Your Own Environment}
\label{\detokenize{introduction:byoe-bring-your-own-environment}}
Engineering work-flows for research computing can be a complicated and iterative process, and even more so on a shared and somewhat inflexible production environment. Singularity solves this problem by making the environment flexible.

Additionally, it is common (especially in education) for schools to provide a standardized pre-configured Linux distribution to the students which includes all of the necessary tools, programs, and configurations so they can immediately follow along.


\subsubsection{Reproducible science}
\label{\detokenize{introduction:reproducible-science}}
Singularity containers can be built to include all of the programs, libraries, data and scripts such that an entire demonstration can be contained and either archived or distributed for others to replicate no matter what version of Linux they are presently running.

Commercially supported code requiring a particular environment Some commercial applications are only certified to run on particular versions of Linux. If that application was installed into a Singularity container running the version of Linux that it is certified for, that container could run on any Linux host. The application environment, libraries, and certified stack would all continue to run exactly as it is intended.

Additionally, Singularity blurs the line between container and host such that your home directory (and other directories) exist within the container. Applications within the container have full and direct access to all files you own thus you can easily incorporate the contained commercial application into your work and process flow on the host.


\subsubsection{Static environments (software appliances)}
\label{\detokenize{introduction:static-environments-software-appliances}}
Fund once, update never software development model. While this is not ideal, it is a common scenario for research funding. A certain amount of money is granted for initial development, and once that has been done the interns, grad students, post-docs, or developers are reassigned to other projects. This leaves the software stack un-maintained, and even rebuilds for updated compilers or Linux distributions can not be done without unfunded effort.


\subsubsection{Legacy code on old operating systems}
\label{\detokenize{introduction:legacy-code-on-old-operating-systems}}
Similar to the above example, while this is less than ideal it is a fact of the research ecosystem. As an example, I know of one Linux distribution which has been end of life for 15 years which is still in production due to the software stack which is custom built for this environment. Singularity has no problem running that operating system and application stack on a current operating system and hardware.


\subsubsection{Complicated software stacks that are very host specific}
\label{\detokenize{introduction:complicated-software-stacks-that-are-very-host-specific}}
There are various software packages which are so complicated that it takes much effort in order to port, update and qualify to new operating systems or compilers. The atmospheric and weather applications are a good example of this. Porting them to a contained operating system will prolong the use-fullness of the development effort considerably.


\subsubsection{Complicated work-flows that require custom installation and/or data}
\label{\detokenize{introduction:complicated-work-flows-that-require-custom-installation-and-or-data}}
Consolidating a work-flow into a Singularity container simplifies distribution and replication of scientific results. Making containers available along with published work enables other scientists to build upon (and verify) previous scientific work.


\subsection{License}
\label{\detokenize{introduction:license}}
Singularity is released under a standard 3 clause BSD license.
Please see our \sphinxhref{https://github.com/singularityware/singularity/blob/master/LICENSE.md}{LICENSE} file for more details).


\subsection{Getting started}
\label{\detokenize{introduction:getting-started}}
Jump in and {\hyperref[\detokenize{quick_start:quick-start}]{\sphinxcrossref{\DUrole{std,std-ref}{get started}}}}, or find ways to get \sphinxhref{https://www.sylabs.io/contact/}{help}.
\begin{itemize}
\item {} 
Project lead: \sphinxhref{https://gmkurtzer.github.io/}{Gregory M. Kurtzer}

\end{itemize}


\chapter{Installation}
\label{\detokenize{installation:installation}}\label{\detokenize{installation::doc}}\phantomsection\label{\detokenize{installation:sec-installation}}
This document will guide you through the process of installing
Singularity from source with the version and location of your choice.


\section{Before you begin}
\label{\detokenize{installation:before-you-begin}}
If you have an earlier version of Singularity installed, you should
remove it before executing the installation commands.

These instructions will build Singularity from source on your system.
So you will need to have some development tools installed. If you run
into missing dependencies, try installing them like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo apt\PYGZhy{}get update \PYGZam{}\PYGZam{} \PYGZbs{}

    sudo apt\PYGZhy{}get install \PYGZbs{}

    python \PYGZbs{}

    dh\PYGZhy{}autoreconf \PYGZbs{}

    build\PYGZhy{}essential \PYGZbs{}

    libarchive\PYGZhy{}dev
\end{sphinxVerbatim}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo yum update \PYGZam{}\PYGZam{} \PYGZbs{}

    sudo yum groupinstall \PYGZsq{}Development Tools\PYGZsq{} \PYGZam{}\PYGZam{} \PYGZbs{}

    sudo yum install libarchive\PYGZhy{}devel
\end{sphinxVerbatim}


\section{Install from a tag}
\label{\detokenize{installation:install-from-a-tag}}
The following commands will install a tagged version of the \sphinxhref{https://github.com/singularityware/singularity}{GitHub
repo} to \sphinxcode{\sphinxupquote{/usr/local}}.
This will work for pre 3.0 tags.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} git clone https://github.com/singularityware/singularity.git

\PYGZdl{} cd singularity

\PYGZdl{} git fetch \PYGZhy{}\PYGZhy{}all

\PYGZdl{} git tag \PYGZhy{}l

\PYGZdl{} git checkout [TAG]

\PYGZdl{} ./autogen.sh

\PYGZdl{} ./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local \PYGZhy{}\PYGZhy{}sysconfdir=/etc

\PYGZdl{} make

\PYGZdl{} sudo make install
\end{sphinxVerbatim}

If you omit the \sphinxcode{\sphinxupquote{-{-}sysconfdir}} option , the configuration file will be installed in \sphinxcode{\sphinxupquote{/usr/local/etc}}.
If you omit the \sphinxcode{\sphinxupquote{-{-}prefix}} option, Singularity will be installed in the \sphinxcode{\sphinxupquote{/usr/local}} directory
hierarchy by default. And if you specify a custom directory with the \sphinxcode{\sphinxupquote{-{-}prefix}}
option, all of Singularity’s binaries and the configuration file will be installed within that directory.
This last option can be useful if you want to install multiple versions of Singularity, install
Singularity on a shared system, or if you want to remove Singularity
easily after installing it.


\section{Install a specific release}
\label{\detokenize{installation:install-a-specific-release}}
The following commands will install a specific release from \sphinxhref{https://github.com/singularityware/singularity/releases}{GitHub
releases} page to \sphinxcode{\sphinxupquote{/usr/local}}.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} VER=2.5.1

\PYGZdl{} wget https://github.com/singularityware/singularity/releases/download/\PYGZdl{}VER/singularity\PYGZhy{}\PYGZdl{}VER.tar.gz

\PYGZdl{} tar xvf singularity\PYGZhy{}\PYGZdl{}VER.tar.gz

\PYGZdl{} cd singularity\PYGZhy{}\PYGZdl{}VER

\PYGZdl{} ./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local \PYGZhy{}\PYGZhy{}sysconfdir=/etc

\PYGZdl{} make

\PYGZdl{} sudo make install
\end{sphinxVerbatim}


\section{Install the development branch}
\label{\detokenize{installation:install-the-development-branch}}
Primary development it now being done in the master branch. As of now (2018-08-16),
this is the development for Singularity 3.0.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} git clone https://github.com/singularityware/singularity.git

\PYGZdl{} cd singularity

[ Read INSTALL.md \PYGZhy{}\PYGZhy{} Some major changes from pre\PYGZhy{}3.0 ]

\PYGZdl{} ./mconfig

\PYGZdl{} cd builddir

\PYGZdl{} make

\PYGZdl{} sudo make install
\end{sphinxVerbatim}


\section{Remove an old version}
\label{\detokenize{installation:remove-an-old-version}}
Let’s say that we installed Singularity to \sphinxcode{\sphinxupquote{/usr/local}}. To remove it completely,
you need to hit all of the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo rm \PYGZhy{}rf /usr/local/libexec/singularity

\PYGZdl{} sudo rm \PYGZhy{}rf /usr/local/etc/singularity

\PYGZdl{} sudo rm \PYGZhy{}rf /usr/local/include/singularity

\PYGZdl{} sudo rm \PYGZhy{}rf /usr/local/lib/singularity

\PYGZdl{} sudo rm \PYGZhy{}rf /usr/local/var/lib/singularity/

\PYGZdl{} sudo rm /usr/local/bin/singularity

\PYGZdl{} sudo rm /usr/local/bin/run\PYGZhy{}singularity

\PYGZdl{} sudo rm /usr/local/etc/bash\PYGZus{}completion.d/singularity

\PYGZdl{} sudo rm /usr/local/man/man1/singularity.1
\end{sphinxVerbatim}

If you modified the system configuration directory, remove the \sphinxcode{\sphinxupquote{singularity.conf}} file
there as well.
If you installed Singularity in a custom directory, you need only
remove that directory to uninstall Singularity. For instance if you
installed singularity with the \sphinxcode{\sphinxupquote{-{-}prefix=/some/temp/dir}} option argument pair, you can remove
Singularity like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo rm \PYGZhy{}rf /some/temp/dir
\end{sphinxVerbatim}

What should you do next? You can check out the {\hyperref[\detokenize{quick_start:quick-start}]{\sphinxcrossref{\DUrole{std,std-ref}{quickstart}}}} guide, or learn how to
interact with your container via the \DUrole{xref,std,std-ref}{shell} , \DUrole{xref,std,std-ref}{exec} , or \DUrole{xref,std,std-ref}{run} commands. Or click \sphinxstylestrong{next}
below to continue reading.


\section{Install on Windows}
\label{\detokenize{installation:install-on-windows}}

\subsection{Setup}
\label{\detokenize{installation:setup}}
First, install the following software:
\begin{itemize}
\item {} 
install \sphinxhref{https://git-for-windows.github.io/}{Git for Windows}

\item {} 
install \sphinxhref{https://www.virtualbox.org/wiki/Downloads}{VirtualBox for Windows}

\item {} 
install \sphinxhref{https://www.vagrantup.com/downloads.html}{Vagrant for Windows}

\item {} 
install \sphinxhref{http://vagrantmanager.com/downloads/}{Vagrant Manager for Windows}

\end{itemize}


\subsection{Singularityware Vagrant Box}
\label{\detokenize{installation:singularityware-vagrant-box}}
We are maintaining a set of Vagrant Boxes via \sphinxhref{https://www.vagrantup.com/}{Vagrant Cloud}, one of \sphinxhref{https://www.hashicorp.com/\#open-source-tools}{Hashicorp} many tools that likely you’ve used and haven’t known it. The current stable version of Singularity is available here:
\begin{itemize}
\item {} 
\sphinxhref{https://app.vagrantup.com/singularityware/boxes/singularity-2.4/versions/2.4}{singularityware/singularity-2.4}

\end{itemize}

For other versions of Singularity see \sphinxhref{https://app.vagrantup.com/singularityware}{our Vagrant Cloud repository}

Run GitBash. The default home directory will be C:Usersyour\_username

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
mkdir singularity\PYGZhy{}2.4

cd singularity\PYGZhy{}2.4
\end{sphinxVerbatim}

Note that if you had installed a previous version of the vm (and are using the same folder), you must destroy it first. In our example we create a new folder. To destroy a previous vm:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant destroy
\end{sphinxVerbatim}

Then issue the following commands to bring up the Virtual Machine:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant init singularityware/singularity\PYGZhy{}2.4

vagrant up

vagrant ssh
\end{sphinxVerbatim}

You are then ready to go with Singularity 2.4!

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant@vagrant:\PYGZti{}\PYGZdl{} which singularity

/usr/local/bin/singularity

vagrant@vagrant:\PYGZti{}\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}version

2.4\PYGZhy{}dist


vagrant@vagrant:\PYGZti{}\PYGZdl{} sudo singularity build growl\PYGZhy{}llo\PYGZhy{}world.simg shub://vsoch/hello\PYGZhy{}world

Cache folder set to /root/.singularity/shub

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Building from local image: /root/.singularity/shub/vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.simg

Building Singularity image...

Singularity container built: growl\PYGZhy{}llo\PYGZhy{}world.simg

Cleaning up...

vagrant@vagrant:\PYGZti{}\PYGZdl{} ./growl\PYGZhy{}llo\PYGZhy{}world.simg

RaawwWWWWWRRRR!!
\end{sphinxVerbatim}

Note that when you do \sphinxcode{\sphinxupquote{vagrant up}} you can also select the provider, if you use vagrant for multiple providers. For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant up \PYGZhy{}\PYGZhy{}provider virtualbox
\end{sphinxVerbatim}

although this isn’t entirely necessary if you only have it configured for virtualbox.


\section{Install on Linux}
\label{\detokenize{installation:install-on-linux}}

\subsection{Installation from Source}
\label{\detokenize{installation:installation-from-source}}
You can try the following two options:


\subsubsection{Option 1: Download latest stable release}
\label{\detokenize{installation:option-1-download-latest-stable-release}}
You can always download the latest tarball release from \sphinxhref{https://github.com/singularityware/singularity/releases}{GitHub}

For example, here is how to download version \sphinxcode{\sphinxupquote{2.5.2}} and install:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
VERSION=2.5.2

wget https://github.com/singularityware/singularity/releases/download/\PYGZdl{}VERSION/singularity\PYGZhy{}\PYGZdl{}VERSION.tar.gz

tar xvf singularity\PYGZhy{}\PYGZdl{}VERSION.tar.gz

cd singularity\PYGZhy{}\PYGZdl{}VERSION

./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local

make

sudo make install
\end{sphinxVerbatim}

Note that when you configure, \sphinxcode{\sphinxupquote{squashfs-tools}} is \sphinxstylestrong{not} required, however it is required for full functionality. You will see this message after the configuration:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
mksquashfs from squash\PYGZhy{}tools is required for full functionality
\end{sphinxVerbatim}

If you choose not to install \sphinxcode{\sphinxupquote{squashfs-tools}}, you will hit an error when you try a pull from Docker Hub, for example.


\subsubsection{Option 2: Download the latest development code}
\label{\detokenize{installation:option-2-download-the-latest-development-code}}
To download the most recent development code, you should use Git and do the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git clone https://github.com/singularityware/singularity.git

cd singularity

./autogen.sh

./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local

make

sudo make install
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The ‘make install’ is required to be run as root to get a properly installed Singularity implementation. If you do not run it as root, you will only be able to launch Singularity as root due to permission limitations.
\end{sphinxadmonition}


\subsubsection{Prefix in special characters}
\label{\detokenize{installation:prefix-in-special-characters}}
If you build Singularity with a non-standard \sphinxcode{\sphinxupquote{-{-}prefix}} argument, please be sure to review the \sphinxhref{https://www.sylabs.io/guides/2.5.2/admin-guide/}{admin guide} for details regarding the \sphinxcode{\sphinxupquote{-{-}localstatedir}} variable. This is especially important in environments utilizing shared filesystems.


\subsubsection{Updating}
\label{\detokenize{installation:updating}}
To update your Singularity version, you might want to first delete the executables for the old version:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo rm \PYGZhy{}rf /usr/local/libexec/singularity
\end{sphinxVerbatim}

And then install using one of the methods above.


\subsection{Debian Ubuntu Package}
\label{\detokenize{installation:debian-ubuntu-package}}
Singularity is available on Debian (and Ubuntu) systems starting with Debian stretch and the Ubuntu 16.10 yakkety releases.
The package is called \sphinxcode{\sphinxupquote{singularity-container}}. For recent releases of singularity and backports for older Debian and Ubuntu releases,
we recommend that you use the \sphinxhref{http://neuro.debian.net/pkgs/singularity-container.html}{NeuroDebian repository}.


\subsubsection{Testing first with Docker}
\label{\detokenize{installation:testing-first-with-docker}}
If you want a quick preview of the NeuroDebian mirror, you can do this most easily with the NeuroDebian Docker image (and if you don’t, skip to the next section). Obviously you should have \sphinxhref{https://docs.docker.com/engine/installation/linux/ubuntu/}{Docker installed} before you do this.

First we run the \sphinxcode{\sphinxupquote{neurodebian}} Docker image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} docker run \PYGZhy{}it \PYGZhy{}\PYGZhy{}rm neurodebian
\end{sphinxVerbatim}

Then we update the cache (very quietly), and look at the \sphinxcode{\sphinxupquote{singularity-container}} policy provided:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} apt\PYGZhy{}get update \PYGZhy{}qqq

\PYGZdl{} apt\PYGZhy{}cache policy singularity\PYGZhy{}container

singularity\PYGZhy{}container:

  Installed: (none)

  Candidate: 2.3\PYGZhy{}1\PYGZti{}nd80+1

  Version table:

    2.3\PYGZhy{}1\PYGZti{}nd80+1 0

      500 http://neuro.debian.net/debian/ jessie/main amd64 Packages
\end{sphinxVerbatim}

You can continue working in Docker, or go back to your host and install Singularity.


\subsubsection{Adding the Mirror and installing}
\label{\detokenize{installation:adding-the-mirror-and-installing}}
You should first enable the NeuroDebian repository following instructions on the \sphinxhref{http://neuro.debian.net/}{NeuroDebian} site. This means using the dropdown menus to find the correct mirror for your operating system and location. For example, after selecting Ubuntu 16.04 and selecting a mirror in CA, I am instructed to add these lists:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo wget \PYGZhy{}O\PYGZhy{} http://neuro.debian.net/lists/xenial.us\PYGZhy{}ca.full \textbar{} sudo tee /etc/apt/sources.list.d/neurodebian.sources.list

sudo apt\PYGZhy{}key adv \PYGZhy{}\PYGZhy{}recv\PYGZhy{}keys \PYGZhy{}\PYGZhy{}keyserver hkp://pool.sks\PYGZhy{}keyservers.net:80 0xA5D32F012649A5A9
\end{sphinxVerbatim}

and then update

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo apt\PYGZhy{}get update
\end{sphinxVerbatim}

then singularity can be installed as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo apt\PYGZhy{}get install \PYGZhy{}y singularity\PYGZhy{}container
\end{sphinxVerbatim}

During the above, if you have a previously installed configuration, you might be asked if you want to define a custom configuration/init, or just use the default provided by the package, eg:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Configuration file \PYGZsq{}/etc/singularity/init\PYGZsq{}

  ==\PYGZgt{} File on system created by you or by a script.

  ==\PYGZgt{} File also in package provided by package maintainer.

    What would you like to do about it ?  Your options are:

      Y or I  : install the package maintainer\PYGZsq{}s version

      N or O  : keep your currently\PYGZhy{}installed version

        D     : show the differences between the versions

        Z     : start a shell to examine the situation

The default action is to keep your current version.

*** init (Y/I/N/O/D/Z) [default=N] ? Y


Configuration file \PYGZsq{}/etc/singularity/singularity.conf\PYGZsq{}

  ==\PYGZgt{} File on system created by you or by a script.

  ==\PYGZgt{} File also in package provided by package maintainer.

    What would you like to do about it ?  Your options are:

      Y or I  : install the package maintainer\PYGZsq{}s version

      N or O  : keep your currently\PYGZhy{}installed version

        D     : show the differences between the versions

        Z     : start a shell to examine the situation

The default action is to keep your current version.

*** singularity.conf (Y/I/N/O/D/Z) [default=N] ? Y
\end{sphinxVerbatim}

And for a user, it’s probably well suited to use the defaults. For a cluster admin, we recommend that you read the \sphinxhref{https://www.sylabs.io/guides/2.5.2/admin-guide/}{admin docs} to get a better understanding of the configuration file options available to you. Remember that you can always tweak the files at \sphinxcode{\sphinxupquote{/etc/singularity/singularity.conf}} and \sphinxcode{\sphinxupquote{/etc/singularity/init}} if you want to make changes.

After this install, you should confirm that \sphinxcode{\sphinxupquote{2.3-dist}} is the version installed:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}version

  2.4\PYGZhy{}dist
\end{sphinxVerbatim}

Note that if you don’t add the NeuroDebian lists, the version provided will be old (e.g., 2.2.1). If you need a backport build of the recent release of Singularity on those or older releases of Debian and Ubuntu, you can \sphinxhref{http://neuro.debian.net/pkgs/singularity-container.html}{see all the various builds and other information here}.


\subsection{Build an RPM from source}
\label{\detokenize{installation:build-an-rpm-from-source}}
Like the above, you can build an RPM of Singularity so it can be more easily managed, upgraded and removed. From the base Singularity source directory do the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
./autogen.sh

./configure

make dist

rpmbuild \PYGZhy{}ta singularity\PYGZhy{}*.tar.gz

sudo yum install \PYGZti{}/rpmbuild/RPMS/*/singularity\PYGZhy{}[0\PYGZhy{}9]*.rpm
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
If you want to have the RPM install the files to an alternative location, you should define the environment variable ‘PREFIX’ to suit your needs, and use the following command to build:
\end{sphinxadmonition}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
PREFIX=/opt/singularity

rpmbuild \PYGZhy{}ta \PYGZhy{}\PYGZhy{}define=\PYGZdq{}\PYGZus{}prefix \PYGZdl{}PREFIX\PYGZdq{} \PYGZhy{}\PYGZhy{}define \PYGZdq{}\PYGZus{}sysconfdir \PYGZdl{}PREFIX/etc\PYGZdq{} \PYGZhy{}\PYGZhy{}define \PYGZdq{}\PYGZus{}defaultdocdir \PYGZdl{}PREFIX/share\PYGZdq{} singularity\PYGZhy{}*.tar.gz
\end{sphinxVerbatim}

When using \sphinxcode{\sphinxupquote{autogen.sh}} If you get an error that you have packages missing, for example on Ubuntu 16.04:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
./autogen.sh

+libtoolize \PYGZhy{}c

./autogen.sh: 13: ./autogen.sh: libtoolize: not found

+aclocal

./autogen.sh: 14: ./autogen.sh: aclocal: not found

+autoheader

./autogen.sh: 15: ./autogen.sh: autoheader: not found

+autoconf

./autogen.sh: 16: ./autogen.sh: autoconf: not found

+automake \PYGZhy{}ca \PYGZhy{}Wno\PYGZhy{}portability

./autogen.sh: 17: ./autogen.sh: automake: not found
\end{sphinxVerbatim}

then you need to install dependencies:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo apt\PYGZhy{}get install \PYGZhy{}y build\PYGZhy{}essential libtool autotools\PYGZhy{}dev automake autoconf
\end{sphinxVerbatim}


\subsection{Build an DEB from source}
\label{\detokenize{installation:build-an-deb-from-source}}
To build a deb package for Debian/Ubuntu/LinuxMint invoke the following commands:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} fakeroot dpkg\PYGZhy{}buildpackage \PYGZhy{}b \PYGZhy{}us \PYGZhy{}uc \PYGZsh{} sudo will ask for a password to run the tests

\PYGZdl{} sudo dpkg \PYGZhy{}i ../singularity\PYGZhy{}container\PYGZus{}2.3\PYGZus{}amd64.deb
\end{sphinxVerbatim}

Note that the tests will fail if singularity is not already installed on your system. This is the case when you run this procedure for the first time. In that case run the following sequence:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} echo \PYGZdq{}echo SKIPPING TESTS THEYRE BROKEN\PYGZdq{} \PYGZgt{} ./test.sh

\PYGZdl{} fakeroot dpkg\PYGZhy{}buildpackage \PYGZhy{}nc \PYGZhy{}b \PYGZhy{}us \PYGZhy{}uc \PYGZsh{} this will continue the previous build without an initial \PYGZsq{}make clean\PYGZsq{}
\end{sphinxVerbatim}


\subsection{Install on your Cluster Resource}
\label{\detokenize{installation:install-on-your-cluster-resource}}
In the case that you want Singularity installed on a shared resource, you will need to talk to the administrator of the resource. Toward this goal, we’ve prepared a {\hyperref[\detokenize{installation:installation-request}]{\sphinxcrossref{\DUrole{std,std-ref}{helpful guide}}}} that you can send to him or her. If you have unanswered questions, please \sphinxhref{https://www.sylabs.io/contact/}{reach out}..


\section{Install on Mac}
\label{\detokenize{installation:install-on-mac}}
This recipe demonstrates how to run Singularity on your Mac via Vagrant and Ubuntu. The recipe requires access to \sphinxcode{\sphinxupquote{brew}} which is a package installation subsystem for OS X. This recipe may take anywhere from 5-20 minutes to complete.


\subsection{Setup}
\label{\detokenize{installation:id1}}
First, install brew if you do not have it already.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/usr/bin/ruby \PYGZhy{}e \PYGZdq{}\PYGZdl{}(curl \PYGZhy{}fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\PYGZdq{}
\end{sphinxVerbatim}

Next, install Vagrant and the necessary bits.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
brew cask install virtualbox

brew cask install vagrant

brew cask install vagrant\PYGZhy{}manager
\end{sphinxVerbatim}


\subsection{Option 1: Singularityware Vagrant Box}
\label{\detokenize{installation:option-1-singularityware-vagrant-box}}
We are maintaining a set of Vagrant Boxes via \sphinxhref{https://www.vagrantup.com/}{Vagrant Cloud}, one of \sphinxhref{https://www.hashicorp.com/\#open-source-tools}{Hashicorp} many tools that likely you’ve used and haven’t known it. The current stable version of Singularity is available here:
\begin{itemize}
\item {} 
\sphinxhref{https://app.vagrantup.com/singularityware/boxes/singularity-2.4/versions/2.4}{singularityware/singularity-2.4}

\end{itemize}

For other versions of Singularity see \sphinxhref{https://app.vagrantup.com/singularityware}{our Vagrant Cloud repository}.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
mkdir singularity\PYGZhy{}vm

cd singularity\PYGZhy{}vm
\end{sphinxVerbatim}

Note that if you have installed a previous version of the vm, you can either destroy it first, or create a new directory.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant destroy
\end{sphinxVerbatim}

Then issue the following commands to bring up the Virtual Machine:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant init singularityware/singularity\PYGZhy{}2.4

vagrant up

vagrant ssh
\end{sphinxVerbatim}

You are then ready to go with Singularity 2.4!

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant@vagrant:\PYGZti{}\PYGZdl{} which singularity

/usr/local/bin/singularity

vagrant@vagrant:\PYGZti{}\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}version

2.4\PYGZhy{}dist


vagrant@vagrant:\PYGZti{}\PYGZdl{} sudo singularity build growl\PYGZhy{}llo\PYGZhy{}world.simg shub://vsoch/hello\PYGZhy{}world

Cache folder set to /root/.singularity/shub

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Building from local image: /root/.singularity/shub/vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.simg

Building Singularity image...

Singularity container built: growl\PYGZhy{}llo\PYGZhy{}world.simg

Cleaning up...

vagrant@vagrant:\PYGZti{}\PYGZdl{} ./growl\PYGZhy{}llo\PYGZhy{}world.simg

RaawwWWWWWRRRR!!
\end{sphinxVerbatim}

Note that when you do \sphinxcode{\sphinxupquote{vagrant up}} you can also select the provider, if you use vagrant for multiple providers. For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant up \PYGZhy{}\PYGZhy{}provider virtualbox
\end{sphinxVerbatim}

although this isn’t entirely necessary if you only have it configured for virtualbox.


\subsection{Option 2: Vagrant Box from Scratch (more advanced alternative)}
\label{\detokenize{installation:option-2-vagrant-box-from-scratch-more-advanced-alternative}}
If you want to get more familiar with how Vagrant and VirtualBox work, you can instead build your own Vagrant Box from scratch. In this case, we will use the Vagrantfile for \sphinxcode{\sphinxupquote{bento/ubuntu-16.04}}, however you could also try any of the \sphinxhref{https://atlas.hashicorp.com/bento}{other bento boxes} that are equally delicious. As before, you should first make a separate directory for your Vagrantfile, and then init a base image.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
mkdir singularity\PYGZhy{}2.4

cd singularity\PYGZhy{}2.4

vagrant init bento/ubuntu\PYGZhy{}16.04
\end{sphinxVerbatim}

Next, build and start the vagrant hosted VM, and you will install Singularity by sending the entire install script as a command (with the \sphinxcode{\sphinxupquote{-c}} argument). You could just as easily shell into the box first with vagrant ssh, and then run these commands on your own. To each bento, his own.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant up \PYGZhy{}\PYGZhy{}provider virtualbox


\PYGZsh{} Run the necessary commands within the VM to install Singularity

vagrant ssh \PYGZhy{}c /bin/sh \PYGZlt{}\PYGZlt{}EOF

    sudo apt\PYGZhy{}get update

    sudo apt\PYGZhy{}get \PYGZhy{}y install build\PYGZhy{}essential curl git sudo man vim autoconf libtool

    git clone https://github.com/singularityware/singularity.git

    cd singularity

    ./autogen.sh

    ./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local

    make

    sudo make install

EOF
\end{sphinxVerbatim}

At this point, Singularity is installed in your Vagrant Ubuntu VM! Now you can use Singularity as you would normally by logging into the VM directly

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
vagrant ssh
\end{sphinxVerbatim}

Remember that the VM is running in the background because we started it via the command \sphinxcode{\sphinxupquote{vagrant up}}. You can shut the VM down using the command \sphinxcode{\sphinxupquote{vagrant halt}} when you no longer need it.


\section{Requesting an Installation}
\label{\detokenize{installation:requesting-an-installation}}

\subsection{How do I ask for Singularity on my local resource?}
\label{\detokenize{installation:how-do-i-ask-for-singularity-on-my-local-resource}}
Installation of a new software is no small feat for a shared cluster resource. Whether you are an administrator reading this, or a user that wants a few talking points and background to share with your administrator, this document is for you. Here we provide you with some background and resources to learn about Singularity. We hope that this information will be useful to you in making the decision to build reproducible containers with Singularity


\subsection{Information Resources}
\label{\detokenize{installation:information-resources}}

\subsubsection{Background}
\label{\detokenize{installation:background}}\begin{itemize}
\item {} 
Frequently Asked Questions is a good first place to start for quick question and answer format.

\item {} 
Singularity Publication: Reviews the history and rationale for development of the Software, along with comparison to other container software available at the time.

\item {} 
Documentation Background is useful to read about use cases, and goals of the Software.

\end{itemize}


\subsubsection{Security}
\label{\detokenize{installation:security}}\begin{itemize}
\item {} 
Administrator Control: The configuration file template is the best source to learn about the configuration options that are under the administrator’s control.

\item {} 
Security Overview discusses common security concerns

\end{itemize}


\subsubsection{Presentations}
\label{\detokenize{installation:presentations}}\begin{itemize}
\item {} 
Contributed Content is a good source of presentations, tutorials, and links.

\end{itemize}


\subsection{Installation Request}
\label{\detokenize{installation:installation-request}}\label{\detokenize{installation:id6}}
Putting all of the above together, a request might look like the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dear Research Computing,


We are interested in having an installation of the Singularity software (https://singularityware.github.io) installed on our cluster. Singularity containers will allow us to build encapsulated environments, meaning that our work is reproducible and we are empowered to choose all dependencies including libraries, operating system, and custom software. Singularity is already installed on over 50 centers internationally (http://singularity.lbl.gov/citation\PYGZhy{}registration) including TACC, NIH,

and several National Labs, Universities, Hospitals. Importantly, it has a vibrant team of developers, scientists, and HPC administrators that invest heavily in the security and development of the software, and are quick to respond to the needs of the community. To help learn more about Singularity, I thought these items might be of interest:


  \PYGZhy{} Security: A discussion of security concerns is discussed at https://www.sylabs.io/guides/2.5.2/user\PYGZhy{}guide/introduction.html\PYGZsh{}security\PYGZhy{}and\PYGZhy{}privilege\PYGZhy{}escalation

  \PYGZhy{} Installation: https://www.sylabs.io/guides/2.5.2/admin\PYGZhy{}guide/


If you have questions about any of the above, you can email the list (singularity@lbl.gov) or join the slack channel (singularity\PYGZhy{}container.slack.com) to get a human response. I can do my best to facilitate this interaction if help is needed. Thank you kindly for considering this request!

Best,

User
\end{sphinxVerbatim}

As is stated in the letter above, you can always \sphinxhref{https://www.sylabs.io/contact/}{reach out} to us for additional questions or support.


\chapter{Build a Container}
\label{\detokenize{build_a_container:build-a-container}}\label{\detokenize{build_a_container:id1}}\label{\detokenize{build_a_container::doc}}\phantomsection\label{\detokenize{build_a_container:sec-buildcontainer}}
\sphinxcode{\sphinxupquote{build}} is the “Swiss army knife” of container creation. You can use it to
download and assemble existing containers from external resources like
\sphinxhref{https://singularity-hub.org/}{Singularity Hub} and \sphinxhref{https://hub.docker.com/}{Docker Hub}. You can use it to convert
containers between the various formats supported by Singularity. And you
can use it in conjunction with a {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity recipe}}}} file to
create a container from scratch and customized it to fit your needs.


\section{Overview}
\label{\detokenize{build_a_container:overview}}
The \sphinxcode{\sphinxupquote{build}} command accepts a target as input and produces a container as output.

The target defines the method that \sphinxcode{\sphinxupquote{build}} uses to create the container. It
can be one of the following:
\begin{itemize}
\item {} 
URI beginning with \sphinxstylestrong{shub://} to build from Singularity Hub

\item {} 
URI beginning with \sphinxstylestrong{docker://} to build from Docker Hub

\item {} 
path to a \sphinxstylestrong{existing container} on your local machine

\item {} 
path to a \sphinxstylestrong{directory} to build from a sandbox

\item {} 
path to an \sphinxstylestrong{archive} in .tar or compressed .tar.gz format

\item {} 
path to a {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity recipe file}}}}

\end{itemize}

In addition \sphinxcode{\sphinxupquote{build}} can produce containers in three different formats. Formats
types can be specified by passing the following options to build.
\begin{itemize}
\item {} 
compressed read-only \sphinxstylestrong{squashfs} file system suitable for production
(default)

\item {} 
writable \sphinxstylestrong{ext3} file system suitable for interactive development ( \sphinxcode{\sphinxupquote{-{-}writable}}
option )

\item {} 
writable \sphinxstylestrong{(ch)root directory} called a sandbox for interactive
development ( \sphinxcode{\sphinxupquote{-{-}sandbox}} option)

\end{itemize}

Because \sphinxcode{\sphinxupquote{build}} can accept an existing container as a target and create a
container in any of these three formats you can convert existing
containers from one format to another.

The following diagram illustrates the targets that can be supplied to \sphinxcode{\sphinxupquote{build}}
as inputs and the containers \sphinxcode{\sphinxupquote{build}} can produce as outputs. Green arrows
represent operations that can be carried out without root privileges
(though the container may not perform properly when run as root). Red
arrows represent operations that must be carried out with root
privileges.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{build_input_output}.png}
\caption{Singularity build process}\label{\detokenize{build_a_container:id2}}\end{figure}


\section{Downloading a existing container from Singularity Hub}
\label{\detokenize{build_a_container:downloading-a-existing-container-from-singularity-hub}}
You can use the build command to download a container from Singularity
Hub.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build lolcow.simg shub://GodloveD/lolcow
\end{sphinxVerbatim}

The first argument (\sphinxcode{\sphinxupquote{lolvow.simg}}) specifies a path and name for your container.
The second argument (\sphinxcode{\sphinxupquote{shub://GodloveD/lolcow}}) gives the Singularity Hub URI from which to download.
But default the container will be converted to a compressed, read-only
squashfs file. If you want your container in a different format use
the \sphinxcode{\sphinxupquote{-{-}writable}} or \sphinxcode{\sphinxupquote{-{-}sandbox}} options.


\section{Downloading a existing container from Docker Hub}
\label{\detokenize{build_a_container:downloading-a-existing-container-from-docker-hub}}
You can use \sphinxcode{\sphinxupquote{build}} to download layers from Docker Hub and assemble them into
Singularity containers.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build lolcow.simg docker://godlovedc/lolcow
\end{sphinxVerbatim}


\section{Creating \sphinxstyleliteralintitle{\sphinxupquote{-{-}writable}} images and \sphinxstyleliteralintitle{\sphinxupquote{-{-}sandbox}} directories}
\label{\detokenize{build_a_container:creating-writable-images-and-sandbox-directories}}

\subsection{\sphinxstyleliteralintitle{\sphinxupquote{-{-}writable}}}
\label{\detokenize{build_a_container:writable}}
If you wanted to create a writable ext3 image similar to those used by
Singularity version \textless{} 2.4, you could do so with the \sphinxcode{\sphinxupquote{-{-}writable}} option. You must
create writable containers as root.

Extending the Singularity Hub example from above:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}writable lolcow.img shub://GodloveD/lolcow
\end{sphinxVerbatim}

The resulting container is writable, but is still mounted as read-only
when executed with commands such as \sphinxcode{\sphinxupquote{run}}, \sphinxcode{\sphinxupquote{exec}}, and \sphinxcode{\sphinxupquote{shell}}. To mount the container
as read-write when using these commands add the \sphinxcode{\sphinxupquote{-{-}writable}} option to them as
well.

To ensure that you have the proper permissions to write to the
container as you like, it is also a good idea to make changes as root.
For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell \PYGZhy{}\PYGZhy{}writable lolcow.img
\end{sphinxVerbatim}


\subsection{\sphinxstyleliteralintitle{\sphinxupquote{-{-}sandbox}}}
\label{\detokenize{build_a_container:sandbox}}
If you wanted to create a container within a writable directory (called
a sandbox) you could do so with the \sphinxcode{\sphinxupquote{-{-}sandbox}} option. It’s possible to create a
sandbox without root privileges, but to ensure proper file permissions
it is recommended to do so as root.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}sandbox lolcow/ shub://GodloveD/lolcow
\end{sphinxVerbatim}

The resulting directory operates just like a container in an image
file. You are permitted to make changes and write files within the
directory, but those changes will not persist when you are finished
using the container. To make your changes persistent, use the \sphinxcode{\sphinxupquote{-{-}writable}} flag
when you invoke your container.
Once again, it’s a good idea to do this as root to ensure you have
permission to access the files and directories that you want to
change.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell \PYGZhy{}\PYGZhy{}writable lolcow/
\end{sphinxVerbatim}


\section{Converting containers from one format to another}
\label{\detokenize{build_a_container:converting-containers-from-one-format-to-another}}
If you already have a container saved locally, you can use it as a
target to build a new container. This allows you convert containers from
one format to another. For example if you had a squashfs container
called \sphinxcode{\sphinxupquote{production.simg}} and wanted to convert it to a writable ext3 container called \sphinxcode{\sphinxupquote{development.img}} you
could:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}writable development.img production.simg
\end{sphinxVerbatim}

Similarly, to convert it to a writable directory (a sandbox):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build \PYGZhy{}\PYGZhy{}sandbox development/ production.simg
\end{sphinxVerbatim}

If you omit any options you can also convert your sandbox back to a
read-only compressed squashfs image suitable for use in a production
environment:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build production2 development/
\end{sphinxVerbatim}

You can convert the three supported container formats using any
combination.

Use care when converting writable ext3 images or sandbox directories
to the default squashfs file format. If changes were made to the
writable container before conversion, there is no record of those
changes in the Singularity recipe file rendering your container
non-reproducible. It is a best practice to build your immutable
production containers directly from a Singularity recipe file instead.


\section{Building containers from Singularity recipe files}
\label{\detokenize{build_a_container:building-containers-from-singularity-recipe-files}}
Of course, Singularity recipe files can be used as the target when
building a container. For detailed information on writing Singularity
recipe files, please see the {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Container Recipes docs}}}}.
Let’s say you already have the following container recipe file called \sphinxcode{\sphinxupquote{Singularity}}
, and you want to use it to build a container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu:16.04


\PYGZpc{}post

    apt\PYGZhy{}get \PYGZhy{}y update

    apt\PYGZhy{}get \PYGZhy{}y install fortune cowsay lolcat


\PYGZpc{}environment

    export LC\PYGZus{}ALL=C

    export PATH=/usr/games:\PYGZdl{}PATH


\PYGZpc{}runscript

    fortune \textbar{} cowsay \textbar{} lolcat
\end{sphinxVerbatim}

You can do so with the following command.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build lolcow.simg Singularity
\end{sphinxVerbatim}

The command requires \sphinxcode{\sphinxupquote{sudo}} just as installing software on your local machine
requires root privileges.


\subsection{\sphinxstyleliteralintitle{\sphinxupquote{-{-}force}}}
\label{\detokenize{build_a_container:force}}
You can build into the same container multiple times (though the
results may be unpredictable and it is generally better to delete your
container and start from scratch).

By default if you build into an existing container, the \sphinxcode{\sphinxupquote{build}} command will
skip the steps involved in adding a new base. You can override this
default with the \sphinxcode{\sphinxupquote{-{-}force}} option requiring that a new base OS is bootstrapped
into the existing container. This behavior does not delete the
existing OS, it just adds the new OS on top of the existing one.

Use care with this option: you may get results that you did not
expect.


\subsection{\sphinxstyleliteralintitle{\sphinxupquote{-{-}section}}}
\label{\detokenize{build_a_container:section}}
If you only want to build a single section of your Singularity recipe
file use the \sphinxcode{\sphinxupquote{-{-}section}} option. For instance, if you have edited the \sphinxcode{\sphinxupquote{\%environment}} section of a
long Singularity recipe and don’t want to completely re-build the
container, you could re-build only the \sphinxcode{\sphinxupquote{\%environment}} section like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}section environment image.simg Singularity
\end{sphinxVerbatim}

Under normal build conditions, the Singularity recipe file is saved into
a container’s meta-data so that there is a record showing how the
container was built. Using the \sphinxcode{\sphinxupquote{-{-}section}} option may render this meta-data useless, so use care if you value reproducibility.


\subsection{\sphinxstyleliteralintitle{\sphinxupquote{-{-}notest}}}
\label{\detokenize{build_a_container:notest}}
If you don’t want to run the \sphinxcode{\sphinxupquote{\%test}} section during the container build, you can
skip it with the \sphinxcode{\sphinxupquote{-{-}notest}} option. For instance, maybe you are building a
container intended to run in a production environment with GPUs. But
perhaps your local build resource does not have GPUs. You want to
include a \sphinxcode{\sphinxupquote{\%test}} section that runs a short validation but you don’t want your
build to exit with an error because it cannot find a GPU on your system.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build GPU.simg \PYGZhy{}\PYGZhy{}notest Singularity
\end{sphinxVerbatim}


\subsection{\sphinxstyleliteralintitle{\sphinxupquote{-{-}checks}}}
\label{\detokenize{build_a_container:checks}}
Checks are a new feature (in 2.4) that offer an easy way for an admin
to define a security (or any other kind of check) to be run on demand
for a Singularity image. They are defined (and run) via different
tags.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
CHECKS OPTIONS:

    \PYGZhy{}c\textbar{}\PYGZhy{}\PYGZhy{}checks    enable checks

    \PYGZhy{}t\textbar{}\PYGZhy{}\PYGZhy{}tag       specify a check tag (not default)

    \PYGZhy{}l\textbar{}\PYGZhy{}\PYGZhy{}low       Specify low threshold (all checks, default)

    \PYGZhy{}m\textbar{}\PYGZhy{}\PYGZhy{}med       Perform medium and high checks

    \PYGZhy{}h\textbar{}\PYGZhy{}\PYGZhy{}high      Perform only checks at level high
\end{sphinxVerbatim}

When you add the \sphinxcode{\sphinxupquote{-{-}checks}} option along with applicable tags to the \sphinxcode{\sphinxupquote{build}} command
Singularity will run the desired checks on your container at build time.
See \sphinxcode{\sphinxupquote{singularity check -{-}help}} for available tags.


\section{More Build topics}
\label{\detokenize{build_a_container:more-build-topics}}\begin{itemize}
\item {} 
If you want to \sphinxstylestrong{customize the cache location} (where Docker layers
are downloaded on your system), specify Docker credentials, or any
custom tweaks to your build environment, see {\hyperref[\detokenize{build_environment:build-environment}]{\sphinxcrossref{\DUrole{std,std-ref}{build environment}}}}.

\item {} 
If you want to make internally \sphinxstylestrong{modular containers}, check out the
getting started guide \sphinxhref{https://sci-f.github.io/tutorials}{here}

\item {} 
If you want to \sphinxstylestrong{build your containers} on Singularity Hub, (because
you don’t have root access on a Linux machine or want to host your
container on the cloud) check out \sphinxhref{https://github.com/singularityhub/singularityhub.github.io/wiki}{this guide}

\end{itemize}


\chapter{Build Environment}
\label{\detokenize{build_environment:build-environment}}\label{\detokenize{build_environment:id1}}\label{\detokenize{build_environment::doc}}\phantomsection\label{\detokenize{build_environment:sec-buildenv}}
It’s commonly the case that you want to customize your build
environment, such as specifying a custom cache directory for layers, or
sending your Docker Credentials to the registry endpoint. Here we will
discuss those things


\section{Cache Folders}
\label{\detokenize{build_environment:cache-folders}}
To make download of layers for build and {\hyperref[\detokenize{appendix:pull-command}]{\sphinxcrossref{\DUrole{std,std-ref}{pull}}}} faster and less redundant, we
use a caching strategy. By default, the Singularity software will create
a set of folders in your \sphinxcode{\sphinxupquote{\$HOME}} directory for docker layers, Singularity Hub
images, and Docker metadata, respectively:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{}HOME/.singularity

\PYGZdl{}HOME/.singularity/docker

\PYGZdl{}HOME/.singularity/shub

\PYGZdl{}HOME/.singularity/metadata
\end{sphinxVerbatim}

Fear not, you have control to customize this behavior! If you don’t want
the cache to be created (and a temporary directory will be used), set \sphinxcode{\sphinxupquote{SINGULARITY\_DISABLE\_CACHE}} to
True/yes, or if you want to move it elsewhere, set \sphinxcode{\sphinxupquote{SINGULARITY\_CACHEDIR}} to the full path
where you want to cache. Remember that when you run commands as sudo
this will use root’s home at \sphinxcode{\sphinxupquote{/root}} and not your user’s home.


\section{Temporary Folders}
\label{\detokenize{build_environment:temporary-folders}}\begin{quote}
\phantomsection\label{\detokenize{build_environment:sec-temporaryfolders}}\end{quote}

Singularity also uses some temporary directories to build the squashfs filesystem,
so this temp space needs to be large enough to hold the entire resulting Singularity image.
By default this happens in \sphinxcode{\sphinxupquote{/tmp}} but can be overridden by setting \sphinxcode{\sphinxupquote{SINGULARITY\_TMPDIR}} to the full
path where you want the squashfs temp files to be stored. Since images
are typically built as root, be sure to set this variable in root’s
environment.

If you are building an image on the fly, for example

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity exec docker://busybox /bin/sh
\end{sphinxVerbatim}

by default a temporary runtime directory is created that looks like \sphinxcode{\sphinxupquote{/tmp/.singularity-runtime.xxxxxxxx}}.

This can be problematic for some \sphinxcode{\sphinxupquote{/tmp}} directories that are hosted at
Jetstream/OpenStack, Azure, and possibly EC2, which are very small. If
you need to change the location of this runtime, then \sphinxstylestrong{export} the
variable \sphinxcode{\sphinxupquote{SINGULARITY\_LOCALCACHEDIR}}.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
SINGULARITY\PYGZus{}LOCALCACHEDIR=/tmp/pancakes

export SINGULARITY\PYGZus{}LOCALCACHEDIR

singularity exec docker://busybox /bin/sh
\end{sphinxVerbatim}

The above runtime folder would be created under \sphinxcode{\sphinxupquote{/tmp/pancakes/.singularity-runtime.xxxxxxxx}}


\section{Pull Folder}
\label{\detokenize{build_environment:pull-folder}}
For details about customizing the output location of {\hyperref[\detokenize{appendix:pull-command}]{\sphinxcrossref{\DUrole{std,std-ref}{pull}}}}, see the
{\hyperref[\detokenize{appendix:pull-command}]{\sphinxcrossref{\DUrole{std,std-ref}{pull docs}}}}. You have the similar ability to set it to be something
different, or to customize the name of the pulled image.


\section{Environment Variables}
\label{\detokenize{build_environment:environment-variables}}
All environmental variables are parsed by Singularity python helper
functions, and specifically the file \sphinxhref{https://github.com/singularityware/singularity/blob/master/libexec/python/defaults.py}{defaults.py} is a gateway
between variables defined at runtime, and pre-defined defaults. By way
of import from the file, variables set at runtime do not change if
re-imported. This was done intentionally to prevent changes during the
execution, and could be changed if needed. For all variables, the
order of operations works as follows:
\begin{enumerate}
\item {} 
First preference goes to environment variable set at runtime

\item {} 
Second preference goes to default defined in this file

\item {} 
Then, if neither is found, null is returned except in the case that \sphinxcode{\sphinxupquote{required=True}}.
A \sphinxcode{\sphinxupquote{required=True}} variable not found will system exit with an error.

\item {} 
Variables that should not be displayed in debug logger are set with \sphinxcode{\sphinxupquote{silent=True}},
and are only reported to be defined.

\end{enumerate}

For boolean variables, the following are acceptable for True, with any
kind of capitalization or not:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(\PYGZdq{}yes\PYGZdq{}, \PYGZdq{}true\PYGZdq{}, \PYGZdq{}t\PYGZdq{}, \PYGZdq{}1\PYGZdq{},\PYGZdq{}y\PYGZdq{})
\end{sphinxVerbatim}


\section{Cache}
\label{\detokenize{build_environment:cache}}
The location and usage of the cache is also determined by environment
variables.

\sphinxstylestrong{SINGULARITY\_DISABLE\_CACHE} If you want to disable the cache, this
means is that the layers are written to a temporary directory. Thus,
if you want to disable cache and write to a temporary folder, simply
set \sphinxcode{\sphinxupquote{SINGULARITY\_DISABLE\_CACHE}} to any true/yes value. By default, the cache is not disabled.

\sphinxstylestrong{SINGULARITY\_CACHEDIR} Is the base folder for caching layers and
singularity hub images. If not defined, it uses default of \sphinxcode{\sphinxupquote{\$HOME/.singularity}}. If
defined, the defined location is used instead.

If \sphinxcode{\sphinxupquote{SINGULARITY\_DISABLE\_CACHE}} is set to True, this value is ignored in favor of a temporary
directory. For specific sub-types of things to cache, subdirectories
are created (by python), including \sphinxcode{\sphinxupquote{\$SINGULARITY\_CACHEDIR/docker}} for docker layers and \sphinxcode{\sphinxupquote{\$SINGULARITY\_CACHEDIR/shub}} for
Singularity Hub images. If the cache is not created, the Python script
creates it.

\sphinxstylestrong{SINGULARITY\_PULLFOLDER} While this isn’t relevant for build, since
build is close to pull, we will include it here. By default, images
are pulled to the present working directory. The user can change this
variable to change that.

\sphinxstylestrong{SINGULARITY\_TMPDIR} Is the base folder for squashfs image
temporary building. If not defined, it uses default of \sphinxcode{\sphinxupquote{\$TEMPDIR}}. If defined,
the defined location is used instead.

\sphinxstylestrong{SINGULARITY\_LOCALCACHEDIR} Is the temporary folder (default \sphinxcode{\sphinxupquote{/tmp}}) to
generate runtime folders (containers “on the fly”) typically a \sphinxcode{\sphinxupquote{run}}, \sphinxcode{\sphinxupquote{exec}} , or \sphinxcode{\sphinxupquote{shell}}
or a \sphinxcode{\sphinxupquote{docker://}} image. This is different from where downloaded layers are cached
(\sphinxcode{\sphinxupquote{\$SINGULARITY\_CACHEDIR}}) or pulled (\sphinxcode{\sphinxupquote{SINGULARITY\_PULLFOLDER}}) or where a (non on-the-fly build) happens ( \sphinxcode{\sphinxupquote{\$SINGULARITY\_TMPDIR}} ). See
{\hyperref[\detokenize{build_environment:temporary-folders}]{\emph{temporary folders}}} above for an example. You can generally determine the value of this
setting by running a command with \sphinxcode{\sphinxupquote{-{-}debug}} , and seeing the last line “Removing
directory:”

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity \PYGZhy{}\PYGZhy{}debug run docker://busybox echo \PYGZdq{}pizza!\PYGZdq{}

...

DEBUG   [U=1000,P=960]     s\PYGZus{}rmdir()                                 Removing directory: /tmp/.singularity\PYGZhy{}runtime.oArO0k
\end{sphinxVerbatim}


\subsection{Defaults}
\label{\detokenize{build_environment:defaults}}
The following variables have defaults that can be customized by you via
environment variables at runtime.


\subsubsection{Docker}
\label{\detokenize{build_environment:docker}}
\sphinxstylestrong{DOCKER\_API\_BASE} Set as \sphinxcode{\sphinxupquote{index.docker.io}}, which is the name of the registry. In
the first version of Singularity we parsed the Registry argument from
the build spec file, however now this is removed because it can be
obtained directly from the image name (eg, \sphinxcode{\sphinxupquote{registry/namespace/repo:tag}}). If you don’t specify a
registry name for your image, this default is used. If you have
trouble with your registry being detected from the image URI, use this
variable.

\sphinxstylestrong{DOCKER\_API\_VERSION} Is the version of the Docker Registry API
currently being used, by default now is \sphinxcode{\sphinxupquote{v2}}.
\sphinxstylestrong{DOCKER\_OS} This is exposed via the exported environment variable \sphinxcode{\sphinxupquote{SINGULARITY\_DOCKER\_OS}}
and pertains to images that reveal a version 2 manifest with a
\sphinxhref{https://docs.docker.com/registry/spec/manifest-v2-2/\#manifest-list}{manifest list}. In the case that the list is present, we must choose
an operating system (this variable) and an architecture (below). The
default is \sphinxcode{\sphinxupquote{linux}}.

\sphinxstylestrong{DOCKER\_ARCHITECTURE} This is exposed via the exported environment
variable \sphinxcode{\sphinxupquote{SINGULARITY\_DOCKER\_ARCHITECTURE}}
and the same applies as for the \sphinxcode{\sphinxupquote{DOCKER\_OS}} with regards to being used in context
of a list of manifests. In the case that the list is present, we must
choose an architecture (this variable) and an os (above). The default
is \sphinxcode{\sphinxupquote{amd64}}, and other common ones include \sphinxcode{\sphinxupquote{arm}}, \sphinxcode{\sphinxupquote{arm64}}, \sphinxcode{\sphinxupquote{ppc64le}}, \sphinxcode{\sphinxupquote{386}}, and \sphinxcode{\sphinxupquote{s390x}}.
\sphinxstylestrong{NAMESPACE} Is the default namespace, \sphinxcode{\sphinxupquote{library}}.

\sphinxstylestrong{RUNSCRIPT\_COMMAND} Is not obtained from the environment, but is a
hard coded default (“/bin/bash”). This is the fallback command used in
the case that the docker image does not have a CMD or ENTRYPOINT.
\sphinxstylestrong{TAG} Is the default tag, \sphinxcode{\sphinxupquote{latest}}.

\sphinxstylestrong{SINGULARITY\_NOHTTPS} This is relevant if you want to use a
registry that doesn’t have https, and it speaks for itself. If you
export the variable \sphinxcode{\sphinxupquote{SINGULARITY\_NOHTTPS}} you can force the software to not use https when
interacting with a Docker registry. This use case is typically for use
of a local registry.


\subsubsection{Singularity Hub}
\label{\detokenize{build_environment:singularity-hub}}
\sphinxstylestrong{SHUB\_API\_BASE} The default base for the Singularity Hub API,
which is \sphinxcode{\sphinxupquote{https://singularity-hub.org/api}}. If you deploy your own registry, you don’t need
to change this, you can again specify the registry name in the URI.


\subsection{General}
\label{\detokenize{build_environment:general}}
\sphinxstylestrong{SINGULARITY\_PYTHREADS} The Python modules use threads (workers) to
download layer files for Docker, and change permissions. By default,
we will use 9 workers, unless the environment variable \sphinxcode{\sphinxupquote{SINGULARITY\_PYTHREADS}} is defined.
\sphinxstylestrong{SINGULARITY\_COMMAND\_ASIS} By default, we want to make sure the container running process gets passed forward as the current process,
so we want to prefix whatever the Docker command or entrypoint is with
\sphinxcode{\sphinxupquote{exec}}. We also want to make sure that following arguments get passed, so we
append \sphinxcode{\sphinxupquote{"\$@"}}. Thus, some entrypoint or cmd might look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/usr/bin/python
\end{sphinxVerbatim}

and we would parse it into the runscript as:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
exec /usr/bin/python \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}

However, it might be the case that the user does not want this. For this
reason, we have the environmental variable \sphinxcode{\sphinxupquote{RUNSCRIPT\_COMMAND\_ASIS}}. If defined as
yes/y/1/True/true, etc., then the runscript will remain as \sphinxcode{\sphinxupquote{/usr/bin/python}}.


\chapter{Container Recipes}
\label{\detokenize{container_recipes:container-recipes}}\label{\detokenize{container_recipes:id1}}\label{\detokenize{container_recipes::doc}}\phantomsection\label{\detokenize{container_recipes:sec-recipefile}}
A Singularity Recipe is the driver of a custom build, and the starting
point for designing any custom container. It includes specifics about
installation software, environment variables, files to add, and container metadata. You can even write a help section, or define modular
components in the container called based on the \sphinxhref{https://sci-f.github.io/}{Scientific
Filesystem}.


\section{Overview}
\label{\detokenize{container_recipes:overview}}
A Singularity Recipe file is divided into several parts:
\begin{enumerate}
\item {} 
\sphinxstylestrong{Header}: The Header describes the core operating system to build
within the container. Here you will configure the base operating
system features that you need within your container. Examples of this
include, what distribution of Linux, what version, what packages must
be part of a core install.

\item {} 
\sphinxstylestrong{Sections}: The rest of the definition is comprised of sections,
sometimes called scriptlets or blobs of data. Each section is defined
by a \sphinxcode{\sphinxupquote{\%}} character followed by the name of the particular section. All
sections are optional. Sections that are executed at build time are
executed with the \sphinxcode{\sphinxupquote{/bin/sh}} interpreter and can accept \sphinxcode{\sphinxupquote{bin/sh}} options. Similarly,
sections that produce scripts to be executed at runtime can accept
options intended for \sphinxcode{\sphinxupquote{/bin/sh}}

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] Please see the {\hyperref[\detokenize{container_recipes:examples}]{\sphinxcrossref{examples}}} directory in the \sphinxhref{https://github.com/singularityware/singularity}{Singularity source code}
for some ideas on how to get started.
\end{DUlineblock}


\subsection{Header}
\label{\detokenize{container_recipes:header}}
The header is at the top of the file, and tells Singularity the base
Operating System that it should use to build the container. It is
composed of several keywords. Specifically:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Bootstrap}}: references the kind of base you want to use (e.g., docker,
debootstrap, shub). For example, a shub bootstrap will pull
containers for shub as bases. A Docker bootstrap will pull docker
layers to start your image. For a full list see {\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}}

\item {} 
\sphinxcode{\sphinxupquote{From}}: is the named container (shub) or reference to layers (Docker) that
you want to use (e.g., vsoch/hello-world)

\end{itemize}

\begin{DUlineblock}{0em}
\item[] Depending on the value assigned to \sphinxcode{\sphinxupquote{Bootstrap}}, other keywords may also be valid
in the header.
\item[] For example, a very minimal Singularity Hub build might look like
this:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: shub

From: vsoch/hello\PYGZhy{}world
\end{sphinxVerbatim}

A build that uses a mirror to install Centos-7 might look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: yum

OSVersion: 7

MirrorURL: http://mirror.centos.org/centos\PYGZhy{}\PYGZpc{}\PYGZob{}OSVERSION\PYGZcb{}/\PYGZpc{}\PYGZob{}OSVERSION\PYGZcb{}/os/\PYGZdl{}basearch/

Include: yum
\end{sphinxVerbatim}

Each build base requires particular details during build time. You can
read about them and see examples at the following links:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:build-shub}]{\sphinxcrossref{\DUrole{std,std-ref}{shub}}}} (images hosted on Singularity Hub)

\item {} 
{\hyperref[\detokenize{appendix:build-docker-module}]{\sphinxcrossref{\DUrole{std,std-ref}{docker}}}} (images hosted on Docker Hub)

\item {} 
{\hyperref[\detokenize{appendix:build-localimage}]{\sphinxcrossref{\DUrole{std,std-ref}{localimage}}}} (images saved on your machine)

\item {} 
{\hyperref[\detokenize{appendix:build-yum}]{\sphinxcrossref{\DUrole{std,std-ref}{yum}}}} (yum based systems such as CentOS and Scientific Linux)

\item {} 
{\hyperref[\detokenize{appendix:build-debootstrap}]{\sphinxcrossref{\DUrole{std,std-ref}{debootstrap}}}} (apt based systems such as Debian and Ubuntu)

\item {} 
{\hyperref[\detokenize{appendix:build-arch}]{\sphinxcrossref{\DUrole{std,std-ref}{arch}}}} (Arch Linux)

\item {} 
{\hyperref[\detokenize{appendix:build-busybox}]{\sphinxcrossref{\DUrole{std,std-ref}{busybox}}}} (BusyBox)

\item {} 
{\hyperref[\detokenize{appendix:build-zypper}]{\sphinxcrossref{\DUrole{std,std-ref}{zypper}}}} (zypper based systems such as Suse and OpenSuse)

\end{itemize}


\subsection{Sections}
\label{\detokenize{container_recipes:sections}}
The main content of the bootstrap file is broken into sections.
Different sections add different content or execute commands at
different times during the build process. Note that if any command
fails, the build process will halt.
Let’s add each section to our container to see how it works. For each
section, we will build the container from the recipe (a file called
Singularity) as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build roar.simg Singularity
\end{sphinxVerbatim}


\subsubsection{\%help}
\label{\detokenize{container_recipes:help}}\label{\detokenize{container_recipes:id2}}\phantomsection\label{\detokenize{container_recipes:sec-help}}
You don’t need to do much programming to add a \sphinxcode{\sphinxupquote{\%help}}
section to your container. Just write it into a section:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}help

Help me. I\PYGZsq{}m in the container.
\end{sphinxVerbatim}

And it will work when the user asks the container for help.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity help roar.simg

Help me. I\PYGZsq{}m in the container.
\end{sphinxVerbatim}


\subsubsection{\%setup}
\label{\detokenize{container_recipes:setup}}
Commands in the \%setup section are executed on the host system outside
of the container after the base OS has been installed. For versions
earlier than 2.3 if you need files during \%post, you should copy files
from your host to \sphinxcode{\sphinxupquote{\$SINGULARITY\_ROOTFS}} to move them into the
container. For \textgreater{}2.3 you can add files to the container (added before
\%post) using the \%files section. We can see the difference between
\%setup and \%post in the following asciicast:

In the above, we see that copying something to \sphinxcode{\sphinxupquote{\$SINGULARITY\_ROOTFS}} during \sphinxcode{\sphinxupquote{\%setup}} was successful
to move the file into the container, but copying during \sphinxcode{\sphinxupquote{\%post}} was not. Let’s
add a setup to our current container, just writing a file to the root
of the image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}help

Help me. I\PYGZsq{}m in the container.


\PYGZpc{}setup

    touch \PYGZdl{}\PYGZob{}SINGULARITY\PYGZus{}ROOTFS\PYGZcb{}/tacos.txt

    touch avocados.txt
\end{sphinxVerbatim}

Importantly, notice that the avocados file isn’t relative to
\$SINGULARITY\_ROOTFS, so we would expect it not to be in the image. Is
tacos there?

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec roar.simg ls /

bin   environment  lib    mnt   root  scif     sys        usr

boot  etc      lib64  opt   run   singularity  **tacos.txt**  var

dev   home     media  proc  sbin  srv      tmp
\end{sphinxVerbatim}

Yes! And avocados.txt isn’t inside the image, but in our present working
directory:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ls

avocados.txt   roar.simg   Singularity
\end{sphinxVerbatim}


\subsubsection{\%files}
\label{\detokenize{container_recipes:files}}
If you want to copy files from your host system into the container,
you should do so using the \sphinxcode{\sphinxupquote{\%files}} section. Each line is a pair of \sphinxcode{\sphinxupquote{\textless{}source\textgreater{}}} and \sphinxcode{\sphinxupquote{\textless{}destination\textgreater{}}}, where
the source is a path on your host system, and the destination is a
path in the container.

The \sphinxcode{\sphinxupquote{\%files}} section uses the traditional \sphinxcode{\sphinxupquote{cp}} command, so the \sphinxhref{https://linux.die.net/man/1/cp}{same conventions
apply}
Files are copied \sphinxstylestrong{before} any \sphinxcode{\sphinxupquote{\%post}} or installation procedures for
Singularity versions \textgreater{}2.3. If you are using a legacy version, files
are copied after \sphinxcode{\sphinxupquote{\%post}} so you must do this via \sphinxcode{\sphinxupquote{\%setup}}. Let’s add the avocado.txt
into the container, to join tacos.txt.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}help

Help me. I\PYGZsq{}m in the container.


\PYGZsh{} Both of the below are copied before \PYGZpc{}post

\PYGZsh{} 1. This is how to copy files for legacy \PYGZlt{} 2.3


\PYGZpc{}setup

    touch \PYGZdl{}\PYGZob{}SINGULARITY\PYGZus{}ROOTFS\PYGZcb{}/tacos.txt

    touch avocados.txt


\PYGZsh{} 2. This is how to copy files for \PYGZgt{}= 2.3


\PYGZpc{}files

    avocados.txt

    avocados.txt /opt
\end{sphinxVerbatim}

Notice that I’m adding the same file to two different places. For the
first, I’m adding the single file to the root of the image. For the
second, I’m adding it to opt. Does it work?

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec roar.simg ls /

 singularity exec roar.simg ls /

**avocados.txt**  dev      home   media  proc  sbin     srv        tmp

bin       environment  lib    mnt    root  scif     sys        usr

boot          etc      lib64  opt    run   singularity  **tacos.txt**  var


\PYGZdl{} singularity exec roar.simg ls /opt

**avocados.txt**
\end{sphinxVerbatim}

We have avocados!


\subsubsection{\%labels}
\label{\detokenize{container_recipes:labels}}
To store metadata with your container, you can add them to the \sphinxcode{\sphinxupquote{\%labels}} section.
They will be stored in the file \sphinxcode{\sphinxupquote{/.singularity.d/labels.json}} as metadata within your container. The
general format is a \sphinxcode{\sphinxupquote{LABELNAME}} followed by a \sphinxcode{\sphinxupquote{LABELVALUE}}. Labels from Docker bootstraps will
be carried forward here. Let’s add to our example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}help

Help me. I\PYGZsq{}m in the container.


\PYGZpc{}setup

    touch \PYGZdl{}\PYGZob{}SINGULARITY\PYGZus{}ROOTFS\PYGZcb{}/tacos.txt

    touch avocados.txt


\PYGZpc{}files

    avocados.txt

    avocados.txt /opt


\PYGZpc{}labels

    Maintainer Vanessasaurus

    Version v1.0
\end{sphinxVerbatim}

The easiest way to see labels is to inspect the image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect roar.simg

\PYGZob{}

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.deffile.bootstrap\PYGZdq{}: \PYGZdq{}docker\PYGZdq{},

    \PYGZdq{}MAINTAINER\PYGZdq{}: \PYGZdq{}Vanessasaurus\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.deffile\PYGZdq{}: \PYGZdq{}Singularity\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage\PYGZdq{}: \PYGZdq{}/.singularity.d/runscript.help\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.schema\PYGZhy{}version\PYGZdq{}: \PYGZdq{}1.0\PYGZdq{},

    \PYGZdq{}VERSION\PYGZdq{}: \PYGZdq{}v1.0\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.deffile.from\PYGZdq{}: \PYGZdq{}ubuntu\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.build\PYGZhy{}date\PYGZdq{}: \PYGZdq{}2017\PYGZhy{}10\PYGZhy{}02T17:00:23\PYGZhy{}07:00\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.runscript.help\PYGZdq{}: \PYGZdq{}/.singularity.d/runscript.help\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.version\PYGZdq{}: \PYGZdq{}2.3.9\PYGZhy{}development.g3dafa39\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.build\PYGZhy{}size\PYGZdq{}: \PYGZdq{}1760MB\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}

You’ll notice some other labels that are captured automatically from the
build process. You can read more about labels and metadata {\hyperref[\detokenize{environment_and_metadata:environment-and-metadata}]{\sphinxcrossref{\DUrole{std,std-ref}{here}}}}.


\subsubsection{\%environment}
\label{\detokenize{container_recipes:environment}}
\begin{DUlineblock}{0em}
\item[] As of Singularity 2.3, you can add environment variables to your
Singularity Recipe in a section called \sphinxcode{\sphinxupquote{\%environment}}. Keep in mind that these
environment variables are sourced at runtime and not at build time.
This means that if you need the same variables during build time, you
should also define them in your \sphinxcode{\sphinxupquote{\%post}} section. Specifically:
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxstylestrong{during build}: the \sphinxcode{\sphinxupquote{\%environment}} section is written to a file in the container’s
metadata folder. This file is not sourced.

\item {} 
\sphinxstylestrong{during runtime}: the file written to the container’s metadata
folder is sourced.

\end{itemize}

Since the file is ultimately sourced, you should generally use the same
conventions that you might use in a bashrc or profile. In the example
below, the variables \sphinxcode{\sphinxupquote{VADER}} and \sphinxcode{\sphinxupquote{LUKE}} would not be available during build, but when
the container is finished and run:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}help

Help me. I\PYGZsq{}m in the container.


\PYGZpc{}setup

    touch \PYGZdl{}\PYGZob{}SINGULARITY\PYGZus{}ROOTFS\PYGZcb{}/tacos.txt

    touch avocados.txt


\PYGZpc{}files

    avocados.txt

    avocados.txt /opt


\PYGZpc{}labels

    Maintainer Vanessasaurus

    Version v1.0


\PYGZpc{}environment

    VADER=badguy

    LUKE=goodguy

    SOLO=someguy

    export VADER LUKE SOLO
\end{sphinxVerbatim}

For the rationale behind this approach and why we do not source the
\%environment section at build time, refer to this issue. When the
container is finished, you can easily see environment variables also
with inspect, and this is done by showing the file produced above:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}e roar.simg \PYGZsh{} Custom environment shell code should follow


    VADER=badguy

    LUKE=goodguy

    SOLO=someguy

    export VADER LUKE SOLO
\end{sphinxVerbatim}

or in the case of variables generated at build time, you can add
environment variables to your container in the \sphinxcode{\sphinxupquote{\%post}} section (see below) using
the following syntax:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}post

    echo \PYGZsq{}export JAWA\PYGZus{}SEZ=wutini\PYGZsq{} \PYGZgt{}\PYGZgt{} \PYGZdl{}SINGULARITY\PYGZus{}ENVIRONMENT
\end{sphinxVerbatim}

When we rebuild, is it added to the environment?

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity exec roar.simg env \textbar{} grep JAWA

JAWA\PYGZus{}SEZ=wutini
\end{sphinxVerbatim}

Where are all these environment variables going? Inside the container
is a metadata folder located at \sphinxcode{\sphinxupquote{/.singularity.d}}, and a subdirectory \sphinxcode{\sphinxupquote{env}} for environment
scripts that are sourced. Text in the \sphinxcode{\sphinxupquote{\%environment}} section is appended to a file
called \sphinxcode{\sphinxupquote{/.singularity.d/env/90-environment.sh}}. Text redirected to the \sphinxcode{\sphinxupquote{SINGULARITY\_ENVIRONMENT}} variable will added to a file called \sphinxcode{\sphinxupquote{/.singularity.d/env/91-environment.sh}}.
At runtime, scripts in \sphinxcode{\sphinxupquote{/.singularity/env}} are sourced in order. This means that variables
in \sphinxcode{\sphinxupquote{\$SINGULARITY\_ENVIRONMENT}} take precedence over those added via \sphinxcode{\sphinxupquote{\%environment}}. Note that you won’t see
these variables in the inspect output, as inspect only shows the
contents added from \sphinxcode{\sphinxupquote{\%environment}}.
See {\hyperref[\detokenize{environment_and_metadata:environment-and-metadata}]{\sphinxcrossref{\DUrole{std,std-ref}{Environment and Metadata}}}} for more information about
the \sphinxcode{\sphinxupquote{\%labels}} and \sphinxcode{\sphinxupquote{\%environment}} sections.


\subsubsection{\%post}
\label{\detokenize{container_recipes:post}}
Commands in the \sphinxcode{\sphinxupquote{\%post}} section are executed within the container after the base
OS has been installed at build time. This is where the meat of your
setup will live, including making directories, and installing software
and libraries. We will jump from our simple use case to show a more
realistic scientific container. Here we are installing yum, openMPI, and
other dependencies for a Centos7 bootstrap:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}post

    echo \PYGZdq{}Installing Development Tools YUM group\PYGZdq{}

    yum \PYGZhy{}y groupinstall \PYGZdq{}Development Tools\PYGZdq{}

    echo \PYGZdq{}Installing OpenMPI into container...\PYGZdq{}


    \PYGZsh{} Here we are at the base, /, of the container

    git clone https://github.com/open\PYGZhy{}mpi/ompi.git


    \PYGZsh{} Now at /ompi

    cd ompi

    ./autogen.pl

    ./configure \PYGZhy{}\PYGZhy{}prefix=/usr/local

    make

    make install


    /usr/local/bin/mpicc examples/ring\PYGZus{}c.c \PYGZhy{}o /usr/bin/mpi\PYGZus{}ring
\end{sphinxVerbatim}

You cannot copy files from the host to your container in this section,
but you can of course download with commands like \sphinxcode{\sphinxupquote{git clone}} and \sphinxcode{\sphinxupquote{wget}} and \sphinxcode{\sphinxupquote{curl}}.


\subsubsection{\%runscript}
\label{\detokenize{container_recipes:runscript}}\label{\detokenize{container_recipes:id3}}\phantomsection\label{\detokenize{container_recipes:sec-runscript}}
The \sphinxcode{\sphinxupquote{\%runscript}} is another scriptlet, but it does not get executed during
bootstrapping. Instead it gets persisted within the container to a
file (or symlink for later versions) called \sphinxcode{\sphinxupquote{singularity}} which is the execution
driver when the container image is run (either via the \sphinxcode{\sphinxupquote{singularity run}} command or via
executing the container directly).
When the \sphinxcode{\sphinxupquote{\%runscript}} is executed, all options are passed along to the executing
script at runtime, this means that you can (and should) manage
argument processing from within your runscript. Here is an example of
how to do that, adding to our work in progress:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}help

Help me. I\PYGZsq{}m in the container.


\PYGZpc{}setup

    touch \PYGZdl{}\PYGZob{}SINGULARITY\PYGZus{}ROOTFS\PYGZcb{}/tacos.txt

    touch avocados.txt


\PYGZpc{}files

    avocados.txt

    avocados.txt /opt


\PYGZpc{}labels

    Maintainer Vanessasaurus

    Version v1.0


\PYGZpc{}environment

    VADER=badguy

    LUKE=goodguy

    SOLO=someguy

    export VADER LUKE SOLO



\PYGZpc{}post

    echo \PYGZsq{}export JAWA\PYGZus{}SEZ=wutini\PYGZsq{} \PYGZgt{}\PYGZgt{} \PYGZdl{}SINGULARITY\PYGZus{}ENVIRONMENT


\PYGZpc{}runscript

    echo \PYGZdq{}Rooooar!\PYGZdq{}

    echo \PYGZdq{}Arguments received: \PYGZdl{}*\PYGZdq{}

    exec echo \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}

In this particular runscript, the arguments are printed as a single
string (\sphinxcode{\sphinxupquote{\$*}}) and then they are passed to echo via a quoted array (\sphinxcode{\sphinxupquote{\$@}}) which
ensures that all of the arguments are properly parsed by the executed
command. Using the \sphinxcode{\sphinxupquote{exec}} command is like handing off the calling process to
the one in the container. The final command (the echo) replaces the
current entry in the process table (which originally was the call to
Singularity). This makes it so the runscript shell process ceases to
exist, and the only process running inside this container is the called
echo command. This could easily be another program like python, or an
analysis script. Running it, it works as expected:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run roar.simg

Rooooar!

Arguments received:


\PYGZdl{} singularity run roar.simg one two

Rooooar!

Arguments received: one two

one two
\end{sphinxVerbatim}


\subsubsection{\%test}
\label{\detokenize{container_recipes:test}}
You may choose to add a \sphinxcode{\sphinxupquote{\%test}} section to your definition file. This section
will be run at the very end of the build process and will give you a
chance to validate the container during the bootstrap process. You can
also execute this scriptlet through the container itself, such that you
can always test the validity of the container itself as you transport it
to different hosts. Extending on the above Open MPI \sphinxcode{\sphinxupquote{\%post}}, consider this real
world example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}test

    /usr/local/bin/mpirun \PYGZhy{}\PYGZhy{}allow\PYGZhy{}run\PYGZhy{}as\PYGZhy{}root /usr/bin/mpi\PYGZus{}test
\end{sphinxVerbatim}

This is a simple Open MPI test to ensure that the MPI is build
properly and communicates between processes as it should.
If you want to build without running tests (for example, if the test
needs to be done in a different environment), you can do so with the
\sphinxcode{\sphinxupquote{-{-}notest}} argument:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}notest mpirun.simg Singularity
\end{sphinxVerbatim}

This argument is useful in cases where you need hardware that is
available during runtime, but is not available on the host that is
building the image.


\section{Apps}
\label{\detokenize{container_recipes:apps}}
What if you want to build a single container with two or three
different apps that each have their own runscripts and custom
environments? In some circumstances, it may be redundant to build
different containers for each app with almost equivalent dependencies.

Starting in Singularity 2.4 all of the above commands can also be used
in the context of internal modules called {\hyperref[\detokenize{reproducible_scif_apps:reproducible-scif-apps}]{\sphinxcrossref{\DUrole{std,std-ref}{apps}}}} based on the \sphinxhref{https://sci-f.github.io/}{Standard
Container Integration Format}. For details on apps, see the {\hyperref[\detokenize{reproducible_scif_apps:reproducible-scif-apps}]{\sphinxcrossref{\DUrole{std,std-ref}{apps}}}}
documentation. For a quick rundown of adding an app to your container,
here is an example runscript:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu


\PYGZpc{}environment

    VADER=badguy

    LUKE=goodguy

    SOLO=someguy

    export VADER LUKE SOLO


\PYGZpc{}labels

   Maintainer Vanessasaur


\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}

\PYGZsh{} foo

\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}


\PYGZpc{}apprun foo

    exec echo \PYGZdq{}RUNNING FOO\PYGZdq{}


\PYGZpc{}applabels foo

   BESTAPP=FOO

   export BESTAPP


\PYGZpc{}appinstall foo

   touch foo.exec


\PYGZpc{}appenv foo

    SOFTWARE=foo

    export SOFTWARE


\PYGZpc{}apphelp foo

    This is the help for foo.


\PYGZpc{}appfiles foo

   avocados.txt



\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}

\PYGZsh{} bar

\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}


\PYGZpc{}apphelp bar

    This is the help for bar.


\PYGZpc{}applabels bar

   BESTAPP=BAR

   export BESTAPP


\PYGZpc{}appinstall bar

    touch bar.exec


\PYGZpc{}appenv bar

    SOFTWARE=bar

    export SOFTWARE
\end{sphinxVerbatim}

Importantly, note that the apps can exist alongside any and all of the
primary sections (e.g. \sphinxcode{\sphinxupquote{\%post}} or \sphinxcode{\sphinxupquote{\%runscript}} ), and the new \sphinxcode{\sphinxupquote{\%appinstall}} section is the equivalent of
\%post but for an app. The title sections (\sphinxcode{\sphinxupquote{\#\#\#\#\#\#}}) aren’t necessary or
required, they are just comments to show you the different apps. The
ordering isn’t important either, you can have any mixture of sections
anywhere in the file after the header. The primary difference is now
the container can perform any of it’s primary functions in the context
of an app:

\sphinxstylestrong{What apps are installed in the container?}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity apps roar.simg

bar

foo
\end{sphinxVerbatim}

\sphinxstylestrong{Help me with bar!}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity help \PYGZhy{}\PYGZhy{}app bar roar.simg

This is the help for bar.
\end{sphinxVerbatim}

\sphinxstylestrong{Run foo}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity run \PYGZhy{}\PYGZhy{}app foo roar.simg

RUNNING FOO
\end{sphinxVerbatim}

\sphinxstylestrong{Show me the custom environments}

Remember how we defined the same environment variable, SOFTWARE for
each of foo and bar? We can execute a command to search the list of
active environment variables with grep to see if the variable changes
depending on the app we specify:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec \PYGZhy{}\PYGZhy{}app foo roar.simg env \textbar{} grep SOFTWARE

SOFTWARE=foo

\PYGZdl{} singularity exec \PYGZhy{}\PYGZhy{}app bar roar.simg env \textbar{} grep SOFTWARE

SOFTWARE=bar
\end{sphinxVerbatim}


\section{Examples}
\label{\detokenize{container_recipes:examples}}
For more examples, for real world scientific recipes we recommend you
look at other containers on \sphinxhref{https://singularity-hub.org/}{Singularity Hub}. For examples of
different bases, look at the examples folder for the most up-to-date
examples. For apps, including snippets and tutorial with more walk
throughs, see \sphinxhref{https://sci-f.github.io/}{SCI-F Apps Home}.


\section{Best Practices for Build Recipes}
\label{\detokenize{container_recipes:best-practices-for-build-recipes}}
When crafting your recipe, it is best to consider the following:
\begin{enumerate}
\item {} 
To make your container internally modular, use {\hyperref[\detokenize{reproducible_scif_apps:reproducible-scif-apps}]{\sphinxcrossref{\DUrole{std,std-ref}{SCI-F apps}}}}. Shared dependencies
(between app modules) can go under \sphinxcode{\sphinxupquote{\%post}}.

\item {} 
For global installs to \sphinxcode{\sphinxupquote{\%post}}, install packages, programs, data, and files
into operating system locations (e.g. not \sphinxcode{\sphinxupquote{/home}}, \sphinxcode{\sphinxupquote{/tmp}} , or any other
directories that might get commonly binded on).

\item {} 
Make your container speak for itself. If your runscript doesn’t spit
out help, write a \sphinxcode{\sphinxupquote{\%help}} or \sphinxcode{\sphinxupquote{\%post}} or \sphinxcode{\sphinxupquote{\%apphelp}} section. A good container tells the user how
to interact with it.

\item {} 
If you require any special environment variables to be defined, add
them the \sphinxcode{\sphinxupquote{\%environment}} and \sphinxcode{\sphinxupquote{\%appenv}} sections of the build recipe.

\item {} 
Files should never be owned by actual users, they should always be
owned by a system account (UID less than 500).

\item {} 
Ensure that the container’s \sphinxcode{\sphinxupquote{/etc/passwd}} , \sphinxcode{\sphinxupquote{/etc/group}} , \sphinxcode{\sphinxupquote{/etc/shadow}} , and no other sensitive files have
anything but the bare essentials within them.

\item {} 
It is encouraged to build containers from a recipe instead of a
sandbox that has been manually changed. This ensures greatest
possibility of reproducibility and mitigates the black box effect.

\end{enumerate}

Are you a recipe pro and now ready to build? Take a look at the
{\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}} documentation.


\chapter{Singularity Flow}
\label{\detokenize{singularity_flow:singularity-flow}}\label{\detokenize{singularity_flow:id1}}\label{\detokenize{singularity_flow::doc}}
This document describes a suggested “best-practices” workflow for
building, running, and managing your containers.

There are generally two ways to get images. You either want to pull an
image file as is, or (more likely) build your own custom image. We
will start with talking about build, and the many different use cases it affords.


\section{Building Images}
\label{\detokenize{singularity_flow:building-images}}\label{\detokenize{singularity_flow:sec-singularityflow}}
If you read the {\hyperref[\detokenize{quick_start:quick-start}]{\sphinxcrossref{\DUrole{std,std-ref}{quick start}}}}, you probably remember that building images from a
Docker base does not require a {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity recipe}}}}. However, if you do want to build and
customize your image, you can create a {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity recipe}}}} text file, which is a simple
text file that describes how the container should be made.


\subsection{The Singularity Flow}
\label{\detokenize{singularity_flow:the-singularity-flow}}
The diagram below is a visual depiction of how you can use Singularity
to build images. The high level idea is that we have two environments:
\begin{itemize}
\item {} 
a \sphinxstylestrong{build} environment (where you have sudo privileges) to test and
build your container

\item {} 
a \sphinxstylestrong{production} environment where you run your container

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{flow}.png}
\caption{Singularity Workflow}\label{\detokenize{singularity_flow:id2}}\end{figure}

Singularity production images are immutable. This is a feature added as
of Singularity 2.4, and it ensures a higher level of reproducibility and
verification of images. To read more about the details, check out the {\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}}
docs. However, immutability is not so great when you are testing,
debugging, or otherwise want to quickly change your image. We will
proceed by describing a typical workflow of developing first, building a
final image, and using it in production.


\subsection{1. Development Commands}
\label{\detokenize{singularity_flow:development-commands}}
If you want a writable image or folder for developing, you have two
options:
\begin{itemize}
\item {} 
build into a directory that has writable permissions using the \sphinxcode{\sphinxupquote{-{-}sandbox}} option

\item {} 
build into an ext3 image file, that has writable permissions with the \sphinxcode{\sphinxupquote{-{-}writable}}
option

\end{itemize}

In both cases you will need to execute your container with the \sphinxcode{\sphinxupquote{-{-}writable}} option at
runtime for your changes to be persistent.


\subsubsection{Sandbox Folder}
\label{\detokenize{singularity_flow:sandbox-folder}}
To build into a folder (we call this a “sandbox”) just ask for it:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}sandbox ubuntu/ docker://ubuntu

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /root/.singularity/docker

Importing: base Singularity environment

Importing: /root/.singularity/docker/sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz

Importing: /root/.singularity/docker/sha256:3b61febd4aefe982e0cb9c696d415137384d1a01052b50a85aae46439e15e49a.tar.gz

Importing: /root/.singularity/docker/sha256:9d99b9777eb02b8943c0e72d7a7baec5c782f8fd976825c9d3fb48b3101aacc2.tar.gz

Importing: /root/.singularity/docker/sha256:d010c8cf75d7eb5d2504d5ffa0d19696e8d745a457dd8d28ec6dd41d3763617e.tar.gz

Importing: /root/.singularity/docker/sha256:7fac07fb303e0589b9c23e6f49d5dc1ff9d6f3c8c88cabe768b430bdb47f03a9.tar.gz

Importing: /root/.singularity/metadata/sha256:22e289880847a9a2f32c62c237d2f7e3f4eae7259bf1d5c7ec7ffa19c1a483c8.tar.gz

Building image from sandbox: ubuntu/

Singularity container built: ubuntu/
\end{sphinxVerbatim}

We now have a folder with the entire ubuntu OS, plus some Singularity
metadata, plopped in our present working directory.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYGZdl{} tree \PYGZhy{}L 1 ubuntu

ubuntu

├── bin

├── boot

├── dev

├── environment \PYGZhy{}\PYGZgt{} .singularity.d/env/90\PYGZhy{}environment.sh

├── etc

├── home

├── lib

├── lib64

├── media

├── mnt

├── opt

├── proc

├── root

├── run

├── sbin

├── singularity \PYGZhy{}\PYGZgt{} .singularity.d/runscript

├── srv

├── sys

├── tmp

├── usr

└── var
\end{sphinxVerbatim}

And you can shell into it just like a normal container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell ubuntu

Singularity: Invoking an interactive shell within container...


Singularity ubuntu:\PYGZti{}/Desktop\PYGZgt{} touch /hello.txt

touch: cannot touch \PYGZsq{}/hello.txt\PYGZsq{}: Permission denied
\end{sphinxVerbatim}

You can make changes to the container (assuming you have the proper
permissions to do so) but those changes will disappear as soon as you
exit. To make your changes persistent across sessions, use the \sphinxcode{\sphinxupquote{-{-}writable}} option.
It’s also a good practice to shell into your container as root to
ensure you have permissions to write where you like.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell ubuntu

Singularity: Invoking an interactive shell within container...


Singularity ubuntu:/home/vanessa/Desktop\PYGZgt{} touch /hello.txt
\end{sphinxVerbatim}


\subsubsection{Writable Image}
\label{\detokenize{singularity_flow:writable-image}}
If you prefer to work with a writable image file rather than a
directory, you can perform a similar development build and specify the \sphinxcode{\sphinxupquote{-{-}writable}}
option. This will produce an image that is writable with an ext3 file
system. Unlike the sandbox, it is a single image file.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}writable ubuntu.img docker://ubuntu

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /root/.singularity/docker

Importing: base Singularity environment

Importing: /root/.singularity/docker/sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz

Importing: /root/.singularity/docker/sha256:3b61febd4aefe982e0cb9c696d415137384d1a01052b50a85aae46439e15e49a.tar.gz

Importing: /root/.singularity/docker/sha256:9d99b9777eb02b8943c0e72d7a7baec5c782f8fd976825c9d3fb48b3101aacc2.tar.gz

Importing: /root/.singularity/docker/sha256:d010c8cf75d7eb5d2504d5ffa0d19696e8d745a457dd8d28ec6dd41d3763617e.tar.gz

Importing: /root/.singularity/docker/sha256:7fac07fb303e0589b9c23e6f49d5dc1ff9d6f3c8c88cabe768b430bdb47f03a9.tar.gz

Importing: /root/.singularity/metadata/sha256:22e289880847a9a2f32c62c237d2f7e3f4eae7259bf1d5c7ec7ffa19c1a483c8.tar.gz

Building image from sandbox: /tmp/.singularity\PYGZhy{}build.VCHPpP

Creating empty Singularity writable container 130MB

Creating empty 162MiB image file: ubuntu.img

Formatting image with ext3 file system

Image is done: ubuntu.img

Building Singularity image...


Cleaning up...


Singularity container built: ubuntu.img
\end{sphinxVerbatim}

You can use this image with commands like \sphinxcode{\sphinxupquote{shell}}, \sphinxcode{\sphinxupquote{exec}} , \sphinxcode{\sphinxupquote{run}} , and if you want to
change the image you must use the \sphinxcode{\sphinxupquote{-{-}writable}} flag. As before, it’s a good idea to
issue these commands as root to ensure you have the proper permissions
to write.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell \PYGZhy{}\PYGZhy{}writable ubuntu.img


Development Tip! When building containers, it often is the case that

you will have a lot of testing of installation commands, and if

building a production image, one error will stop the entire build.

If you interactively write the build recipe with one of these

writable containers, you can debug as you go, and then build the

production (squashfs) container without worrying that it will error

and need to be started again.
\end{sphinxVerbatim}


\subsection{2. Production Commands}
\label{\detokenize{singularity_flow:production-commands}}
Let’s set the scene - we just finished building our perfect hello world
container. It does a fantastic hello-world analysis, and we have written
a paper on it! We now want to build an immutable container - meaning
that if someone obtained our container and tried to change it, they
could not. They could easily use the same recipe that you used (it is
provided as metadata inside the container), or convert your container to
one of the writable formats above using \sphinxcode{\sphinxupquote{build}} . So your work can still be
extended.


\subsubsection{Recommended Production Build}
\label{\detokenize{singularity_flow:recommended-production-build}}
What we want for production is a build into a \sphinxhref{https://en.wikipedia.org/wiki/SquashFS}{squashfs image} .
Squashfs is a read only, and compressed filesystem, and well suited for
confident archive and re-use of your hello-world. To build a production
image, just remove the extra options:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build ubuntu.simg docker://ubuntu

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /root/.singularity/docker

Importing: base Singularity environment

Importing: /root/.singularity/docker/sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz

Importing: /root/.singularity/docker/sha256:3b61febd4aefe982e0cb9c696d415137384d1a01052b50a85aae46439e15e49a.tar.gz

Importing: /root/.singularity/docker/sha256:9d99b9777eb02b8943c0e72d7a7baec5c782f8fd976825c9d3fb48b3101aacc2.tar.gz

Importing: /root/.singularity/docker/sha256:d010c8cf75d7eb5d2504d5ffa0d19696e8d745a457dd8d28ec6dd41d3763617e.tar.gz

Importing: /root/.singularity/docker/sha256:7fac07fb303e0589b9c23e6f49d5dc1ff9d6f3c8c88cabe768b430bdb47f03a9.tar.gz

Importing: /root/.singularity/metadata/sha256:22e289880847a9a2f32c62c237d2f7e3f4eae7259bf1d5c7ec7ffa19c1a483c8.tar.gz

Building Singularity image...

Cleaning up...

Singularity container built: ubuntu.simg
\end{sphinxVerbatim}


\subsubsection{Production Build from Sandbox}
\label{\detokenize{singularity_flow:production-build-from-sandbox}}
We understand that it might be wanted to build a Singularity (squashfs)
from a previous development image. While we advocate for the first
approach, we support this use case. To do this, given our folder called
“ubuntu/” we made above:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build ubuntu.simg ubuntu/
\end{sphinxVerbatim}

It could be the case that a cluster maintains a “working” base of
container folders (with writable) and then builds and provides
production containers to its users.

If you want to go through this entire process without having
singularity installed locally, or without leaving your cluster, you
can build images using \sphinxhref{https://github.com/singularityhub/singularityhub.github.io/wiki}{Singularity Hub}.


\chapter{Bind Paths and Mounts}
\label{\detokenize{bind_paths_and_mounts:bind-paths-and-mounts}}\label{\detokenize{bind_paths_and_mounts:id1}}\label{\detokenize{bind_paths_and_mounts::doc}}\phantomsection\label{\detokenize{bind_paths_and_mounts:sec-bindpaths}}
If \sphinxhref{https://singularity-admindoc.readthedocs.io/en/latest/the\_singularity\_config\_file.html\#user-bind-control-boolean-default-yes}{enabled by the system administrator}, Singularity allows you to map
directories on your host system to directories within your container
using bind mounts. This allows you to read and write data on the host
system with ease.


\section{Overview}
\label{\detokenize{bind_paths_and_mounts:overview}}
When Singularity ‘swaps’ the host operating system for the one inside
your container, the host file systems becomes inaccessible. But you may
want to read and write files on the host system from within the
container. To enable this functionality, Singularity will bind
directories back in via two primary methods: system-defined bind points
and conditional user-defined bind points.


\subsection{System-defined bind points}
\label{\detokenize{bind_paths_and_mounts:system-defined-bind-points}}
The system administrator has the ability to define what bind points will
be included automatically inside each container. The bind paths are
locations on the host’s root file system which should also be visible
within the container. Some of the bind paths are automatically derived
(e.g. a user’s home directory) and some are statically defined (e.g.
bind path in the Singularity configuration file). In the default
configuration, the directories \sphinxcode{\sphinxupquote{\$HOME}} , \sphinxcode{\sphinxupquote{/tmp}} , \sphinxcode{\sphinxupquote{/proc}} , \sphinxcode{\sphinxupquote{/sys}} , \sphinxcode{\sphinxupquote{/dev}} and are among the system-defined
bind points.


\subsection{User-defined bind points}
\label{\detokenize{bind_paths_and_mounts:user-defined-bind-points}}
If the system administrator has \sphinxhref{https://singularity-admindoc.readthedocs.io/en/latest/the\_singularity\_config\_file.html\#user-bind-control-boolean-default-yes}{enabled user control of binds}, you
will be able to request your own bind points within your container.

To \sphinxstyleemphasis{mount} a bind path inside the container, a \sphinxstylestrong{bind point} must be
defined within the container. The bind point is a directory within the
container that Singularity can use to bind a directory on the host
system. This means that if you want to bind to a point within the
container such as \sphinxcode{\sphinxupquote{/global}}, that directory must already exist within the
container.

It is, however, possible that the system administrator has enabled a
Singularity feature called \sphinxhref{https://singularity-admindoc.readthedocs.io/en/latest/the\_singularity\_config\_file.html\#enable-overlay-boolean-default-no}{overlay in the Singularity configuration
file}. This will cause the bind points to be created on an as-needed
basis in an overlay file system so that the underlying container is
not modified. But because the overlay feature is not always enabled or
is unavailable in the kernels of some older host systems, it may be
necessary for container standards to exist to ensure portability from
host to host.


\subsubsection{Specifying Bind Paths}
\label{\detokenize{bind_paths_and_mounts:specifying-bind-paths}}
Many of the Singularity commands such as \sphinxcode{\sphinxupquote{run}}, \sphinxcode{\sphinxupquote{exec}} , and \sphinxcode{\sphinxupquote{shell}} take the \sphinxcode{\sphinxupquote{-{-}bind /
command-line}} option to specify bind paths, in addition to the \sphinxcode{\sphinxupquote{SINGULARITY\_BINDPATH}}
environment variable. This option’s argument is a comma-delimited
string of bind path specifications in the format \sphinxcode{\sphinxupquote{src{[}:dest{[}:opts{]}{]}}}, where \sphinxcode{\sphinxupquote{src}} and \sphinxcode{\sphinxupquote{dest}} are
outside and inside paths. If \sphinxcode{\sphinxupquote{dest}} is not given, it is set equal to \sphinxcode{\sphinxupquote{src}} . Mount
options (\sphinxcode{\sphinxupquote{opts}}) may be specified as \sphinxcode{\sphinxupquote{ro}} (read-only) or \sphinxcode{\sphinxupquote{rw}} (read/write, which is
the default). The \sphinxcode{\sphinxupquote{-{-}bind/-B}} option can be specified multiple times, or a
comma-delimited string of bind path specifications can be used.

Here’s an example of using the \sphinxcode{\sphinxupquote{-B}} option and binding \sphinxcode{\sphinxupquote{/tmp}} on the host to \sphinxcode{\sphinxupquote{/scratch}} in
the container (\sphinxcode{\sphinxupquote{/scratch}} does not need to already exist in the container if
file system overlay is enabled):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell \PYGZhy{}B /tmp:/scratch /tmp/Centos7\PYGZhy{}ompi.img

Singularity: Invoking an interactive shell within container...


Singularity.Centos7\PYGZhy{}ompi.img\PYGZgt{} ls /scratch

ssh\PYGZhy{}7vywtVeOez  systemd\PYGZhy{}private\PYGZhy{}cd84c81dda754fe4a7a593647d5a5765\PYGZhy{}ntpd.service\PYGZhy{}12nMO4
\end{sphinxVerbatim}

You can bind multiple directories in a single command with this
syntax:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell \PYGZhy{}B /opt,/data:/mnt /tmp/Centos7\PYGZhy{}ompi.img
\end{sphinxVerbatim}

This will bind \sphinxcode{\sphinxupquote{/opt}} on the host to \sphinxcode{\sphinxupquote{/opt}} in the container and \sphinxcode{\sphinxupquote{/data}} on the host to \sphinxcode{\sphinxupquote{/mnt}} in the
container. Using the environment variable instead of the command line
argument, this would be:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} export SINGULARITY\PYGZus{}BINDPATH=\PYGZdq{}/opt,/data:/mnt\PYGZdq{}

\PYGZdl{} singularity shell /tmp/Centos7\PYGZhy{}ompi.img
\end{sphinxVerbatim}

Using the environment variable \sphinxcode{\sphinxupquote{\$SINGULARITY\_BINDPATH}}, you can bind directories even when you
are running your container as an executable file with a runscript. If
you bind many directories into your Singularity containers and they
don’t change, you could even benefit by setting this variable in your \sphinxcode{\sphinxupquote{.bashrc}}
file.


\subsubsection{Binding with Overlay}
\label{\detokenize{bind_paths_and_mounts:binding-with-overlay}}
If a bind path is requested and the bind point does not exist within the
container, a warning message will be displayed and Singularity will
continue trying to start the container. For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell \PYGZhy{}\PYGZhy{}bind /global /tmp/Centos7\PYGZhy{}ompi.img

WARNING: Non existent bind point (directory) in container: \PYGZsq{}/global\PYGZsq{}

Singularity: Invoking an interactive shell within container...


Singularity.Centos7\PYGZhy{}ompi.img\PYGZgt{}
\end{sphinxVerbatim}

Even though \sphinxcode{\sphinxupquote{/global}} did not exist inside the container, the shell command
printed a warning but continued on. If overlay is available and enabled,
you will find that we no longer get the error and \sphinxcode{\sphinxupquote{/global}} is created and
accessible as expected:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell \PYGZhy{}\PYGZhy{}bind /global /tmp/Centos7\PYGZhy{}ompi.img

Singularity: Invoking an interactive shell within container...


Singularity.Centos7\PYGZhy{}ompi.img\PYGZgt{}
\end{sphinxVerbatim}

In this case, Singularity dynamically created the necessary bind point
in your container. Without overlay, you would have needed to manually
create the \sphinxcode{\sphinxupquote{/global}} directory inside your container.


\chapter{Persistent Overlays}
\label{\detokenize{persistent_overlays:persistent-overlays}}\label{\detokenize{persistent_overlays::doc}}
Persistent overlay images are new to version 2.4! This feature allows
you to overlay a writable file system on an immutable read-only
container for the illusion of read-write access.


\section{Overview}
\label{\detokenize{persistent_overlays:overview}}
A persistent overlay is an image that “sits on top” of your
compressed, immutable squashfs container. When you install new
software or create and modify files the overlay image stores the
changes.

In Singularity versions 2.4 and later an overlay file system is
automatically added to your squashfs or sandbox container when it is
mounted. This means you can install new software and create and modify
files even though your container is read-only. But your changes will disappear as soon as you exit the container.

If you want your changes to persist in your container across uses, you
can create a writable image to use as a persistent overlay. Then you
can specify that you want to use the image as an overlay at runtime
with the \sphinxcode{\sphinxupquote{-{-}overlay}} option.

You can use a persistent overlays with the following commands:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{run}}

\item {} 
\sphinxcode{\sphinxupquote{exec}}

\item {} 
\sphinxcode{\sphinxupquote{shell}}

\item {} 
\sphinxcode{\sphinxupquote{instance.start}}

\end{itemize}


\section{Usage}
\label{\detokenize{persistent_overlays:usage}}
To use a persistent overlay, you must first have a container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build ubuntu.simg shub://GodloveD/ubuntu
\end{sphinxVerbatim}

Then you must create a writable, ext3 image. We can do so with the \sphinxcode{\sphinxupquote{image.create}}
command:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity image.create my\PYGZhy{}overlay.img
\end{sphinxVerbatim}

Now you can use this overlay image with your container. Note that it is
not necessary to be root to use an overlay partition, but this will
ensure that we have write privileges where we want them.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell \PYGZhy{}\PYGZhy{}overlay my\PYGZhy{}overlay.img ubuntu.simg

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} touch /foo

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} apt\PYGZhy{}get install \PYGZhy{}y vim

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} which vim

/usr/bin/vim

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} exit
\end{sphinxVerbatim}

You will find that your changes persist across sessions as though you
were using a writable container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell \PYGZhy{}\PYGZhy{}overlay my\PYGZhy{}overlay.img ubuntu.simg

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} ls /foo

/foo

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} which vim

/usr/bin/vim

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} exit
\end{sphinxVerbatim}

If you mount your container without the \sphinxcode{\sphinxupquote{-{-}overlay}} option, your changes will be
gone.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity shell ubuntu.simg

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} ls /foo

ls: cannot access \PYGZsq{}foo\PYGZsq{}: No such file or directory

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} which vim

Singularity ubuntu.simg:\PYGZti{}\PYGZgt{} exit
\end{sphinxVerbatim}


\chapter{Running Services}
\label{\detokenize{running_services:running-services}}\label{\detokenize{running_services:id1}}\label{\detokenize{running_services::doc}}
Singularity 2.4 introduces the ability to run “container instances”,
allowing you to run services (e.g. Nginx, MySQL, etc…) using
Singularity. A container instance, simply put, is a persistent and
isolated version of the container image that runs in the background.


\section{Why container instances?}
\label{\detokenize{running_services:why-container-instances}}
that is pretty simple, I install nginx and start the service:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
apt\PYGZhy{}get update \PYGZam{}\PYGZam{} apt\PYGZhy{}get install \PYGZhy{}y nginx

service nginx start
\end{sphinxVerbatim}

With older versions of Singularity, if you were to do something like
this, from inside the container you would happily see the service
start, and the web server running! But then if you were to log out of
the container what would happen?
Orphan process within unreachable namespaces!
You would lose control of the process. It would still be running, but
you couldn’t easily kill or interface with it. This is a called an
orphan process. Singularity versions less than 2.4 were not designed to handle running services properly.


\section{Container Instances in Singularity}
\label{\detokenize{running_services:container-instances-in-singularity}}
With Singularity 2.4 and the addition of container instances, the
ability to cleanly, reliably, and safely run services in a container is
here. First, let’s put some commands that we want our instance to
execute into a script. Let’s call it a \sphinxcode{\sphinxupquote{startscript}}. This fits into a definition
file like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}startscript


service nginx start
\end{sphinxVerbatim}

Now let’s say we build a container with that startscript into an image
called \sphinxcode{\sphinxupquote{nginx.img}} and we want to run an nginx service. All we need to do is start
the instance with the \DUrole{xref,std,std-ref}{instance.start} command, and the
startscript will run inside the container automatically:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
              [command]        [image]    [name of instance]

\PYGZdl{} singularity instance.start   nginx.img  web
\end{sphinxVerbatim}

When we run that command, Singularity creates an isolated environment
for the container instances’ processes/services to live inside. We can
confirm that this command started an instance by running the
instance.list command like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.list

INSTANCE NAME    PID      CONTAINER IMAGE

web              790      /home/mibauer/nginx.img
\end{sphinxVerbatim}

If we want to run multiple instances from the same image, it’s as simple
as running the command multiple times. The instance names are an
identifier used to uniquely describe an instance, so they cannot be
repeated.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start   nginx.img  web1

\PYGZdl{} singularity instance.start   nginx.img  web2

\PYGZdl{} singularity instance.start   nginx.img  web3
\end{sphinxVerbatim}

And again to confirm that the instances are running as we expected:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.list

INSTANCE NAME    PID      CONTAINER IMAGE

web1             790      /home/mibauer/nginx.img

web2             791      /home/mibauer/nginx.img

web3             792      /home/mibauer/nginx.img
\end{sphinxVerbatim}

If the service you want to run in your instance requires a bind mount,
then you must pass the \sphinxcode{\sphinxupquote{-B}} option when calling \sphinxcode{\sphinxupquote{instance.start}}. For example, if you wish to
capture the output of the \sphinxcode{\sphinxupquote{web1}} container instance which is placed at \sphinxcode{\sphinxupquote{/output/}} inside
the container you could do:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start \PYGZhy{}B output/dir/outside/:/output/ nginx.img  web1
\end{sphinxVerbatim}

If you want to poke around inside of your instance, you can do a normal \sphinxcode{\sphinxupquote{singularity shell}}
command, but give it the instance URI:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell instance://web1

Singularity: Invoking an interactive shell within container...


Singularity pdf\PYGZus{}server.img:\PYGZti{}/\PYGZgt{}
\end{sphinxVerbatim}

Similarly, you can use the \sphinxcode{\sphinxupquote{singularity run/exec}} commands on instances:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run instance://web1

\PYGZdl{} singularity exec instance://web1 ps \PYGZhy{}ef
\end{sphinxVerbatim}

When using \sphinxcode{\sphinxupquote{run}} with an instance URI, the \sphinxcode{\sphinxupquote{runscript}} will be executed inside of the
instance. Similarly with \sphinxcode{\sphinxupquote{exec}}, it will execute the given command in the
instance.

When you are finished with your instance you can clean it up with the
\DUrole{xref,std,std-ref}{instance.stop} command like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.stop web1
\end{sphinxVerbatim}

If you have multiple instances running and you want to stop all of
them, you can do so with a wildcard or the -a flag:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.stop \PYGZbs{}*

\PYGZdl{} singularity instance.stop \PYGZhy{}a
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
Note that you must escape the wildcard with a backslash like this \sphinxcode{\sphinxupquote{\textbackslash{}*}} to
pass it properly.
\end{sphinxadmonition}


\section{Nginx “Hello-world” in Singularity}
\label{\detokenize{running_services:nginx-hello-world-in-singularity}}
Let’s take a look at setting up a sample nginx web server using
instances in Singularity. First we will just create a basic definition
file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: nginx

Includecmd: no


\PYGZpc{}startscript

    nginx
\end{sphinxVerbatim}

All this does is download the official nginx Docker container, convert
it to a Singularity image, and tell it to run nginx when you start the
instance. Since we’re running a web server, we’re going to run the
following commands as root.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} singularity build nginx.img Singularity

\PYGZsh{} singularity instance.start nginx.img web1
\end{sphinxVerbatim}

Just like that we’ve downloaded, built, and ran an nginx Singularity
image. And to confirm that it’s correctly running:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} curl localhost

127.0.0.1 \PYGZhy{} \PYGZhy{} [06/Oct/2017:21:46:43 +0000] \PYGZdq{}GET / HTTP/1.1\PYGZdq{} 200 612 \PYGZdq{}\PYGZhy{}\PYGZdq{} \PYGZdq{}curl/7.47.0\PYGZdq{} \PYGZdq{}\PYGZhy{}\PYGZdq{}

\PYGZlt{}!DOCTYPE html\PYGZgt{}

\PYGZlt{}html\PYGZgt{}

\PYGZlt{}head\PYGZgt{}

\PYGZlt{}title\PYGZgt{}Welcome to nginx!\PYGZlt{}/title\PYGZgt{}

\PYGZlt{}style\PYGZgt{}

    body \PYGZob{}

        width: 35em;

        margin: 0 auto;

        font\PYGZhy{}family: Tahoma, Verdana, Arial, sans\PYGZhy{}serif;

    \PYGZcb{}

\PYGZlt{}/style\PYGZgt{}

\PYGZlt{}/head\PYGZgt{}

\PYGZlt{}body\PYGZgt{}

\PYGZlt{}h1\PYGZgt{}Welcome to nginx!\PYGZlt{}/h1\PYGZgt{}

\PYGZlt{}p\PYGZgt{}If you see this page, the nginx web server is successfully installed and

working. Further configuration is required.\PYGZlt{}/p\PYGZgt{}


\PYGZlt{}p\PYGZgt{}For online documentation and support please refer to

\PYGZlt{}a href=\PYGZdq{}http://nginx.org/\PYGZdq{}\PYGZgt{}nginx.org\PYGZlt{}/a\PYGZgt{}.\PYGZlt{}br/\PYGZgt{}

Commercial support is available at

\PYGZlt{}a href=\PYGZdq{}http://nginx.com/\PYGZdq{}\PYGZgt{}nginx.com\PYGZlt{}/a\PYGZgt{}.\PYGZlt{}/p\PYGZgt{}


\PYGZlt{}p\PYGZgt{}\PYGZlt{}em\PYGZgt{}Thank you for using nginx.\PYGZlt{}/em\PYGZgt{}\PYGZlt{}/p\PYGZgt{}

\PYGZlt{}/body\PYGZgt{}

\PYGZlt{}/html\PYGZgt{}
\end{sphinxVerbatim}


\section{Putting all together}
\label{\detokenize{running_services:putting-all-together}}
In this section, we will demonstrate an example of packaging a service
into a container and running it. The service we will be packaging is an
API server that converts a web page into a PDF, and can be found
\sphinxhref{https://github.com/alvarcarto/url-to-pdf-api}{here}. The final
example can be found \sphinxhref{https://github.com/bauerm97/instance-example}{here on GitHub}.
If you wish to just download the final image directly from Singularity
Hub, simply run \sphinxcode{\sphinxupquote{singularity pull shub://bauerm97/instance-example}}.


\subsection{Building the image}
\label{\detokenize{running_services:building-the-image}}
To begin, we need to build the image. When looking at the GitHub page of
the \sphinxcode{\sphinxupquote{url-to-pdf-api}}, we can see that it is a Node 8 server that uses headless Chromium
called \sphinxhref{https://github.com/GoogleChrome/puppeteer}{Puppeteer}. Let’s first choose a base from which to build our
container, in this case I used the docker image \sphinxcode{\sphinxupquote{node:8}} which comes
pre-installed with Node 8:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: node:8

Includecmd: no
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] Puppeteer also requires a few dependencies to be manually installed in
addition to Node 8, so we can add those into the \sphinxcode{\sphinxupquote{post}} section as well as
the installation script for the \sphinxcode{\sphinxupquote{url-to-pdf-api}}:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}post

     apt\PYGZhy{}get update

     apt\PYGZhy{}get install \PYGZhy{}yq gconf\PYGZhy{}service libasound2 libatk1.0\PYGZhy{}0 libc6 libcairo2 libcups2 \PYGZbs{}

     libdbus\PYGZhy{}1\PYGZhy{}3 libexpat1 libfontconfig1 libgcc1 libgconf\PYGZhy{}2\PYGZhy{}4 libgdk\PYGZhy{}pixbuf2.0\PYGZhy{}0 \PYGZbs{}

     libglib2.0\PYGZhy{}0 libgtk\PYGZhy{}3\PYGZhy{}0 libnspr4 libpango\PYGZhy{}1.0\PYGZhy{}0 libpangocairo\PYGZhy{}1.0\PYGZhy{}0 libstdc++6 \PYGZbs{}

     libx11\PYGZhy{}6 libx11\PYGZhy{}xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 \PYGZbs{}

     libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 ca\PYGZhy{}certificates \PYGZbs{}

     fonts\PYGZhy{}liberation libappindicator1 libnss3 lsb\PYGZhy{}release xdg\PYGZhy{}utils wget curl

     rm \PYGZhy{}r /var/lib/apt/lists/*

     cd /

     git clone https://github.com/alvarcarto/url\PYGZhy{}to\PYGZhy{}pdf\PYGZhy{}api.git pdf\PYGZus{}server

     cd pdf\PYGZus{}server

     npm install

     chmod \PYGZhy{}R 0755 .
\end{sphinxVerbatim}

And now we need to define what happens when we start an instance of the
container. In this situation, we want to run the commands that starts up
the url-to-pdf-api server:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}startscript

    cd /pdf\PYGZus{}server

    \PYGZsh{} Use nohup and /dev/null to completely detach server process from terminal

    nohup npm start \PYGZgt{} /dev/null 2\PYGZgt{}\PYGZam{}1 \PYGZlt{} /dev/null \PYGZam{}
\end{sphinxVerbatim}

Also, the \sphinxcode{\sphinxupquote{url-to-pdf-api}} server requires \sphinxcode{\sphinxupquote{environment}} some variables be set, which we can do in the
environment section:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}environment

    NODE\PYGZus{}ENV=development

    PORT=8000

    ALLOW\PYGZus{}HTTP=true

    URL=localhost

    export NODE\PYGZus{}ENV PORT ALLOW\PYGZus{}HTTP URL
\end{sphinxVerbatim}

Now we can build the definition file into an image! Simply run \sphinxcode{\sphinxupquote{build}} and the
image will be ready to go:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build url\PYGZhy{}to\PYGZhy{}pdf\PYGZhy{}api.img Singularity
\end{sphinxVerbatim}


\subsection{Running the Server}
\label{\detokenize{running_services:running-the-server}}
Now that we have an image, we are ready to start an instance and run the
server:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start url\PYGZhy{}to\PYGZhy{}pdf\PYGZhy{}api.img pdf
\end{sphinxVerbatim}

We can confirm it’s working by sending the server an http request using
curl:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} curl \PYGZhy{}o google.pdf localhost:8000/api/render?url=http://google.com

  \PYGZpc{} Total    \PYGZpc{} Received \PYGZpc{} Xferd  Average Speed   Time    Time     Time  Current

                                 Dload  Upload   Total   Spent    Left  Speed

100 51664  100 51664    0     0  12443      0  0:00:04  0:00:04 \PYGZhy{}\PYGZhy{}:\PYGZhy{}\PYGZhy{}:\PYGZhy{}\PYGZhy{} 12446
\end{sphinxVerbatim}

If you shell into the instance, you can see the running processes:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell instance://pdf

Singularity: Invoking an interactive shell within container...


Singularity pdf\PYGZus{}server.img:\PYGZti{}/bauerm97/instance\PYGZhy{}example\PYGZgt{} ps auxf

USER       PID \PYGZpc{}CPU \PYGZpc{}MEM    VSZ   RSS TTY      STAT START   TIME COMMAND

node        87  0.2  0.0  20364  3384 pts/0    S    16:16   0:00 /bin/bash \PYGZhy{}\PYGZhy{}norc

node        88  0.0  0.0  17496  2144 pts/0    R+   16:16   0:00  \PYGZbs{}\PYGZus{} ps auxf

node         1  0.0  0.0  13968  1904 ?        Ss   16:10   0:00 singularity\PYGZhy{}instance: mibauer [pdf]

node         3  0.1  0.4 997452 40364 ?        Sl   16:10   0:00 npm

node        13  0.0  0.0   4340   724 ?        S    16:10   0:00  \PYGZbs{}\PYGZus{} sh \PYGZhy{}c nodemon \PYGZhy{}\PYGZhy{}watch ./src \PYGZhy{}e j

node        14  0.0  0.4 1184492 37008 ?       Sl   16:10   0:00      \PYGZbs{}\PYGZus{} node /scif/apps/pdf\PYGZus{}server/p

node        26  0.0  0.0   4340   804 ?        S    16:10   0:00          \PYGZbs{}\PYGZus{} sh \PYGZhy{}c node src/index.js

node        27  0.2  0.5 906108 43424 ?        Sl   16:10   0:00              \PYGZbs{}\PYGZus{} node src/index.js

Singularity pdf\PYGZus{}server.img:\PYGZti{}/bauerm97/instance\PYGZhy{}example\PYGZgt{} ls

LICENSE  README.md  Singularity  out  pdf\PYGZus{}server.img

Singularity pdf\PYGZus{}server.img:\PYGZti{}/bauerm97/instance\PYGZhy{}example\PYGZgt{} exit
\end{sphinxVerbatim}


\subsection{Making it Pretty}
\label{\detokenize{running_services:making-it-pretty}}
Now that we have confirmation that the server is working, let’s make
it a little cleaner. It’s difficult to remember the exact curl command
and URL syntax each time you want to request a PDF, so let’s automate
that. To do that, we’re going to be using Standard Container
Integration Format (SCIF) apps, which are integrated directly into
singularity. If you haven’t already, check out the {\hyperref[\detokenize{reproducible_scif_apps:reproducible-scif-apps}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity app documentation}}}} to come up to
speed.

First off, we’re going to move the installation of the url-to-pdf-api
into an app, so that there is a designated spot to place output files.
To do that, we want to add a section to our definition file to build
the server:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}appinstall pdf\PYGZus{}server

    git clone https://github.com/alvarcarto/url\PYGZhy{}to\PYGZhy{}pdf\PYGZhy{}api.git pdf\PYGZus{}server

    cd pdf\PYGZus{}server

    npm install

    chmod \PYGZhy{}R 0755 .
\end{sphinxVerbatim}

And update our \sphinxcode{\sphinxupquote{startscript}} to point to the app location:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}startscript

    cd \PYGZdq{}\PYGZdl{}\PYGZob{}APPROOT\PYGZus{}pdf\PYGZus{}server\PYGZcb{}/pdf\PYGZus{}server\PYGZdq{}

    \PYGZsh{} Use nohup and /dev/null to completely detach server process from terminal

    nohup npm start \PYGZgt{} /dev/null 2\PYGZgt{}\PYGZam{}1 \PYGZlt{} /dev/null \PYGZam{}
\end{sphinxVerbatim}

Now we want to define the pdf\_client app, which we will run to send the
requests to the server:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}apprun pdf\PYGZus{}client

    if [ \PYGZhy{}z \PYGZdq{}\PYGZdl{}\PYGZob{}1:\PYGZhy{}\PYGZcb{}\PYGZdq{} ]; then

        echo \PYGZdq{}Usage: singularity run \PYGZhy{}\PYGZhy{}app pdf \PYGZlt{}instance://name\PYGZgt{} \PYGZlt{}URL\PYGZgt{} [output file]\PYGZdq{}

        exit 1

    fi

    curl \PYGZhy{}o \PYGZdq{}\PYGZdl{}\PYGZob{}SINGULARITY\PYGZus{}APPDATA\PYGZcb{}/output/\PYGZdl{}\PYGZob{}2:\PYGZhy{}output.pdf\PYGZcb{}\PYGZdq{} \PYGZdq{}\PYGZdl{}\PYGZob{}URL\PYGZcb{}:\PYGZdl{}\PYGZob{}PORT\PYGZcb{}/api/render?url=\PYGZdl{}\PYGZob{}1\PYGZcb{}\PYGZdq{}
\end{sphinxVerbatim}

As you can see, the \sphinxcode{\sphinxupquote{pdf\_client}} app checks to make sure that the user provides at
least one argument. Now that we have an output directory in the
container, we need to expose it to the host using a bind mount. Once
we’ve rebuilt the container, make a new directory callout \sphinxcode{\sphinxupquote{out}} for the
generated PDF’s to go. Now we simply start the instance like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start \PYGZhy{}B out/:/scif/data/pdf\PYGZus{}client/output/ url\PYGZhy{}to\PYGZhy{}pdf\PYGZhy{}api.img pdf
\end{sphinxVerbatim}

And to request a pdf simply do:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}app pdf\PYGZus{}client instance://pdf http://google.com google.pdf
\end{sphinxVerbatim}

And to confirm that it worked:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ls out/

google.pdf
\end{sphinxVerbatim}

When you are finished, use the instance.stop command to close all
running instances.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.stop \PYGZbs{}*
\end{sphinxVerbatim}


\section{Important Notes}
\label{\detokenize{running_services:important-notes}}

\chapter{Container Checks}
\label{\detokenize{container_checks:container-checks}}\label{\detokenize{container_checks::doc}}
New to Singularity 2.4 is the ability to run container “checks” on
demand. Checks can be anything from a filter for sensitive
information, to an analysis of installed binaries. A few default checks are installed with Singularity and others can be added by the
administrator. Users can perform checks at build time or on demand:
Perform all default checks, these are the same

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity check ubuntu.img

\PYGZdl{} singularity check \PYGZhy{}\PYGZhy{}tag default ubuntu.img
\end{sphinxVerbatim}

Perform checks with tag “clean”

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity check \PYGZhy{}\PYGZhy{}tag clean ubuntu.img
\end{sphinxVerbatim}


\section{Tags and Organization}
\label{\detokenize{container_checks:tags-and-organization}}
Currently, checks are organized by tag and security level. If you know a
specific tag that you want to use, for example “docker” deploys checks
for containers with Docker imported layers, you can specify the tag:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
USAGE

    \PYGZhy{}t/\PYGZhy{}\PYGZhy{}tag       tag to filter checks. default is \PYGZdq{}default\PYGZdq{}

                      Available: default, security, docker, clean


EXAMPLE

\PYGZdl{} singularity check \PYGZhy{}\PYGZhy{}tag docker ubuntu.img
\end{sphinxVerbatim}

If you want to run checks associated with a different security level,
you can specify with \sphinxcode{\sphinxupquote{-{-}low}} , \sphinxcode{\sphinxupquote{-{-}med}} , or \sphinxcode{\sphinxupquote{-{-}high}} :

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
USAGE: singularity [...] check [exec options...] \PYGZlt{}container path\PYGZgt{}

This command will run security checks for an image.

Note that some checks require sudo.


    \PYGZhy{}l/\PYGZhy{}\PYGZhy{}low       Specify low threshold (all checks, default)

    \PYGZhy{}m/\PYGZhy{}\PYGZhy{}med       Perform medium and high checks

    \PYGZhy{}h/\PYGZhy{}\PYGZhy{}high      Perform only checks at level high
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
Note that some checks will require sudo, and you will be alerted if this
is the case and you didn’t use it. Finally, if you want to run all
default checks, just don’t specify a tag or level.
\end{sphinxadmonition}


\section{What checks are available?}
\label{\detokenize{container_checks:what-checks-are-available}}
Currently, you can view all installable checks
\sphinxhref{https://github.com/singularityware/singularity/blob/development/libexec/helpers/check.sh\#L49}{here},
and we anticipate adding an ability to view tags that are available,
along with your own custom checks. You should also ask your
administration if new checks have been added not supported by
Singularity. If you want to request adding a new check, please \sphinxhref{https://github.com/singularityware/singularity/issues}{tell
us!}.


\chapter{Environment and Metadata}
\label{\detokenize{environment_and_metadata:environment-and-metadata}}\label{\detokenize{environment_and_metadata:id1}}\label{\detokenize{environment_and_metadata::doc}}\phantomsection\label{\detokenize{environment_and_metadata:sec-envandmetadata}}
Singularity containers support environment variables and labels that you
can add to your container during the build process. This page details
general information about defining environments and labels. If you are looking for specific environment variables for build time, see build
environment.


\section{Environment}
\label{\detokenize{environment_and_metadata:environment}}
If you build a container from Singularity Hub or Docker Hub, the
environment will be included with the container at build time. You can
also define custom environment variables in your Recipe file like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: shub

From: vsoch/hello\PYGZhy{}world


\PYGZpc{}environment

    VARIABLE\PYGZus{}NAME=VARIABLE\PYGZus{}VALUE

    export VARIABLE\PYGZus{}NAME
\end{sphinxVerbatim}

You may need to add environment variables to your container during the
\sphinxcode{\sphinxupquote{\%post}} section. For instance, maybe you will not know the appropriate
value of a variable until you have installed some software.
To add variables to the environment during \sphinxcode{\sphinxupquote{\%post}} you can use the
\sphinxcode{\sphinxupquote{\$SINGULARITY\_ENVIRONMENT}} variable with the following syntax:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}post

    echo \PYGZsq{}export VARIABLE\PYGZus{}NAME=VARIABLE\PYGZus{}VALUE\PYGZsq{} \PYGZgt{}\PYGZgt{}\PYGZdl{}SINGULARITY\PYGZus{}ENVIRONMENT
\end{sphinxVerbatim}

Text in the \sphinxcode{\sphinxupquote{\%environment}} section will be appended to the file \sphinxcode{\sphinxupquote{/.singularity.d/env/90-environment.sh}} while text redirected
to \sphinxcode{\sphinxupquote{\$SINGULARITY\_ENVIRONMENT}} will end up in the file /.singularity.d/env/91-environment.sh.

Because files in \sphinxcode{\sphinxupquote{/.singularity.d/env}} are sourced in alpha-numerical order, this means that
variables added using \sphinxcode{\sphinxupquote{\$SINGULARITY\_ENVIRONMENT}} take precedence over those added via the \sphinxcode{\sphinxupquote{\%environment}}
section.

Need to define a variable at runtime? You can set variables inside the
container by prefixing them with \sphinxcode{\sphinxupquote{SINGULARITYENV\_}}. They will be
transposed automatically and the prefix will be stripped. For example,
let’s say we want to set the variable \sphinxcode{\sphinxupquote{HELLO}} to have value \sphinxcode{\sphinxupquote{WORLD}}. We can do that
as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} SINGULARITYENV\PYGZus{}HELLO=WORLD singularity exec \PYGZhy{}\PYGZhy{}cleanenv centos7.img env

HELLO=WORLD

LD\PYGZus{}LIBRARY\PYGZus{}PATH=:/usr/local/lib:/usr/local/lib64

SINGULARITY\PYGZus{}NAME=test.img

PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

PWD=/home/gmk/git/singularity

LANG=en\PYGZus{}US.UTF\PYGZhy{}8

SHLVL=0

SINGULARITY\PYGZus{}INIT=1

SINGULARITY\PYGZus{}CONTAINER=test.img
\end{sphinxVerbatim}

Notice the \sphinxcode{\sphinxupquote{-{-}cleanenv}} in the example above? That argument specifies that we want
to remove the host environment from the container. If we remove the \sphinxcode{\sphinxupquote{-{-}cleanenv}},
we will still pass forward \sphinxcode{\sphinxupquote{HELLO=WORLD}}, and the list shown above, but we will
also pass forward all the other environment variables from the host.

If you need to change the \$PATH of your container at runtime there are
a few environmental variables you can use:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SINGULARITYENV\_PREPEND\_PATH=/good/stuff/at/beginning}} to prepend directories to the beginning of the

\item {} 
\sphinxcode{\sphinxupquote{SINGULARITYENV\_APPEND\_PATH=/good/stuff/at/end}} to append directories to the end of the

\item {} 
\sphinxcode{\sphinxupquote{SINGULARITYENV\_PATH=/a/new/path}} to override the \sphinxcode{\sphinxupquote{\$PATH}} within the container

\end{itemize}


\section{Labels}
\label{\detokenize{environment_and_metadata:labels}}
Your container stores metadata about it’s build, along with Docker
labels, and custom labels that you define during build in a \sphinxcode{\sphinxupquote{\%labels}} section.

For containers that are generated with Singularity version 2.4 and
later, labels are represented using the \sphinxhref{http://label-schema.org/rc1/}{rc1 Label Schema}. For
example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect dino.img

\PYGZob{}

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.deffile.bootstrap\PYGZdq{}: \PYGZdq{}docker\PYGZdq{},

    \PYGZdq{}MAINTAINER\PYGZdq{}: \PYGZdq{}Vanessasaurus\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.deffile\PYGZdq{}: \PYGZdq{}Singularity.help\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage\PYGZdq{}: \PYGZdq{}/.singularity.d/runscript.help\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.schema\PYGZhy{}version\PYGZdq{}: \PYGZdq{}1.0\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.deffile.from\PYGZdq{}: \PYGZdq{}ubuntu:latest\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.build\PYGZhy{}date\PYGZdq{}: \PYGZdq{}2017\PYGZhy{}07\PYGZhy{}28T22:59:17\PYGZhy{}04:00\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.runscript.help\PYGZdq{}: \PYGZdq{}/.singularity.d/runscript.help\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.usage.singularity.version\PYGZdq{}: \PYGZdq{}2.3.1\PYGZhy{}add/label\PYGZhy{}schema.g00f040f\PYGZdq{},

    \PYGZdq{}org.label\PYGZhy{}schema.build\PYGZhy{}size\PYGZdq{}: \PYGZdq{}715MB\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}

You will notice that the one label doesn’t belong to the label schema, \sphinxcode{\sphinxupquote{MAINTAINER}} .
This was a user provided label during bootstrap. Finally, for
Singularity versions \textgreater{}= 2.4, the image build size is added as a label, \sphinxcode{\sphinxupquote{org.label-schema.build-size}},
and the label schema is used throughout. For versions earlier than 2.4,
containers did not use the label schema, and looked like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity exec centos7.img cat /.singularity.d/labels.json

\PYGZob{} \PYGZdq{}name\PYGZdq{}:

      \PYGZdq{}CentOS Base Image\PYGZdq{},

       \PYGZdq{}build\PYGZhy{}date\PYGZdq{}: \PYGZdq{}20170315\PYGZdq{},

       \PYGZdq{}vendor\PYGZdq{}: \PYGZdq{}CentOS\PYGZdq{},

       \PYGZdq{}license\PYGZdq{}: \PYGZdq{}GPLv2\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}

You can add custom labels to your container in a bootstrap file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu: latest



\PYGZpc{}labels

AUTHOR Vanessasaur
\end{sphinxVerbatim}

The \sphinxcode{\sphinxupquote{inspect}} command is useful for viewing labels and other container meta-data.


\section{Container Metadata}
\label{\detokenize{environment_and_metadata:container-metadata}}
Inside of the container, metadata is stored in the \sphinxcode{\sphinxupquote{/.singularity.d}} directory. You
probably shouldn’t edit any of these files directly but it may be
helpful to know where they are and what they do:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/.singularity.d/


├── actions

│   ├── exec

│   ├── run

│   ├── shell

│   ├── start

│   └── test

├── env

│   ├── 01\PYGZhy{}base.sh

│   ├── 90\PYGZhy{}environment.sh

│   ├── 95\PYGZhy{}apps.sh

│   └── 99\PYGZhy{}base.sh

├── labels.json

├── libs

├── runscript

├── Singularity

└── startscript
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{actions}: This directory contains helper scripts to allow the
container to carry out the action commands.

\item {} 
\sphinxstylestrong{env}: All *.sh files in this directory are sourced in
alpha-numeric order when the container is initiated. For legacy
purposes there is a symbolic link called \sphinxcode{\sphinxupquote{/environment}} that points to \sphinxcode{\sphinxupquote{/.singularity.d/env/90-environment.sh}}.

\item {} 
\sphinxstylestrong{labels.json}: The json file that stores a containers labels
described above.

\item {} 
\sphinxstylestrong{libs}: At runtime the user may request some host-system libraries
to be mapped into the container (with the \sphinxcode{\sphinxupquote{-{-}nv}} option for example). If so,
this is their destination.

\item {} 
\sphinxstylestrong{runscript}: The commands in this file will be executed when the
container is invoked with the \sphinxcode{\sphinxupquote{run}} command or called as an executable. For
legacy purposes there is a symbolic link called \sphinxcode{\sphinxupquote{/singularity}} that points to this
file

\item {} 
\sphinxstylestrong{Singularity}: This is the Recipe file that was used to generate
the container. If more than 1 Recipe file was used to generate the
container additional Singularity files will appear in numeric order
in a sub-directory called \sphinxcode{\sphinxupquote{bootstrap\_history}}

\item {} 
\sphinxstylestrong{startscript}: The commands in this file will be executed when the
container is invoked with the \sphinxcode{\sphinxupquote{instance.start}} command.

\end{itemize}


\chapter{Reproducible SCI-F Apps}
\label{\detokenize{reproducible_scif_apps:reproducible-sci-f-apps}}\label{\detokenize{reproducible_scif_apps:reproducible-scif-apps}}\label{\detokenize{reproducible_scif_apps::doc}}

\section{Why do we need SCI-F?}
\label{\detokenize{reproducible_scif_apps:why-do-we-need-sci-f}}\label{\detokenize{reproducible_scif_apps:sec-scifapps}}
The Scientific Filesystem (SCIF) provides internal modularity of
containers, and it makes it easy for the creator to give the container
implied metadata about software. For example, installing a set of
libraries, defining environment variables, or adding labels that
belong to app \sphinxcode{\sphinxupquote{foo}} makes a strong assertion that those dependencies belong
to \sphinxcode{\sphinxupquote{foo}} . When I run foo, I can be confident that the container is running
in this context, meaning with \sphinxcode{\sphinxupquote{foo's}} custom environment, and with \sphinxcode{\sphinxupquote{foo's}} libraries
and executables on the path. This is drastically different from
serving many executables in a single container, because there is no
way to know which are associated with which of the container’s
intended functions. This documentation will walk through some
rationale, background, and examples of the SCIF integration for
Singularity containers. For other examples (and a client that works
across container technologies) see the the \sphinxhref{https://sci-f.github.io/}{scientific filesystem}.
This page will primarily cover the native Singularity SCIF integration.

To start, let’s take a look at this series of steps to install
dependencies for software foo and bar.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}post


\PYGZsh{} install dependencies 1

\PYGZsh{} install software A (foo)

\PYGZsh{} install software B (bar)

\PYGZsh{} install software C (foo)

\PYGZsh{} install software D (bar)
\end{sphinxVerbatim}

The creator may know that A and C were installed for \sphinxcode{\sphinxupquote{foo}} and B and D for \sphinxcode{\sphinxupquote{bar}} ,
but down the road, when someone discovers the container, if they can
find the software at all, the intention of the container creator would
be lost. As many are now, containers without any form of internal
organization and predictability are black boxes. We don’t know if some
software installed to \sphinxcode{\sphinxupquote{/opt}} , or to  \sphinxcode{\sphinxupquote{/usr/local/bin}} , or to their custom favorite folder \sphinxcode{\sphinxupquote{/code}} . We
could assume that the creator added important software to the path and
look in these locations, but that approach is still akin to fishing in a
swamp. We might only hope that the container’s main function, the
Singularity runscript, is enough to make the container perform as
intended.


\subsection{Mixed up Modules}
\label{\detokenize{reproducible_scif_apps:mixed-up-modules}}
\begin{DUlineblock}{0em}
\item[] If your container truly runs one script, the traditional model of a
runscript fits well. Even in the case of having two functions like \sphinxcode{\sphinxupquote{foo}} and \sphinxcode{\sphinxupquote{bar}}
you probably have something like this.
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}runscript

if some logic to choose foo:

   check arguments for foo

   run foo

else if some logic to choose bar:

   run bar
\end{sphinxVerbatim}

and maybe your environment looks like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}environment

    BEST\PYGZus{}GUY=foo

    export BEST\PYGZus{}GUY
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] but what if you run into this issue, with foo and bar?
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}environment

    BEST\PYGZus{}GUY=foo

    BEST\PYGZus{}GUY=bar

    export BEST\PYGZus{}GUY
\end{sphinxVerbatim}

You obviously can’t have them at separate times. You’d have to source
some custom environment file (that you make on your own) and it gets
hard easily with issues of using shell and sourcing. We don’t know who
the best guy is! You probably get the general idea. Without internal
organization and modularity:
\begin{itemize}
\item {} 
You have to do a lot of manual work to expose the different software
to the user via a custom runscript (and be a generally decent
programmer).

\item {} 
All software must share the same metadata, environment, and labels.

\end{itemize}

Under these conditions, containers are at best black boxes with unclear
delineation between software provided, and only one context for running
anything. The container creator shouldn’t need to spend inordinate
amounts of time writing custom runscripts to support multiple functions
and inputs. Each of \sphinxcode{\sphinxupquote{foo}} and \sphinxcode{\sphinxupquote{bar}} should be easy to define, and have its own
runscript, environment, labels, tests and help section.


\subsection{Container Transparency}
\label{\detokenize{reproducible_scif_apps:container-transparency}}
SCI-F Apps make \sphinxcode{\sphinxupquote{foo}} and \sphinxcode{\sphinxupquote{bar}} transparent, and solve this problem of mixed up
modules. Our simple issue of mixed up modules could be solved if we
could do this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap:docker

From: ubuntu:16.04


\PYGZpc{}appenv foo

    BEST\PYGZus{}GUY=foo

    export BEST\PYGZus{}GUY


\PYGZpc{}appenv bar

    BEST\PYGZus{}GUY=bar

    export BEST\PYGZus{}GUY


\PYGZpc{}apprun foo

    echo The best guy is \PYGZdl{}BEST\PYGZus{}GUY


\PYGZpc{}apprun bar

    echo The best guy is \PYGZdl{}BEST\PYGZus{}GUY
\end{sphinxVerbatim}

Generate the container

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build foobar.simg Singularity
\end{sphinxVerbatim}

and run it in the context of \sphinxcode{\sphinxupquote{foo}} and then \sphinxcode{\sphinxupquote{bar}}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}app bar foobar.simg

The best guy is bar

\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}app foo foobar.simg

The best guy is foo
\end{sphinxVerbatim}

Using SCI-F apps, a user can easily discover both \sphinxcode{\sphinxupquote{foo}} and \sphinxcode{\sphinxupquote{bar}} without knowing
anything about the container:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity apps foobar.simg

bar

foo
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] and inspect each one:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity inspect \PYGZhy{}\PYGZhy{}app foo  foobar.simg

\PYGZob{}

    \PYGZdq{}SCIF\PYGZus{}APP\PYGZus{}NAME\PYGZdq{}: \PYGZdq{}foo\PYGZdq{},

    \PYGZdq{}SCIF\PYGZus{}APP\PYGZus{}SIZE\PYGZdq{}: \PYGZdq{}1MB\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}


\subsection{Container Modularity}
\label{\detokenize{reproducible_scif_apps:container-modularity}}
What is going on, under the hood? Just a simple, clean organization that
is tied to a set of sections in the build recipe relevant to each app.
For example, I can specify custom install procedures (and they are
relevant to each app’s specific base defined under \sphinxcode{\sphinxupquote{/scif/apps}}), labels, tests, and
help sections. Before I tell you about the sections, I’ll briefly show
you what the organization looks like, for each app:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/scif/apps/


     foo/

        bin/

        lib/

        scif/

            runscript.help

            runscript

            env/

                01\PYGZhy{}base.sh

                90\PYGZhy{}environment.sh


     bar/

     ....
\end{sphinxVerbatim}

If you are familiar with Singularity, the above will look very familiar.
It mirrors the Singularity (main container) metadata folder, except
instead of \sphinxcode{\sphinxupquote{.singularity.d}} we have \sphinxcode{\sphinxupquote{scif}}. The name and base \sphinxcode{\sphinxupquote{scif}} is chosen intentionally to be
something short, and likely to be unique. On the level of organization
and metadata, these internal apps are like little containers! Are you
worried that you need to remember all this path nonsense? Don’t worry,
you don’t. You can just use environment variables in your runscripts,
etc. Here we are looking at the environment active for lolcat:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity exec \PYGZhy{}\PYGZhy{}app foo foobar.simg env \textbar{} grep foo
\end{sphinxVerbatim}

Let’s talk about the output of the above in sections, you will notice
some interesting things! First, notice that the app’s \sphinxcode{\sphinxupquote{bin}} has been added to
the path, and its \sphinxcode{\sphinxupquote{lib}} added to the \sphinxcode{\sphinxupquote{LD\_LIBRARY\_PATH}} . This means that anything you drop in
either will automatically be added. You don’t need to make these folders
either, they are created for you.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
LD\PYGZus{}LIBRARY\PYGZus{}PATH=/scif/apps/foo/lib::/.singularity.d/libs

PATH=/scif/apps/foo/bin:/scif/apps/foo:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
\end{sphinxVerbatim}

Next, notice that we have environment variables relevant to the active
app’s (foo) data and metadata. They look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
SCIF\PYGZus{}APPOUTPUT=/scif/data/foo/output

SCIF\PYGZus{}APPDATA=/scif/data/foo

SCIF\PYGZus{}APPINPUT=/scif/data/foo/input

SCIF\PYGZus{}APPMETA=/scif/apps/foo/scif

SCIF\PYGZus{}APPROOT=/scif/apps/foo

SCIF\PYGZus{}APPNAME=foo
\end{sphinxVerbatim}

We also have foo’s environment variables defined under \sphinxcode{\sphinxupquote{\%appenv foo}} , and
importantly, we don’t see bar’s.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
BEST\PYGZus{}GUY=foo
\end{sphinxVerbatim}

Also provided are more global paths for data and apps:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
SCIF\PYGZus{}APPS=/scif/apps

SCIF\PYGZus{}DATA=/scif/data
\end{sphinxVerbatim}

Importantly, each app has its own modular location. When you do an \sphinxcode{\sphinxupquote{\%appinstall foo}},
the commands are all done in context of that base. The bin and lib are
also automatically generated. So what would be a super simple app?

Just add a script and name it:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}appfiles foo

    runfoo.sh   bin/runfoo.sh
\end{sphinxVerbatim}

and then maybe for install I’d make it executable

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}appinstall foo

    chmod u+x bin/runfoo.sh
\end{sphinxVerbatim}

You don’t even need files! You could just do this.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}appinstall foo

    echo \PYGZsq{}echo \PYGZdq{}Hello Foo.\PYGZdq{}\PYGZsq{} \PYGZgt{}\PYGZgt{} bin/runfoo.sh

    chmod u+x bin/runfoo.sh
\end{sphinxVerbatim}

We can summarize these observations about using apps:
\begin{itemize}
\item {} 
the specific environment (\sphinxcode{\sphinxupquote{\%appenv\_foo}}) is active because \sphinxcode{\sphinxupquote{BEST\_APP}} is foo

\item {} 
the lib folder in foo’s base is added to the LD\_LIBRARY\_PATH

\item {} 
the bin folder is added to the path

\item {} 
locations for input, output, and general data are exposed. It’s up to
you how you use these, but you can predictably know that a well made
app will look for inputs and outputs in its specific folder.

\item {} 
environment variables are provided for the app’s root, its data, and
its name

\end{itemize}


\subsection{Sections}
\label{\detokenize{reproducible_scif_apps:sections}}
Finding the section \sphinxcode{\sphinxupquote{\%appinstall}} , \sphinxcode{\sphinxupquote{\%apphelp}} , or \sphinxcode{\sphinxupquote{\%apprun}} is indication of an application command.
The following string is parsed as the name of the application, and
this folder is created, in lowercase, under \sphinxcode{\sphinxupquote{/scif/apps}} if it doesn’t exist. A
singularity metadata folder, .singularity.d, equivalent to the
container’s main folder, is generated inside the application. An
application thus is like a smaller image inside of its parent.
Specifically, SCI-F defines the following new sections for the build
recipe, where each is optional for 0 or more apps:

\sphinxstylestrong{\%appinstall} corresponds to executing commands within the folder to
install the application. These commands would previously belong in
\%post, but are now attributable to the application.

\sphinxstylestrong{\%apphelp} is written as a file called runscript.help in the
application’s metadata folder, where the Singularity software knows
where to find it. If no help section is provided, the software simply
will alert the user and show the files provided for inspection.

\sphinxstylestrong{\%apprun} is also written as a file called runscript.exec in the
application’s metadata folder, and again looked for when the user asks
to run the software. If not found, the container should default to
shelling into that location.

\sphinxstylestrong{\%applabels} will write a labels.json in the application’s metadata
folder, allowing for application specific labels.

\sphinxstylestrong{\%appenv} will write an environment file in the application’s base
folder, allowing for definition of application specific environment
variables.

\sphinxstylestrong{\%apptest} will run tests specific to the application, with present
working directory assumed to be the software module’s folder

\sphinxstylestrong{\%appfiles} will add files to the app’s base at \sphinxcode{\sphinxupquote{/scif/apps/\textless{}app\textgreater{}}}


\subsection{Interaction}
\label{\detokenize{reproducible_scif_apps:interaction}}
I didn’t show you the complete output of a \sphinxcode{\sphinxupquote{grep}} to the environment when
running foo in the first example - because the remainder of variables
are more fit for a discussion about app interaction. Essentially, when
any app is active, we also have named variable that can explicitly
reference the environment file, labels file, runscript, \sphinxcode{\sphinxupquote{lib}} and \sphinxcode{\sphinxupquote{bin}} folders for
all app’s in the container. For our above Singularity Recipe, we would
also find:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
SCIF\PYGZus{}APPDATA\PYGZus{}bar=/scif/data/bar

SCIF\PYGZus{}APPRUN\PYGZus{}bar=/scif/apps/bar/scif/runscript

SCIF\PYGZus{}APPROOT\PYGZus{}bar=/scif/apps/bar

SCIF\PYGZus{}APPLIB\PYGZus{}bar=/scif/apps/bar/lib

SCIF\PYGZus{}APPMETA\PYGZus{}bar=/scif/apps/bar/scif

SCIF\PYGZus{}APPBIN\PYGZus{}bar=/scif/apps/bar/bin

SCIF\PYGZus{}APPENV\PYGZus{}bar=/scif/apps/bar/scif/env/90\PYGZhy{}environment.sh

SCIF\PYGZus{}APPLABELS\PYGZus{}bar=/scif/apps/bar/scif/labels.json


SCIF\PYGZus{}APPENV\PYGZus{}foo=/scif/apps/foo/scif/env/90\PYGZhy{}environment.sh

SCIF\PYGZus{}APPLABELS\PYGZus{}foo=/scif/apps/foo/scif/labels.json

SCIF\PYGZus{}APPDATA\PYGZus{}foo=/scif/data/foo

SCIF\PYGZus{}APPRUN\PYGZus{}foo=/scif/apps/foo/scif/runscript

SCIF\PYGZus{}APPROOT\PYGZus{}foo=/scif/apps/foo

SCIF\PYGZus{}APPLIB\PYGZus{}foo=/scif/apps/foo/lib

SCIF\PYGZus{}APPMETA\PYGZus{}foo=/scif/apps/foo/scif

SCIF\PYGZus{}APPBIN\PYGZus{}foo=/scif/apps/foo/bin
\end{sphinxVerbatim}

This is really great because it means that we can have apps interact
with one another internally. For example, let’s modify the recipe a bit:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap:docker

From: ubuntu:16.04


\PYGZpc{}appenv cow

    ANIMAL=COW

    NOISE=moo

    export ANIMAL NOISE


\PYGZpc{}appenv bird

    NOISE=tweet

    ANIMAL=BIRD

    export ANIMAL


\PYGZpc{}apprun moo

    echo The \PYGZdl{}\PYGZob{}ANIMAL\PYGZcb{} goes \PYGZdl{}\PYGZob{}NOISE\PYGZcb{}


\PYGZpc{}appenv moo

    . \PYGZdl{}\PYGZob{}APPENV\PYGZus{}cow\PYGZcb{}
\end{sphinxVerbatim}

In the above example, we have three apps. One for a cow, one for a bird,
and a third that depends on the cow. We can’t define global functions or
environment variables (in \sphinxcode{\sphinxupquote{\%post}} or  \sphinxcode{\sphinxupquote{/environment}} , respectively) because they would
interfere with the third app, bird, that has equivalently named
variables. What we do then, is source the environment for “cow” in the
environment for “moo” and the result is what we would want:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}app moo /tmp/one.simg

The COW goes moo
\end{sphinxVerbatim}

The same is true for each of the labels, environment, runscript, bin,
and lib. The following variables are available to you, for each app in
the container, whenever any app is being run:
\begin{itemize}
\item {} 
\sphinxstylestrong{SCIF\_APPBIN\_}: the path to the bin folder, if you want to add
an app that isn’t active to your ‘PATH‘

\item {} 
\sphinxstylestrong{SCIF\_APPLIB\_}: the path to the lib folder, if you want to add
an app that isn’t active to your ‘LD\_LIBRARY\_PATH‘

\item {} 
\sphinxstylestrong{SCIF\_APPRUN\_}: the app’s runscript (so you can call it from
elsewhere)

\item {} 
\sphinxstylestrong{SCIF\_APPMETA\_}: the path to the metadata folder for the app

\item {} 
\sphinxstylestrong{SCIF\_APPENV\_}: the path to the primary environment file (for
sourcing) if it exists

\item {} 
\sphinxstylestrong{SCIF\_APPROOT\_}: the app’s install folder

\item {} 
\sphinxstylestrong{SCIF\_APPDATA\_}: the app’s data folder

\item {} 
\sphinxstylestrong{SCIF\_APPLABELS\_}: The path to the label.json in the metadata
folder, if it exists

\end{itemize}

Singularity containers are already reproducible in that they package
dependencies. This basic format adds to that by making the software
inside of them modular, predictable, and programmatically accessible. We
can say confidently that some set of steps, labels, or variables in the
runscript is associated with a particular action of the container. We
can better reveal how dependencies relate to each step in a scientific
workflow. Making containers is not easy. When a scientist starts to
write a recipe for his set of tools, he probably doesn’t know where to
put it, perhaps that a help file should exist, or that metadata about
the software should be served by the container. If container generation
software made it easy to organize and capture container content
automatically, we would easily meet these goals of internal modularity
and consistency, and generate containers that easily integrate with
external hosts, data, and other containers. These are essential
components for (ultimately) optimizing the way we develop, understand,
and execute our scientific containers.


\section{Cowsay Container}
\label{\detokenize{reproducible_scif_apps:cowsay-container}}
Now let’s go through the tutorial to build our {\hyperref[\detokenize{reproducible_scif_apps:cowsay-container}]{\sphinxcrossref{cowsay container}}}.

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxstylestrong{Important!} This tutorial is for Singularity 2.4.
\end{sphinxadmonition}
\begin{description}
\item[{When you’ve installed 2.4, download the recipe, and save it to your}] \leavevmode
present working directory. By the way, credit for anything and
everything lolcat and cowsay goes to \sphinxhref{https://www.github.com/GodLoveD}{GodLoveD}! Here is the recipe:

\end{description}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
wget https://raw.githubusercontent.com/singularityware/singularity/master/examples/apps/Singularity.cowsay

sudo singularity build moo.simg Singularity.cowsay
\end{sphinxVerbatim}

What apps are installed?

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity apps moo.simg

cowsay

fortune

lolcat
\end{sphinxVerbatim}

Ask for help for a specific app!

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity help \PYGZhy{}\PYGZhy{}app fortune moo.simg

fortune is the best app
\end{sphinxVerbatim}

Ask for help for all apps, without knowing in advance what they are:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
for app in \PYGZdl{}(singularity apps moo.simg)

   do

     singularity help \PYGZhy{}\PYGZhy{}app \PYGZdl{}app moo.simg

done

cowsay is the best app

fortune is the best app

lolcat is the best app
\end{sphinxVerbatim}

Run a particular app

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity run \PYGZhy{}\PYGZhy{}app fortune moo.simg

    My dear People.

    My dear Bagginses and Boffins, and my dear Tooks and Brandybucks,

and Grubbs, and Chubbs, and Burrowses, and Hornblowers, and Bolgers,

Bracegirdles, Goodbodies, Brockhouses and Proudfoots.  Also my good

Sackville Bagginses that I welcome back at last to Bag End.  Today is my

one hundred and eleventh birthday: I am eleventy\PYGZhy{}one today!\PYGZdq{}

        \PYGZhy{}\PYGZhy{} J. R. R. Tolkien
\end{sphinxVerbatim}

Advanced running - pipe the output of fortune into lolcat, and make a
fortune that is beautifully colored!

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity run \PYGZhy{}\PYGZhy{}app fortune moo.simg \textbar{} singularity run \PYGZhy{}\PYGZhy{}app lolcat moo.simg

You will be surrounded by luxury.
\end{sphinxVerbatim}

This one might be easier to see - pipe the same fortune into the cowsay
app:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity run \PYGZhy{}\PYGZhy{}app fortune moo.simg \textbar{} singularity run \PYGZhy{}\PYGZhy{}app cowsay moo.simg

 \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

/ Executive ability is prominent in your \PYGZbs{}

\PYGZbs{} make\PYGZhy{}up.                               /

 \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

        \PYGZbs{}   \PYGZca{}\PYGZus{}\PYGZus{}\PYGZca{}

         \PYGZbs{}  (oo)\PYGZbs{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

            (\PYGZus{}\PYGZus{})\PYGZbs{}       )\PYGZbs{}/\PYGZbs{}

                \textbar{}\textbar{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}w \textbar{}

                \textbar{}\textbar{}     \textbar{}\textbar{}
\end{sphinxVerbatim}

and the final shabang - do the same, but make it colored. Let’s even get
lazy and use an environment variable for the command:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
CMD=\PYGZdq{}singularity run \PYGZhy{}\PYGZhy{}app\PYGZdq{}

\PYGZdl{}CMD fortune moo.simg \textbar{} \PYGZdl{}CMD cowsay moo.simg \textbar{} \PYGZdl{}CMD lolcat moo.simg

 \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

/ Ships are safe in harbor, but they were \PYGZbs{}

\PYGZbs{} never meant to stay there.              /

 \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

        \PYGZbs{}   \PYGZca{}\PYGZus{}\PYGZus{}\PYGZca{}

         \PYGZbs{}  (oo)\PYGZbs{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

            (\PYGZus{}\PYGZus{})\PYGZbs{}       )\PYGZbs{}/\PYGZbs{}

                \textbar{}\textbar{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}w \textbar{}

                \textbar{}\textbar{}     \textbar{}\textbar{}
\end{sphinxVerbatim}

Yes, you need to watch the asciinema to see the colors. Finally, inspect
an app:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity inspect \PYGZhy{}\PYGZhy{}app fortune moo.simg

\PYGZob{}

    \PYGZdq{}SCIF\PYGZus{}APP\PYGZus{}NAME\PYGZdq{}: \PYGZdq{}fortune\PYGZdq{},

    \PYGZdq{}SCIF\PYGZus{}APP\PYGZus{}SIZE\PYGZdq{}: \PYGZdq{}1MB\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}

If you want to see the full specification or create your own
Scientific Filesystem integration (doesn’t have to be Singularity, or
Docker, or containers!) see the \sphinxhref{https://sci-f.github.io/}{full documentation}.

If you haven’t yet, \sphinxhref{https://asciinema.org/a/139153?speed=3}{take a look at these examples} with the
asciinema!


\chapter{Singularity and Docker}
\label{\detokenize{singularity_and_docker:singularity-and-docker}}\label{\detokenize{singularity_and_docker:id1}}\label{\detokenize{singularity_and_docker::doc}}
Singularity is good friends with Docker. The reason is because the
developers use and really like using Docker, and scientists have already
put much resources into creating Docker images. Thus, one of our early goals was to support Docker. What can you do?
\begin{itemize}
\item {} 
You don’t need Docker installed

\item {} 
You can shell into a Singularity-ized Docker image

\item {} 
You can run a Docker image instantly as a Singularity image

\item {} 
You can pull a Docker image (without sudo)

\item {} 
You can build images with bases from assembled Docker layers that
include environment, guts, and labels

\end{itemize}


\section{TLDR (Too Long Didn’t Read)}
\label{\detokenize{singularity_and_docker:tldr-too-long-didnt-read}}
You can shell, import, run, and exec.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity shell docker://ubuntu:latest

singularity run docker://ubuntu:latest

singularity exec docker://ubuntu:latest echo \PYGZdq{}Hello Dinosaur!\PYGZdq{}


singularity pull docker://ubuntu:latest

singularity build ubuntu.img docker://ubuntu:latest
\end{sphinxVerbatim}


\section{Import a Docker image into a Singularity Image}
\label{\detokenize{singularity_and_docker:import-a-docker-image-into-a-singularity-image}}
The core of a Docker image is basically a compressed set of files, a set
of \sphinxcode{\sphinxupquote{.tar.gz}} that (if you look in your \sphinxhref{http://stackoverflow.com/questions/19234831/where-are-docker-images-stored-on-the-host-machine}{Docker image folder} on your host
machine, you will see. The Docker Registry, which you probably interact
with via \sphinxhref{https://hub.docker.com/}{Docker Hub}, serves these layers. These are the layers that
you see downloading when you interact with the docker daemon. We are
going to use these same layers for Singularity!


\section{Quick Start: The Docker Registry}
\label{\detokenize{singularity_and_docker:quick-start-the-docker-registry}}
The Docker engine communicates with the Docker Hub via the \sphinxhref{https://docs.docker.com/engine/reference/api/docker\_remote\_api/}{Docker
Remote API}, and guess what, we can too! The easiest thing to do is
create an image, and then pipe a Docker image directly into it from
the Docker Registry. You don’t need Docker installed on your machine,
but you will need a working internet connection. Let’s create an
ubuntu operating system, from Docker. We will pull, then build:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull docker://ubuntu

WARNING: pull for Docker Hub is not guaranteed to produce the

WARNING: same image on repeated pull. Use Singularity Registry

WARNING: (shub://) to pull exactly equivalent images.

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /home/vanessa/.singularity/docker

[5/5] \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Importing: base Singularity environment

Importing: /home/vanessa/.singularity/docker/sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:3b61febd4aefe982e0cb9c696d415137384d1a01052b50a85aae46439e15e49a.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:9d99b9777eb02b8943c0e72d7a7baec5c782f8fd976825c9d3fb48b3101aacc2.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:d010c8cf75d7eb5d2504d5ffa0d19696e8d745a457dd8d28ec6dd41d3763617e.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:7fac07fb303e0589b9c23e6f49d5dc1ff9d6f3c8c88cabe768b430bdb47f03a9.tar.gz

Importing: /home/vanessa/.singularity/metadata/sha256:77cece4ce6ef220f66747bb02205a00d9ca5ad0c0a6eea1760d34c744ef7b231.tar.gz

WARNING: Building container as an unprivileged user. If you run this container as root

WARNING: it may be missing some functionality.

Building Singularity image...

Cleaning up...

Singularity container built: ./ubuntu.img
\end{sphinxVerbatim}

The warnings mean well - it is to tell you that you are creating the
image on the fly from layers, and if one of those layers changes, you
won’t produce the same image next time.


\section{The Build Specification file, Singularity}
\label{\detokenize{singularity_and_docker:the-build-specification-file-singularity}}
Just like Docker has the Dockerfile, Singularity has a file called
Singularity that (currently) applications like Singularity Hub know to
sniff for. For reproducibility of your containers, our strong
recommendation is that you build from these files. Any command that you
issue to change a container sandbox (building with \sphinxcode{\sphinxupquote{-{-}sandbox}} ) or to a build with \sphinxcode{\sphinxupquote{-{-}writable}}
is by default not recorded, and your container loses its
reproducibility. So let’s talk about how to make these files! First,
let’s look at the absolute minimum requirement:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu
\end{sphinxVerbatim}

We would save this content to a file called Singularity and then issue
the following commands to bootstrap the image from the file

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build ubuntu.img Singularity
\end{sphinxVerbatim}

Do you want to specify a particular tag? or version? You can just add
that to the docker uri:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu:latest
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
Note that the default is \sphinxcode{\sphinxupquote{latest}} . If you want to customize the Registry or
Namespace, just add those to the header:
\end{sphinxadmonition}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu

Registry: pancakes.registry.index.io

Namespace: blue/berry/cream
\end{sphinxVerbatim}

The power of build comes with the other stuff that you can do! This
means running specific install commands, specifying your containers
runscript (what it does when you execute it), adding files, labels, and
customizing the environment. Here is a full Singularity file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: tensorflow/tensorflow:latest


\PYGZpc{}runscript

    exec /usr/bin/python \PYGZdq{}\PYGZdl{}@\PYGZdq{}


\PYGZpc{}post

    echo \PYGZdq{}Post install stuffs!\PYGZdq{}


\PYGZpc{}files

/home/vanessa/Desktop/analysis.py /tmp/analysis.py

relative\PYGZus{}path.py /tmp/analysis2.py


\PYGZpc{}environment

TOPSECRET=pancakes

HELLO=WORLD

export HELLO TOPSECRET


\PYGZpc{}labels

AUTHOR Vanessasaur
\end{sphinxVerbatim}

In the example above, I am overriding any Dockerfile \sphinxcode{\sphinxupquote{ENTRYPOINT}} or \sphinxcode{\sphinxupquote{CMD}} because I have
defined a \sphinxcode{\sphinxupquote{\%runscript}} . If I want the Dockerfile \sphinxcode{\sphinxupquote{ENTRYPOINT}} to take preference, I would remove
the \sphinxcode{\sphinxupquote{\%runscript}} section. If I want to use \sphinxcode{\sphinxupquote{CMD}} instead of \sphinxcode{\sphinxupquote{ENTRYPOINT}} , I would again remove the
runscript, and add IncludeCmd to the header:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: tensorflow/tensorflow:latest

IncludeCmd: yes


\PYGZpc{}post


    echo \PYGZdq{}Post install stuffs!\PYGZdq{}
\end{sphinxVerbatim}

Did you know that you can commit this Singularity file to a GitHub repo
and it will automatically build for you when you push to \sphinxhref{https://singularity-hub.org/}{Singularity
Hub}?. This will ensure maximum reproducibility of your work.


\section{How does the runscript work?}
\label{\detokenize{singularity_and_docker:how-does-the-runscript-work}}
Docker has two commands in the \sphinxcode{\sphinxupquote{Dockerfile}} that have something to do with
execution, \sphinxcode{\sphinxupquote{CMD}} and \sphinxcode{\sphinxupquote{ENTRYPOINT}}. The differences are subtle, but the best description
I’ve found is the following:
\begin{quote}

A \sphinxcode{\sphinxupquote{CMD}} is to provide defaults for an executing container.
\end{quote}

and
\begin{quote}

An \sphinxcode{\sphinxupquote{ENTRYPOINT}} helps you to configure a container that you can run as an
executable.
\end{quote}

Given the definition, the \sphinxcode{\sphinxupquote{ENTRYPOINT}} is most appropriate for the Singularity \sphinxcode{\sphinxupquote{\%runscript}} , and
so using the default bootstrap (whether from a \sphinxcode{\sphinxupquote{docker://}} endpoint or a \sphinxcode{\sphinxupquote{Singularity}} spec file)
will set the \sphinxcode{\sphinxupquote{ENTRYPOINT}} variable as the runscript. You can change this behavior by
specifying \sphinxcode{\sphinxupquote{IncludeCmd: yes}} in the Spec file (see below). If you provide any sort of \sphinxcode{\sphinxupquote{\%runscript}} in
your Spec file, this overrides anything provided in Docker. In summary,
the order of operations is as follows:
\begin{enumerate}
\item {} 
If a \sphinxcode{\sphinxupquote{\%runscript}} is specified in the Singularity spec file, this takes prevalence
over all

\item {} 
If no \sphinxcode{\sphinxupquote{\%runscript}} is specified, or if the \sphinxcode{\sphinxupquote{import}} command is used as in the example
above, the \sphinxcode{\sphinxupquote{ENTRYPOINT}} is used as runscript.

\item {} 
If no \sphinxcode{\sphinxupquote{\%runscript}} is specified, but the user has a \sphinxcode{\sphinxupquote{Singularity}} spec with \sphinxcode{\sphinxupquote{IncludeCmd}} , then the Docker \sphinxcode{\sphinxupquote{CMD}} is
used.

\item {} 
If no \sphinxcode{\sphinxupquote{\%runscript}} is specified, and there is no \sphinxcode{\sphinxupquote{CMD}} or \sphinxcode{\sphinxupquote{ENTRYPOINT}} , the image’s default
execution action is to run the bash shell.

\end{enumerate}


\section{How do I specify my Docker image?}
\label{\detokenize{singularity_and_docker:how-do-i-specify-my-docker-image}}
In the example above, you probably saw that we referenced the docker
image first with the uri \sphinxcode{\sphinxupquote{docker://}} and that is important to tell Singularity that
it will be pulling Docker layers. To ask for ubuntu, we asked for \sphinxcode{\sphinxupquote{docker://ubuntu}} . This
uri that we give to Singularity is going to be very important to choose
the following Docker metadata items:
\begin{itemize}
\item {} 
registry (e.g., “index.docker.io”)

\item {} 
namespace (e.g., “library”)

\item {} 
repository (e.g., “ubuntu”)

\item {} 
tag (e.g., “latest”) OR version (e.g., “@sha256:1234…)

\end{itemize}

When we put those things together, it looks like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker://\PYGZlt{}registry\PYGZgt{}/\PYGZlt{}namespace\PYGZgt{}/\PYGZlt{}repo\PYGZus{}name\PYGZgt{}:\PYGZlt{}repo\PYGZus{}tag\PYGZgt{}
\end{sphinxVerbatim}

By default, the minimum requirement is that you specify a repository
name (eg, ubuntu) and it will default to the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker://index.docker.io/library/ubuntu:latest
\end{sphinxVerbatim}

If you provide a version instead of a tag, that will be used instead:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker://index.docker.io/library/ubuntu@sha256:1235...
\end{sphinxVerbatim}

You can have one or the other, both are considered a “digest” in
Docker speak.

If you want to change any of those fields and are having trouble with
the uri, you can also just state them explicitly:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu

Registry: index.docker.io

Namespace: library
\end{sphinxVerbatim}


\section{Custom Authentication}
\label{\detokenize{singularity_and_docker:custom-authentication}}
For both import and build using a build spec file, by default we use
the Docker Registry \sphinxcode{\sphinxupquote{index.docker.io}} . Singularity first tries the call without a
token, and then asks for one with pull permissions if the request is
defined. However, it may be the case that you want to provide a custom
token for a private registry. You have two options. You can either
provide a \sphinxcode{\sphinxupquote{Username}} and \sphinxcode{\sphinxupquote{Password}} in the build specification file (if stored locally and
there is no need to share), or (in the case of doing an import or
needing to secure the credentials) you can export these variables to
environmental variables. We provide instructions for each of these
cases:


\subsection{Authentication in the Singularity Build File}
\label{\detokenize{singularity_and_docker:authentication-in-the-singularity-build-file}}
You can simply specify your additional authentication parameters in the
header with the labels \sphinxcode{\sphinxupquote{Username}} and \sphinxcode{\sphinxupquote{Password}} :

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Username: vanessa

Password: [password]
\end{sphinxVerbatim}

Again, this can be in addition to specification of a custom registry
with the \sphinxcode{\sphinxupquote{Registry}} parameter.


\subsection{Authentication in the Environment}
\label{\detokenize{singularity_and_docker:authentication-in-the-environment}}
You can export your username, and password for Singularity as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
export SINGULARITY\PYGZus{}DOCKER\PYGZus{}USERNAME=vanessasaur

export SINGULARITY\PYGZus{}DOCKER\PYGZus{}PASSWORD=rawwwwwr
\end{sphinxVerbatim}


\subsection{Testing Authentication}
\label{\detokenize{singularity_and_docker:testing-authentication}}
If you are having trouble, you can test your token by obtaining it on
the command line and putting it into an environmental variable, \sphinxcode{\sphinxupquote{CREDENTIAL}} :

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
CREDENTIAL=\PYGZdl{}(echo \PYGZhy{}n vanessa:[password] \textbar{} base64)

TOKEN=\PYGZdl{}(http \PYGZsq{}https://auth.docker.io/token?service=registry.docker.io\PYGZam{}scope=repository:vanessa/code\PYGZhy{}samples:pull\PYGZsq{} Authorization:\PYGZdq{}Basic \PYGZdl{}CREDENTIAL\PYGZdq{} \textbar{} jq \PYGZhy{}r \PYGZsq{}.token\PYGZsq{})
\end{sphinxVerbatim}

This should place the token in the environmental variable \sphinxcode{\sphinxupquote{TOKEN}} . To test that
your token is valid, you can do the following

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
http https://index.docker.io/v2/vanessa/code\PYGZhy{}samples/tags/list Authorization:\PYGZdq{}Bearer \PYGZdl{}TOKEN\PYGZdq{}
\end{sphinxVerbatim}

The above call should return the tags list as expected. And of course
you should change the repo name to be one that actually exists that you
have credentials for.


\section{Best Practices}
\label{\detokenize{singularity_and_docker:best-practices}}
While most docker images can import and run without a hitch, there are
some special cases for which things can go wrong. Here is a general list
of suggested practices, and if you discover a new one in your building
ventures please \sphinxhref{https://www.github.com/singularityware/singularityware.github.io/issues}{let us know}.


\subsection{1. Installation to Root}
\label{\detokenize{singularity_and_docker:installation-to-root}}
When using Docker, you typically run as root, meaning that root’s home
at \sphinxcode{\sphinxupquote{/root}} is where things will install given a specification of home. This is
fine when you stay in Docker, or if the content at \sphinxcode{\sphinxupquote{/root}} doesn’t need any
kind of write access, but generally can lead to a lot of bugs because
it is, after all, root’s home. This leads us to best practice \#1.

Don’t install anything to root’s home, \sphinxcode{\sphinxupquote{/root}}.


\subsection{2. Library Configurations}
\label{\detokenize{singularity_and_docker:library-configurations}}
The command \sphinxhref{https://codeyarns.com/2014/01/14/how-to-add-library-directory-to-ldconfig-cache/}{ldconfig} is used to update the shared library cache. If
you have software that requires symbolic linking of libraries and you
do the installation without updating the cache, then the Singularity
image (in read only) will likely give you an error that the library is
not found. If you look in the image, the library will exist but the
symbolic link will not. This leads us to best practice \#2:

Update the library cache at the end of your Dockerfile with a call
to ldconfig.


\subsection{3. Don’t install to \$HOME or \$TMP}
\label{\detokenize{singularity_and_docker:don-t-install-to-home-or-tmp}}
We can assume that the most common Singularity use case has the \$USER
home being automatically mounted to \sphinxcode{\sphinxupquote{\$HOME}}, and \sphinxcode{\sphinxupquote{\$TMP}} also mounted. Thus, given
the potential for some kind of conflict or missing files, for best
practice \#3 we suggest the following:

Don’t put container valuables in \sphinxcode{\sphinxupquote{\$TMP}} or \sphinxcode{\sphinxupquote{\$HOME}}

Have any more best practices? Please \sphinxhref{https://www.github.com/singularityware/singularityware.github.io/issues}{let us know}!


\section{Troubleshooting}
\label{\detokenize{singularity_and_docker:troubleshooting}}
Why won’t my image build work? If you can’t find an answer on this site,
please \sphinxhref{https://www.github.com/singularityware/singularity/issues}{ping us an issue}. If you’ve found an answer and you’d like to
see it on the site for others to benefit from, then post to us
\sphinxhref{https://www.github.com/singularityware/singularityware.github.io/issues}{here}.


\chapter{Troubleshooting}
\label{\detokenize{troubleshooting:troubleshooting}}\label{\detokenize{troubleshooting::doc}}
A little bit of help.


\section{No space left on device}
\label{\detokenize{troubleshooting:no-space-left-on-device}}
Sometimes when you are building an image, Singularity tells you that
it runs out of space on the device:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build fatty.simg Singularity

IOError: [Errno 28] No space left on device

ABORT: Aborting with RETVAL=255
\end{sphinxVerbatim}

The issue here is that during build of a squashfs image, Singularity is
using the \sphinxcode{\sphinxupquote{\$TMPDIR}} . If your \sphinxcode{\sphinxupquote{\$TMPDIR}} is overflowing (or the mount is very small!) then
you would see this error. As a test, you can try building a sandbox. If this is the issue, then the sandbox should work.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build \PYGZhy{}\PYGZhy{}sandbox [fatty] Singularity
\end{sphinxVerbatim}

\sphinxstylestrong{Solution}
You simply need to set the \sphinxcode{\sphinxupquote{\$SINGULARITY\_CACHEDIR}} to a different location that you have more
room.


\section{Segfault on Bootstrap of Centos Image}
\label{\detokenize{troubleshooting:segfault-on-bootstrap-of-centos-image}}
If you are bootstrapping a centos 6 docker image from a debian host,
you might hit a segfault:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell docker://centos:6

Docker image path: index.docker.io/library/centos:6

Cache folder set to /home/jbdenis/.singularity/docker

Creating container runtime...

Singularity: Invoking an interactive shell within container...


Segmentation fault
\end{sphinxVerbatim}

The fix is on your host, you need to pass the variable \sphinxcode{\sphinxupquote{vsyscall=emulate}} to the kernel,
meaning in the file \sphinxcode{\sphinxupquote{/etc/default/grub}} (note, this file is debian specific), add the
following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
GRUB\PYGZus{}CMDLINE\PYGZus{}LINUX\PYGZus{}DEFAULT=\PYGZdq{}vsyscall=emulate\PYGZdq{}
\end{sphinxVerbatim}

and then update grub and reboot:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
update\PYGZhy{}grub \PYGZam{}\PYGZam{} reboot
\end{sphinxVerbatim}

Please note that this change might have \sphinxhref{https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/admin-guide/kernel-parameters.txt?h=v4.13-rc3\#n4387}{security implications} that
you should be aware of. For more information, see the \sphinxhref{https://github.com/singularityware/singularity/issues/845}{original issue}.


\section{How to use Singularity with GRSecurity enabled kernels}
\label{\detokenize{troubleshooting:how-to-use-singularity-with-grsecurity-enabled-kernels}}
\begin{DUlineblock}{0em}
\item[] To run Singularity on a GRSecurity enabled kernel, you must disable
several security features:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo sysctl \PYGZhy{}w kernel.grsecurity.chroot\PYGZus{}caps=0

\PYGZdl{} sudo sysctl \PYGZhy{}w kernel.grsecurity.chroot\PYGZus{}deny\PYGZus{}mount=0

\PYGZdl{} sudo sysctl \PYGZhy{}w kernel.grsecurity.chroot\PYGZus{}deny\PYGZus{}chmod=0

\PYGZdl{} sudo sysctl \PYGZhy{}w kernel.grsecurity.chroot\PYGZus{}deny\PYGZus{}fchdir=0
\end{sphinxVerbatim}


\section{The container isn’t working on a different host!}
\label{\detokenize{troubleshooting:the-container-isnt-working-on-a-different-host}}
Singularity by default mounts your home directory. While this is great
for seamless communication between your host and the container, it can
introduce issues if you have software modules installed at \sphinxcode{\sphinxupquote{\$HOME}}. For
example, we had a user \sphinxhref{https://github.com/singularityware/singularity/issues/476}{run into this issue}.

\sphinxstylestrong{Solution 1: Specify the home to mount}
A first thing to try is to point to some “sanitized home,” which is
the purpose of the -H or \textendash{}home option. For example, here we are
creating a home directory under /tmp/homie, and then telling the
container to mount it as home:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
rm \PYGZhy{}rf /tmp/homie \PYGZam{}\PYGZam{} mkdir \PYGZhy{}p /tmp/homie \PYGZam{}\PYGZam{} \PYGZbs{}

singularity exec \PYGZhy{}H /tmp/homie analysis.img /bin/bash
\end{sphinxVerbatim}

\sphinxstylestrong{Solution 2: Specify the executable to use}
It may be the issue that there is an executable in your host
environment (eg, python) that is being called in preference to the
containers. To avoid this, in your runscript (the \sphinxcode{\sphinxupquote{\%runscript}} section of the
bootstrap file) you should specify the path to the executable exactly.
This means:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}runscript


\PYGZsh{} This specifies the python in the container

exec /usr/bin/python \PYGZdq{}\PYGZdl{}@\PYGZdq{}


\PYGZsh{} This may pick up a different one

exec python \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}

This same idea would be useful if you are issuing the command to the
container using \sphinxcode{\sphinxupquote{exec}}. Thanks to \sphinxhref{https://github.com/yarikoptic}{yarikoptic} for the suggestions on this
issue.


\section{Invalid Argument or Unknown Option}
\label{\detokenize{troubleshooting:invalid-argument-or-unknown-option}}
When I try mounting my container with the \sphinxcode{\sphinxupquote{-B}} or \sphinxcode{\sphinxupquote{-{-}bind}} option I receive an
unknown option or Invalid argument error.
Make sure that you are using the most recent Singularity release to
mount your container to the host system, and that the \sphinxcode{\sphinxupquote{-{-}bind}} argument is
placed after the execution command. An example might look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run \PYGZhy{}B \PYGZdl{}PWD:/data my\PYGZus{}container.img
\end{sphinxVerbatim}

Also, make sure you are using an up-to-date Singularity to bootstrap
your container. Some features (such as \sphinxcode{\sphinxupquote{-{-}bind}} ) will not work in earlier
versions.


\section{Error running Singularity with sudo}
\label{\detokenize{troubleshooting:error-running-singularity-with-sudo}}
This fix solves the following error when Singularity is installed into
the default compiled prefix of /usr/local:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity instance.start container.img daemon1

sudo: singularity: command not found
\end{sphinxVerbatim}

The cause of the problem is that \sphinxcode{\sphinxupquote{sudo}} sanitizes the PATH environment
variable and does not include /usr/local/bin in the default search
path. Considering this program path is by default owned by root, it is
reasonable to extend the default sudo PATH to include this directory.
To add /usr/local/bin to the default sudo search path, run the program
visudo which will edit the sudoers file, and search for the string
‘secure\_path’. Once found, append :/usr/local/bin to that line so it
looks like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Defaults    secure\PYGZus{}path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin
\end{sphinxVerbatim}


\section{How to resolve “Too many levels of symbolic links” error}
\label{\detokenize{troubleshooting:how-to-resolve-too-many-levels-of-symbolic-links-error}}
Running singularity failed with “Too many levels of symbolic links”
error

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run \PYGZhy{}B /apps container.img

ERROR : There was an error binding the path /apps: Too many levels of symbolic links

ABORT : Retval = 255
\end{sphinxVerbatim}

You got this error because /apps directory is an autofs mount point. You
can fix it by editing singularity.conf and adding the following
directive with corresponding path:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
autofs bug path = /apps
\end{sphinxVerbatim}


\chapter{Appendix}
\label{\detokenize{appendix:appendix}}\label{\detokenize{appendix::doc}}

\section{build-docker-module}
\label{\detokenize{appendix:build-docker-module}}\label{\detokenize{appendix:id1}}

\subsection{Overview}
\label{\detokenize{appendix:overview}}\label{\detokenize{appendix:sec-build-docker-module}}
Docker images are comprised of layers that are assembled at runtime to create an image. You can use Docker layers to create a base
image, and then add your own custom software. For example, you might use Docker’s Ubuntu image layers to create an Ubuntu Singularity
container. You could do the same with CentOS, Debian, Arch, Suse, Alpine, BusyBox, etc.

Or maybe you want a container that already has software installed. For instance, maybe you want to build a container that uses CUDA
and cuDNN to leverage the GPU, but you don’t want to install from scratch. You can start with one of the \sphinxcode{\sphinxupquote{nvidia/cuda}} containers and
install your software on top of that.

Or perhaps you have already invested in Docker and created your own Docker containers. If so, you can seamlessly convert them to
Singularity with the \sphinxcode{\sphinxupquote{docker}} bootstrap module.


\subsection{Keywords}
\label{\detokenize{appendix:keywords}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
From: \PYGZlt{}registry\PYGZgt{}/\PYGZlt{}namespace\PYGZgt{}/\PYGZlt{}container\PYGZgt{}:\PYGZlt{}tag\PYGZgt{}@\PYGZlt{}digest\PYGZgt{}
\end{sphinxVerbatim}

The From keyword is mandatory. It specifies the container to use as a base. \sphinxcode{\sphinxupquote{registry}} is optional and defaults to \sphinxcode{\sphinxupquote{index.docker.io}}.
\sphinxcode{\sphinxupquote{namespace}} is optional and defaults to \sphinxcode{\sphinxupquote{library}}. This is the correct namespace to use for some official containers (ubuntu for example).
\sphinxcode{\sphinxupquote{tag}} is also optional and will default to \sphinxcode{\sphinxupquote{latest}}

See {\hyperref[\detokenize{singularity_and_docker:singularity-and-docker}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity and Docker}}}} for more detailed info on using Docker registries.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Registry: http://custom\PYGZus{}registry
\end{sphinxVerbatim}

The Registry keyword is optional. It will default to \sphinxcode{\sphinxupquote{index.docker.io}}.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Namespace: namespace
\end{sphinxVerbatim}

The Namespace keyword is optional. It will default to \sphinxcode{\sphinxupquote{library}}.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
IncludeCmd: yes
\end{sphinxVerbatim}

The IncludeCmd keyword is optional. If included, and if a \sphinxcode{\sphinxupquote{\%runscript}} is not specified, a Docker \sphinxcode{\sphinxupquote{CMD}} will take precedence over \sphinxcode{\sphinxupquote{ENTRYPOINT}}
and will be used as a runscript. Note that the \sphinxcode{\sphinxupquote{IncludeCmd}} keyword is considered valid if it is not empty! This means that
\begin{quote}

\sphinxcode{\sphinxupquote{IncludeCmd: yes}} and \sphinxcode{\sphinxupquote{IncludeCmd: no}} are identical. In both cases the \sphinxcode{\sphinxupquote{IncludeCmd}} keyword is not empty, so the Docker \sphinxcode{\sphinxupquote{CMD}} will take precedence
over an \sphinxcode{\sphinxupquote{ENTRYPOINT}}.

See {\hyperref[\detokenize{singularity_and_docker:singularity-and-docker}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity and Docker}}}} for more info on order of operations for determining a runscript.
\end{quote}


\subsection{Notes}
\label{\detokenize{appendix:notes}}
Docker containers are stored as a collection of tarballs called layers. When building from a Docker container the layers must be downloaded and then
assembled in the proper order to produce a viable file system. Then the file system must be converted to squashfs or ext3 format.

Building from Docker Hub is not considered reproducible because if any of the layers of the image are changed, the container will change.
If reproducibility is important to you, consider hosting a base container on Singularity Hub and building from it instead.

For detailed information about setting your build environment see {\hyperref[\detokenize{build_environment:build-environment}]{\sphinxcrossref{\DUrole{std,std-ref}{Build Customization}}}}.


\section{build-shub}
\label{\detokenize{appendix:build-shub}}\label{\detokenize{appendix:id2}}

\subsection{Overview}
\label{\detokenize{appendix:sec-build-shub}}\label{\detokenize{appendix:id3}}
You can use an existing container on Singularity Hub as your “base,” and then add customization. This allows you to build multiple images
from the same starting point. For example, you may want to build several containers with the same custom python installation, the same custom
compiler toolchain, or the same base MPI installation. Instead of building these from scratch each time, you could create a base container on
Singularity Hub and then build new containers from that existing base container adding customizations in \sphinxcode{\sphinxupquote{\%post}} , \sphinxcode{\sphinxupquote{\%environment}}, \sphinxcode{\sphinxupquote{\%runscript}}, etc.


\subsection{Keywords}
\label{\detokenize{appendix:id4}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: shub
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
From: shub://\PYGZlt{}registry\PYGZgt{}/\PYGZlt{}username\PYGZgt{}/\PYGZlt{}container\PYGZhy{}name\PYGZgt{}:\PYGZlt{}tag\PYGZgt{}@digest
\end{sphinxVerbatim}

The From keyword is mandatory. It specifies the container to use as a base. \sphinxcode{\sphinxupquote{registry is optional and defaults to {}`{}`singularity-hub.org}}.
\sphinxcode{\sphinxupquote{tag}} and \sphinxcode{\sphinxupquote{digest}} are also optional. \sphinxcode{\sphinxupquote{tag}} defaults to \sphinxcode{\sphinxupquote{latest}} and \sphinxcode{\sphinxupquote{digest}} can be left blank if you want the latest build.


\subsection{Notes}
\label{\detokenize{appendix:id5}}
When bootstrapping from a Singularity Hub image, all previous definition files that led to the creation of the current image will be stored
in a directory within the container called \sphinxcode{\sphinxupquote{/.singularity.d/bootstrap\_history}}. Singularity will also alert you if environment variables have
been changed between the base image and the new image during bootstrap.


\section{build-localimage}
\label{\detokenize{appendix:build-localimage}}\label{\detokenize{appendix:id6}}\phantomsection\label{\detokenize{appendix:sec-build-localimage}}
This module allows you to build a container from an existing Singularity container on your host system. The name is somewhat misleading
because your container can be in either image or directory format.


\subsection{Overview}
\label{\detokenize{appendix:id7}}
You can use an existing container image as your “base,” and then add customization. This allows you to build multiple images from the same
starting point. For example, you may want to build several containers with the same custom python installation, the same custom compiler
toolchain, or the same base MPI installation. Instead of building these from scratch each time, you could start with the appropriate local
base container and then customize the new container in \sphinxcode{\sphinxupquote{\%post}}, \sphinxcode{\sphinxupquote{\%environment}}, \sphinxcode{\sphinxupquote{\%runscript}}, etc.


\subsection{Keywords}
\label{\detokenize{appendix:id8}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: localimage
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
From: /path/to/container/file/or/directory
\end{sphinxVerbatim}

The From keyword is mandatory. It specifies the local container to use as a base.


\subsection{Notes}
\label{\detokenize{appendix:id9}}
When building from a local container, all previous definition files that led to the creation of the current container will be stored in a
directory within the container called \sphinxcode{\sphinxupquote{/.singularity.d/bootstrap\_history}}. Singularity will also alert you if environment variables have been
changed between the base image and the new image during bootstrap.


\section{build-yum}
\label{\detokenize{appendix:build-yum}}\label{\detokenize{appendix:id10}}\phantomsection\label{\detokenize{appendix:sec-build-yum}}
This module allows you to build a Red Hat/CentOS/Scientific Linux style container from a mirror URI.


\subsection{Overview}
\label{\detokenize{appendix:id11}}
Use the \sphinxcode{\sphinxupquote{yum}} module to specify a base for a CentOS-like container. You must also specify the URI for the mirror you would like to use.


\subsection{Keywords}
\label{\detokenize{appendix:id12}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: yum
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
OSVersion: 7
\end{sphinxVerbatim}

The OSVersion keyword is optional. It specifies the OS version you would like to use. It is only required if you have specified a \%\{OSVERSION\}
variable in the \sphinxcode{\sphinxupquote{MirrorURL}} keyword.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
MirrorURL: http://mirror.centos.org/centos\PYGZhy{}\PYGZpc{}\PYGZob{}OSVERSION\PYGZcb{}/\PYGZpc{}\PYGZob{}OSVERSION\PYGZcb{}/os/\PYGZdl{}basearch/
\end{sphinxVerbatim}

The MirrorURL keyword is mandatory. It specifies the URL to use as a mirror to download the OS. If you define the \sphinxcode{\sphinxupquote{OSVersion}} keyword, than you
can use it in the URL as in the example above.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Include: yum
\end{sphinxVerbatim}

The Include keyword is optional. It allows you to install additional packages into the core operating system. It is a best practice to supply
only the bare essentials such that the \sphinxcode{\sphinxupquote{\%post}} section has what it needs to properly complete the build. One common package you may want to install
when using the \sphinxcode{\sphinxupquote{yum}} build module is YUM itself.


\subsection{Notes}
\label{\detokenize{appendix:id13}}
There is a major limitation with using YUM to bootstrap a container. The RPM database that exists within the container will be created using the
RPM library and Berkeley DB implementation that exists on the host system. If the RPM implementation inside the container is not compatible with
the RPM database that was used to create the container, RPM and YUM commands inside the container may fail. This issue can be easily demonstrated
by bootstrapping an older RHEL compatible image by a newer one (e.g. bootstrap a Centos 5 or 6 container from a Centos 7 host).

In order to use the \sphinxcode{\sphinxupquote{debootstrap}} build module, you must have \sphinxcode{\sphinxupquote{yum}} installed on your system. It may seem counter-intuitive to install YUM on a system
that uses a different package manager, but you can do so. For instance, on Ubuntu you can install it like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo apt\PYGZhy{}get update \PYGZam{}\PYGZam{} sudo apt\PYGZhy{}get install yum
\end{sphinxVerbatim}


\section{build-debootstrap}
\label{\detokenize{appendix:build-debootstrap}}\label{\detokenize{appendix:id14}}\phantomsection\label{\detokenize{appendix:sec-build-debootstrap}}
This module allows you to build a Debian/Ubuntu style container from a mirror URI.


\subsection{Overview}
\label{\detokenize{appendix:id15}}
Use the \sphinxcode{\sphinxupquote{debootstrap}} module to specify a base for a Debian-like container. You must also specify the OS version and a URI for the mirror you would like to use.


\subsection{Keywords}
\label{\detokenize{appendix:id16}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: debootstrap
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
OSVersion: xenial
\end{sphinxVerbatim}

The OSVersion keyword is mandatory. It specifies the OS version you would like to use. For Ubuntu you can use code words like \sphinxcode{\sphinxupquote{trusty}} (14.04), \sphinxcode{\sphinxupquote{xenial}} (16.04),
and \sphinxcode{\sphinxupquote{yakkety}} (17.04). For Debian you can use values like \sphinxcode{\sphinxupquote{stable}}, \sphinxcode{\sphinxupquote{oldstable}}, \sphinxcode{\sphinxupquote{testing}}, and \sphinxcode{\sphinxupquote{unstable}} or code words like \sphinxcode{\sphinxupquote{wheezy}} (7), \sphinxcode{\sphinxupquote{jesse}} (8), and \sphinxcode{\sphinxupquote{stretch}} (9).
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
MirrorURL:  http://us.archive.ubuntu.com/ubuntu/
\end{sphinxVerbatim}
\end{quote}

The MirrorURL keyword is mandatory. It specifies a URL to use as a mirror when downloading the OS.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Include: somepackage
\end{sphinxVerbatim}

The Include keyword is optional. It allows you to install additional packages into the core operating system. It is a best practice to supply only the bare essentials
such that the \sphinxcode{\sphinxupquote{\%post}} section has what it needs to properly complete the build.


\subsection{Notes}
\label{\detokenize{appendix:id17}}
In order to use the \sphinxcode{\sphinxupquote{debootstrap}} build module, you must have \sphinxcode{\sphinxupquote{debootstrap}} installed on your system. On Ubuntu you can install it like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo apt\PYGZhy{}get update \PYGZam{}\PYGZam{} sudo apt\PYGZhy{}get install debootstrap
\end{sphinxVerbatim}

On CentOS you can install it from the epel repos like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo yum update \PYGZam{}\PYGZam{} sudo yum install epel\PYGZhy{}release \PYGZam{}\PYGZam{} sudo yum install debootstrap.noarch
\end{sphinxVerbatim}


\section{build-arch}
\label{\detokenize{appendix:build-arch}}\label{\detokenize{appendix:id18}}\phantomsection\label{\detokenize{appendix:sec-build-arch}}
This module allows you to build a Arch Linux based container.


\subsection{Overview}
\label{\detokenize{appendix:id19}}
Use the \sphinxcode{\sphinxupquote{arch}} module to specify a base for an Arch Linux based container. Arch Linux uses the aptly named the \sphinxcode{\sphinxupquote{pacman}} package manager (all puns intended).


\subsection{Keywords}
\label{\detokenize{appendix:id20}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: arch
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

The Arch Linux bootstrap module does not name any additional keywords at this time. By defining the \sphinxcode{\sphinxupquote{arch}} module, you have essentially given all of the
information necessary for that particular bootstrap module to build a core operating system.


\subsection{Notes}
\label{\detokenize{appendix:id21}}
Arch Linux is, by design, a very stripped down, light-weight OS. You may need to perform a fair amount of configuration to get a usable OS. Please refer
to this \sphinxhref{https://github.com/singularityware/singularity/blob/master/examples/arch/README.md}{README.md} and
the \sphinxhref{https://github.com/singularityware/singularity/blob/master/examples/arch/Singularity}{Arch Linux example} for more info.


\section{build-busybox}
\label{\detokenize{appendix:build-busybox}}\label{\detokenize{appendix:id22}}\phantomsection\label{\detokenize{appendix:sec-build-busybox}}
This module allows you to build a container based on BusyBox.


\subsection{Overview}
\label{\detokenize{appendix:id23}}
Use the \sphinxcode{\sphinxupquote{busybox}} module to specify a BusyBox base for container. You must also specify a URI for the mirror you would like to use.


\subsection{Keywords}
\label{\detokenize{appendix:id24}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: busybox
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
MirrorURL: https://www.busybox.net/downloads/binaries/1.26.1\PYGZhy{}defconfig\PYGZhy{}multiarch/busybox\PYGZhy{}x86\PYGZus{}64
\end{sphinxVerbatim}

The MirrorURL keyword is mandatory. It specifies a URL to use as a mirror when downloading the OS.


\subsection{Notes}
\label{\detokenize{appendix:id25}}
You can build a fully functional BusyBox container that only takes up \textasciitilde{}600kB of disk space!


\section{build-zypper}
\label{\detokenize{appendix:build-zypper}}\label{\detokenize{appendix:id26}}\phantomsection\label{\detokenize{appendix:sec-build-zypper}}
This module allows you to build a Suse style container from a mirror URI.


\subsection{Overview}
\label{\detokenize{appendix:id27}}
Use the \sphinxcode{\sphinxupquote{zypper}} module to specify a base for a Suse-like container. You must also specify a URI for
the mirror you would like to use.


\subsection{Keywords}
\label{\detokenize{appendix:id28}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: zypper
\end{sphinxVerbatim}

The Bootstrap keyword is always mandatory. It describes the bootstrap module to use.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
OSVersion: 42.2
\end{sphinxVerbatim}

The OSVersion keyword is optional. It specifies the OS version you would like to use.
It is only required if you have specified a \%\{OSVERSION\} variable in the \sphinxcode{\sphinxupquote{MirrorURL}} keyword.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Include: somepackage
\end{sphinxVerbatim}

The Include keyword is optional. It allows you to install additional packages into the core operating system.
It is a best practice to supply only the bare essentials such that the \sphinxcode{\sphinxupquote{\%post}} section has what it needs to properly complete the build.
One common package you may want to install when using the zypper build module is \sphinxcode{\sphinxupquote{zypper}} itself.


\section{Singularity Action Flags}
\label{\detokenize{appendix:singularity-action-flags}}\label{\detokenize{appendix:id29}}\phantomsection\label{\detokenize{appendix:sec-action-flags}}
For each of \sphinxcode{\sphinxupquote{exec}}, \sphinxcode{\sphinxupquote{run}}, and \sphinxcode{\sphinxupquote{shell}}, there are a few important flags that we want to note for new users that have substantial impact on using
your container. While we won’t include the complete list of run options (for this complete list see \sphinxcode{\sphinxupquote{singularity run -{-}help}} or more generally
\sphinxcode{\sphinxupquote{singularity \textless{}action\textgreater{} -{-}help}}) we will review some highly useful flags that you can add to these actions.
\begin{itemize}
\item {} 
\sphinxstylestrong{\textendash{}contain}: Contain suggests that we want to better isolate the container runtime from the host. Adding the \sphinxcode{\sphinxupquote{-{-}contain}} flag will use minimal

\end{itemize}

\sphinxcode{\sphinxupquote{/dev}} and empty other directories (e.g., \sphinxcode{\sphinxupquote{/tmp}}).
\begin{itemize}
\item {} 
\sphinxstylestrong{\textendash{}containall}: In addition to what is provided with \sphinxcode{\sphinxupquote{-{-}contain}} (filesystems) also contain PID, IPC, and environment.

\item {} 
\sphinxstylestrong{\textendash{}cleanenv}: Clean the environment before running the container.

\item {} 
\sphinxstylestrong{\textendash{}pwd}: Initial working directory for payload process inside the container.

\end{itemize}

This is \sphinxstylestrong{not} a complete list! Please see the \sphinxcode{\sphinxupquote{singularity \textless{}action\textgreater{} help}} for an updated list.


\subsection{Examples}
\label{\detokenize{appendix:examples}}
Here we are cleaning the environment. In the first command, we see that the variable \sphinxcode{\sphinxupquote{PEANUTBUTTER}} gets passed into the container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
PEANUTBUTTER=JELLY singularity exec Centos7.img env \textbar{} grep PEANUT

PEANUTBUTTER=JELLY
\end{sphinxVerbatim}

And now here we add \sphinxcode{\sphinxupquote{-{-}cleanenv}} to see that it doesn’t.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
PEANUTBUTTER=JELLY singularity exec \PYGZhy{}\PYGZhy{}cleanenv Centos7.img env \textbar{} grep PEANUT
\end{sphinxVerbatim}

Here we will test contain. We can first confirm that there are a lot of files on our host in /tmp, and the same files are found in the container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} On the host

\PYGZdl{} ls /tmp \textbar{} wc \PYGZhy{}l

17


\PYGZsh{} And then /tmp is mounted to the container, by default

\PYGZdl{} singularity exec Centos7.img  ls /tmp \textbar{} wc \PYGZhy{}l


\PYGZsh{} ..but not if we use \PYGZhy{}\PYGZhy{}contain

\PYGZdl{} singularity exec \PYGZhy{}\PYGZhy{}contain Centos7.img  ls /tmp \textbar{} wc \PYGZhy{}l

0
\end{sphinxVerbatim}


\section{Commands}
\label{\detokenize{appendix:commands}}

\subsection{Command Usage}
\label{\detokenize{appendix:command-usage}}\label{\detokenize{appendix:id30}}

\subsubsection{The Singularity command}
\label{\detokenize{appendix:the-singularity-command}}\label{\detokenize{appendix:sec-commandlineinterface}}
Singularity uses a primary command wrapper called \sphinxcode{\sphinxupquote{singularity}}. When you run \sphinxcode{\sphinxupquote{singularity}}
without any options or arguments it will dump the high level usage
syntax.

The general usage form is:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity (opts1) [subcommand] (opts2) ...
\end{sphinxVerbatim}

If you type \sphinxcode{\sphinxupquote{singularity}} without any arguments, you will see a high
level help for all arguments. The main options include:
\sphinxstylestrong{Container Actions}
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:build-command}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}} : Build a container on your user endpoint or build environment

\item {} 
{\hyperref[\detokenize{appendix:exec-command}]{\sphinxcrossref{\DUrole{std,std-ref}{exec}}}} : Execute a command to your container

\item {} 
{\hyperref[\detokenize{appendix:inspect-command}]{\sphinxcrossref{\DUrole{std,std-ref}{inspect}}}} : See labels, run and test scripts, and environment variables

\item {} 
{\hyperref[\detokenize{appendix:pull-command}]{\sphinxcrossref{\DUrole{std,std-ref}{pull}}}} : pull an image from Docker or Singularity Hub

\item {} 
{\hyperref[\detokenize{appendix:run-command}]{\sphinxcrossref{\DUrole{std,std-ref}{run}}}} : Run your image as an executable

\item {} 
{\hyperref[\detokenize{appendix:shell-command}]{\sphinxcrossref{\DUrole{std,std-ref}{shell}}}} : Shell into your image

\end{itemize}

\sphinxstylestrong{Image Commands}
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:image-import}]{\sphinxcrossref{\DUrole{std,std-ref}{image.import}}}} : import layers or other file content to your image

\item {} 
{\hyperref[\detokenize{appendix:image-export}]{\sphinxcrossref{\DUrole{std,std-ref}{image.export}}}} : export the contents of the image to tar or stream

\item {} 
{\hyperref[\detokenize{appendix:image-create}]{\sphinxcrossref{\DUrole{std,std-ref}{image.create}}}} : create a new image, using the old ext3 filesystem

\item {} 
{\hyperref[\detokenize{appendix:image-expand}]{\sphinxcrossref{\DUrole{std,std-ref}{image.expand}}}} : increase the size of your image (old ext3)

\end{itemize}

\sphinxstylestrong{Instance Commands}

Instances were added in 2.4. This list is brief, and likely to expand
with further development.
\begin{itemize}
\item {} 
{\hyperref[\detokenize{running_services:running-services}]{\sphinxcrossref{\DUrole{std,std-ref}{instances}}}} : Start, stop, and list container instances

\end{itemize}

\sphinxstylestrong{Deprecated Commands}
The following commands are deprecated in 2.4 and will be removed in
future releases.
\begin{itemize}
\item {} 
{\hyperref[\detokenize{appendix:bootstrap}]{\sphinxcrossref{\DUrole{std,std-ref}{bootstrap}}}} : Bootstrap a container recipe

\end{itemize}

For the full usage, {\hyperref[\detokenize{appendix:command-usage}]{\sphinxcrossref{\DUrole{std,std-ref}{see the bottom of this page}}}}


\paragraph{Options and argument processing}
\label{\detokenize{appendix:options-and-argument-processing}}
Because of the nature of how Singularity cascades commands and
sub-commands, argument processing is done with a mandatory order.
\sphinxstylestrong{This means that where you place arguments is important!} In the
above usage example, \sphinxcode{\sphinxupquote{opts1}} are the global Singularity run-time options.
These options are always applicable no matter what subcommand you
select (e.g. \sphinxcode{\sphinxupquote{-{-}verbose}} or \sphinxcode{\sphinxupquote{-{-}debug}} ). But subcommand specific options must be passed
after the relevant subcommand.

To further clarify this example, the \sphinxcode{\sphinxupquote{exec}} Singularity subcommand will
execute a program within the container and pass the arguments passed
to the program. So to mitigate any argument clashes, Singularity must
not interpret or interfere with any of the command arguments or
options that are not relevant for that particular function.


\paragraph{Singularity Help}
\label{\detokenize{appendix:singularity-help}}
Singularity comes with some internal documentation by using the \sphinxcode{\sphinxupquote{help}}
subcommand followed by the subcommand you want more information about.
For example:
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity help create

CREATE OPTIONS:

    \PYGZhy{}s/\PYGZhy{}\PYGZhy{}size   Specify a size for an operation in MiB, i.e. 1024*1024B

                (default 768MiB)

    \PYGZhy{}F/\PYGZhy{}\PYGZhy{}force  Overwrite an image file if it exists


EXAMPLES:


    \PYGZdl{} singularity create /tmp/Debian.img

    \PYGZdl{} singularity create \PYGZhy{}s 4096 /tmp/Debian.img


For additional help, please visit our public documentation pages which are

found at:


    https://www.sylabs.io/docs/
\end{sphinxVerbatim}
\end{quote}


\subsubsection{Commands Usage}
\label{\detokenize{appendix:commands-usage}}\begin{quote}

\def\sphinxLiteralBlockLabel{\label{\detokenize{appendix:sec-commandsusage}}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
USAGE: singularity [global options...] \PYGZlt{}command\PYGZgt{} [command options...] ...


GLOBAL OPTIONS:

    \PYGZhy{}d\textbar{}\PYGZhy{}\PYGZhy{}debug    Print debugging information

    \PYGZhy{}h\textbar{}\PYGZhy{}\PYGZhy{}help     Display usage summary

    \PYGZhy{}s\textbar{}\PYGZhy{}\PYGZhy{}silent   Only print errors

    \PYGZhy{}q\textbar{}\PYGZhy{}\PYGZhy{}quiet    Suppress all normal output

       \PYGZhy{}\PYGZhy{}version  Show application version

    \PYGZhy{}v\textbar{}\PYGZhy{}\PYGZhy{}verbose  Increase verbosity +1

    \PYGZhy{}x\textbar{}\PYGZhy{}\PYGZhy{}sh\PYGZhy{}debug Print shell wrapper debugging information


GENERAL COMMANDS:

    help       Show additional help for a command or container

    selftest   Run some self tests for singularity install


CONTAINER USAGE COMMANDS:

    exec       Execute a command within container

    run        Launch a runscript within container

    shell      Run a Bourne shell within container

    test       Launch a testscript within container


CONTAINER MANAGEMENT COMMANDS:

    apps       List available apps within a container

    bootstrap  *Deprecated* use build instead

    build      Build a new Singularity container

    check      Perform container lint checks

    inspect    Display a container\PYGZsq{}s metadata

    mount      Mount a Singularity container image

    pull       Pull a Singularity/Docker container to \PYGZdl{}PWD


COMMAND GROUPS:

    image      Container image command group

    instance   Persistent instance command group



CONTAINER USAGE OPTIONS:

    see singularity help \PYGZlt{}command\PYGZgt{}


For any additional help or support visit the Singularity

website: https://www.sylabs.io/contact/
\end{sphinxVerbatim}
\end{quote}


\subsubsection{Support}
\label{\detokenize{appendix:support}}
Have a question, or need further information? \sphinxhref{https://www.sylabs.io/contact/}{Reach out to us}.


\subsection{build}
\label{\detokenize{appendix:build}}\label{\detokenize{appendix:build-command}}
Use \sphinxcode{\sphinxupquote{build}} to download and assemble existing containers, convert containers
from one format to another, or build a container from a {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{Singularity recipe}}}}.


\subsubsection{Overview}
\label{\detokenize{appendix:id31}}
The \sphinxcode{\sphinxupquote{build}} command accepts a target as input and produces a container as
output. The target can be a Singularity Hub or Docker Hub URI, a path
to an existing container, or a path to a Singularity Recipe file. The
output container can be in squashfs, ext3, or directory format.

For a complete list of \sphinxcode{\sphinxupquote{build}} options type \sphinxcode{\sphinxupquote{singularity help build}}. For more info on building
containers see {\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{Build a Container}}}}.


\subsubsection{Examples}
\label{\detokenize{appendix:id32}}

\paragraph{Download an existing container from Singularity Hub or Docker Hub}
\label{\detokenize{appendix:download-an-existing-container-from-singularity-hub-or-docker-hub}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity build lolcow.simg shub://GodloveD/lolcow

\PYGZdl{} singularity build lolcow.simg docker://godlovedc/lolcow
\end{sphinxVerbatim}


\paragraph{Create \textendash{}writable images and \textendash{}sandbox directories}
\label{\detokenize{appendix:create-writable-images-and-sandbox-directories}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}writable lolcow.img shub://GodloveD/lolcow

\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}sandbox lolcow/ shub://GodloveD/lolcow
\end{sphinxVerbatim}


\paragraph{Convert containers from one format to another}
\label{\detokenize{appendix:convert-containers-from-one-format-to-another}}
You can convert the three supported container formats using any
combination.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build \PYGZhy{}\PYGZhy{}writable development.img production.simg

\PYGZdl{} singularity build \PYGZhy{}\PYGZhy{}sandbox development/ production.simg

\PYGZdl{} singularity build production2 development/
\end{sphinxVerbatim}


\paragraph{Build a container from a Singularity recipe}
\label{\detokenize{appendix:build-a-container-from-a-singularity-recipe}}
Given a Singularity Recipe called \sphinxcode{\sphinxupquote{Singularity}} :

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity build lolcow.simg Singularity
\end{sphinxVerbatim}


\subsection{exec}
\label{\detokenize{appendix:exec}}\label{\detokenize{appendix:exec-command}}
The \sphinxcode{\sphinxupquote{exec}} Singularity sub-command allows you to spawn an arbitrary command
within your container image as if it were running directly on the host
system. All standard IO, pipes, and file systems are accessible via the
command being exec’ed within the container. Note that this exec is
different from the Docker exec, as it does not require a container to be
“running” before using it.


\subsubsection{Examples}
\label{\detokenize{appendix:id33}}

\paragraph{Printing the OS release inside the container}
\label{\detokenize{appendix:printing-the-os-release-inside-the-container}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec container.img cat /etc/os\PYGZhy{}release

PRETTY\PYGZus{}NAME=\PYGZdq{}Debian GNU/Linux 8 (jessie)\PYGZdq{}

NAME=\PYGZdq{}Debian GNU/Linux\PYGZdq{}

VERSION\PYGZus{}ID=\PYGZdq{}8\PYGZdq{}

VERSION=\PYGZdq{}8 (jessie)\PYGZdq{}

ID=debian

HOME\PYGZus{}URL=\PYGZdq{}http://www.debian.org/\PYGZdq{}

SUPPORT\PYGZus{}URL=\PYGZdq{}http://www.debian.org/support\PYGZdq{}

BUG\PYGZus{}REPORT\PYGZus{}URL=\PYGZdq{}https://bugs.debian.org/\PYGZdq{}

\PYGZdl{}
\end{sphinxVerbatim}


\paragraph{Printing the OS release for a running instance}
\label{\detokenize{appendix:printing-the-os-release-for-a-running-instance}}
Use the \sphinxcode{\sphinxupquote{instance://\textless{}instance name\textgreater{}}} syntax like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec instance://my\PYGZhy{}instance cat /etc/os\PYGZhy{}release
\end{sphinxVerbatim}


\paragraph{Runtime Flags}
\label{\detokenize{appendix:runtime-flags}}
If you are interested in containing an environment or filesystem
locations, we highly recommend that you look at the \sphinxcode{\sphinxupquote{singularity run help}} and our
documentation on {\hyperref[\detokenize{appendix:singularity-action-flags}]{\sphinxcrossref{\DUrole{std,std-ref}{flags}}}} to better customize this command.


\paragraph{Special Characters}
\label{\detokenize{appendix:special-characters}}
And properly passing along special characters to the program within the
container.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec container.img echo \PYGZhy{}ne \PYGZdq{}hello\PYGZbs{}nworld\PYGZbs{}n\PYGZbs{}n\PYGZdq{}

hello

world

\PYGZdl{}
\end{sphinxVerbatim}

And a demonstration using pipes:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} cat debian.def \textbar{} singularity exec container.img grep \PYGZsq{}MirrorURL\PYGZsq{}

MirrorURL \PYGZdq{}http://ftp.us.debian.org/debian/\PYGZdq{}

\PYGZdl{}
\end{sphinxVerbatim}


\paragraph{A Python example}
\label{\detokenize{appendix:a-python-example}}
Starting with the file \sphinxcode{\sphinxupquote{hello.py}} in the current directory with the contents of:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}!/usr/bin/python


import sys

print(\PYGZdq{}Hello World: The Python version is \PYGZpc{}s.\PYGZpc{}s.\PYGZpc{}s\PYGZdq{} \PYGZpc{} sys.version\PYGZus{}info[:3])
\end{sphinxVerbatim}

Because our home directory is automatically bound into the container,
and we are running this from our home directory, we can easily execute
that script using the Python within the container:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec /tmp/Centos7\PYGZhy{}ompi.img /usr/bin/python hello.py

Hello World: The Python version is 2.7.5
\end{sphinxVerbatim}

We can also pipe that script through the container and into the Python
binary which exists inside the container using the following command:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} cat hello.py \textbar{} singularity exec /tmp/Centos7\PYGZhy{}ompi.img /usr/bin/python

Hello World: The Python version is 2.7.5
\end{sphinxVerbatim}

For demonstration purposes, let’s also try to use the latest Python
container which exists in DockerHub to run this script:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec docker://python:latest /usr/local/bin/python hello.py

library/python:latest

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:fbd06356349dd9fb6af91f98c398c0c5d05730a9996bbf88ff2f2067d59c70c4

Downloading layer: sha256:644eaeceac9ff6195008c1e20dd693346c35b0b65b9a90b3bcba18ea4bcef071

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:766692404ca72f4e31e248eb82f8eca6b2fcc15b22930ec50e3804cc3efe0aba

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:6a3d69edbe90ef916e1ecd8d197f056de873ed08bcfd55a1cd0b43588f3dbb9a

Downloading layer: sha256:ff18e19c2db42055e6f34323700737bde3c819b413997cddace2c1b7180d7efd

Downloading layer: sha256:7b9457ec39de00bc70af1c9631b9ae6ede5a3ab715e6492c0a2641868ec1deda

Downloading layer: sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4

Downloading layer: sha256:6a5a5368e0c2d3e5909184fa28ddfd56072e7ff3ee9a945876f7eee5896ef5bb

Hello World: The Python version is 3.5.2
\end{sphinxVerbatim}


\paragraph{A GPU example}
\label{\detokenize{appendix:a-gpu-example}}
If your host system has an NVIDIA GPU card and a driver installed you
can leverage the card with the \sphinxcode{\sphinxupquote{-{-}nv}} option. (This example requires a fairly
recent version of the NVIDIA driver on the host system to run the latest
version of TensorFlow.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} git clone https://github.com/tensorflow/models.git

\PYGZdl{} singularity exec \PYGZhy{}\PYGZhy{}nv docker://tensorflow/tensorflow:latest\PYGZhy{}gpu \PYGZbs{}

    python ./models/tutorials/image/mnist/convolutional.py

Docker image path: index.docker.io/tensorflow/tensorflow:latest\PYGZhy{}gpu

Cache folder set to /home/david/.singularity/docker

[19/19] \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Creating container runtime...

Extracting data/train\PYGZhy{}images\PYGZhy{}idx3\PYGZhy{}ubyte.gz

Extracting data/train\PYGZhy{}labels\PYGZhy{}idx1\PYGZhy{}ubyte.gz

Extracting data/t10k\PYGZhy{}images\PYGZhy{}idx3\PYGZhy{}ubyte.gz

Extracting data/t10k\PYGZhy{}labels\PYGZhy{}idx1\PYGZhy{}ubyte.gz

2017\PYGZhy{}08\PYGZhy{}18 20:33:59.677580: W tensorflow/core/platform/cpu\PYGZus{}feature\PYGZus{}guard.cc:45] The TensorFlow library wasn\PYGZsq{}t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.

2017\PYGZhy{}08\PYGZhy{}18 20:33:59.677620: W tensorflow/core/platform/cpu\PYGZus{}feature\PYGZus{}guard.cc:45] The TensorFlow library wasn\PYGZsq{}t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.

2017\PYGZhy{}08\PYGZhy{}18 20:34:00.148531: I tensorflow/stream\PYGZus{}executor/cuda/cuda\PYGZus{}gpu\PYGZus{}executor.cc:893] successful NUMA node read from SysFS had negative value (\PYGZhy{}1), but there must be at least one NUMA node, so returning NUMA node zero

2017\PYGZhy{}08\PYGZhy{}18 20:34:00.148926: I tensorflow/core/common\PYGZus{}runtime/gpu/gpu\PYGZus{}device.cc:955] Found device 0 with properties:

name: GeForce GTX 760 (192\PYGZhy{}bit)

major: 3 minor: 0 memoryClockRate (GHz) 0.8885

pciBusID 0000:03:00.0

Total memory: 2.95GiB

Free memory: 2.92GiB

2017\PYGZhy{}08\PYGZhy{}18 20:34:00.148954: I tensorflow/core/common\PYGZus{}runtime/gpu/gpu\PYGZus{}device.cc:976] DMA: 0

2017\PYGZhy{}08\PYGZhy{}18 20:34:00.148965: I tensorflow/core/common\PYGZus{}runtime/gpu/gpu\PYGZus{}device.cc:986] 0:   Y

2017\PYGZhy{}08\PYGZhy{}18 20:34:00.148979: I tensorflow/core/common\PYGZus{}runtime/gpu/gpu\PYGZus{}device.cc:1045] Creating TensorFlow device (/gpu:0) \PYGZhy{}\PYGZgt{} (device: 0, name: GeForce GTX 760 (192\PYGZhy{}bit), pci bus id: 0000:03:00.0)

Initialized!

Step 0 (epoch 0.00), 21.7 ms

Minibatch loss: 8.334, learning rate: 0.010000

Minibatch error: 85.9\PYGZpc{}

Validation error: 84.6\PYGZpc{}

Step 100 (epoch 0.12), 20.9 ms

Minibatch loss: 3.235, learning rate: 0.010000

Minibatch error: 4.7\PYGZpc{}

Validation error: 7.8\PYGZpc{}

Step 200 (epoch 0.23), 20.5 ms

Minibatch loss: 3.363, learning rate: 0.010000

Minibatch error: 9.4\PYGZpc{}

Validation error: 4.2\PYGZpc{}

[...snip...]

Step 8500 (epoch 9.89), 20.5 ms

Minibatch loss: 1.602, learning rate: 0.006302

Minibatch error: 0.0\PYGZpc{}

Validation error: 0.9\PYGZpc{}

Test error: 0.8\PYGZpc{}
\end{sphinxVerbatim}


\subsection{inspect}
\label{\detokenize{appendix:inspect}}\label{\detokenize{appendix:inspect-command}}
How can you sniff an image? We have provided the inspect command for
you to easily see the runscript, test script, environment, help, and
metadata labels.

This command is essential for making containers understandable by
other tools and applications.


\subsubsection{JSON Api Standard}
\label{\detokenize{appendix:json-api-standard}}
For any inspect command, by adding \sphinxcode{\sphinxupquote{-{-}json}} you can be assured to get a
JSON API standardized response, for example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity inspect \PYGZhy{}l \PYGZhy{}\PYGZhy{}json ubuntu.img

\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}labels\PYGZdq{}: \PYGZob{}

                \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}BOOTSTRAP\PYGZdq{}: \PYGZdq{}docker\PYGZdq{},

                \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZdq{}: \PYGZdq{}Singularity\PYGZdq{},

                \PYGZdq{}SINGULARITY\PYGZus{}BOOTSTRAP\PYGZus{}VERSION\PYGZdq{}: \PYGZdq{}2.2.99\PYGZdq{},

                \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}FROM\PYGZdq{}: \PYGZdq{}ubuntu:latest\PYGZdq{}

            \PYGZcb{}

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}
\end{sphinxVerbatim}


\subsubsection{Inspect Flags}
\label{\detokenize{appendix:inspect-flags}}
The default, if run without any arguments, will show you the container
labels file

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect ubuntu.img

\PYGZob{}

    \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}BOOTSTRAP\PYGZdq{}: \PYGZdq{}docker\PYGZdq{},

    \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZdq{}: \PYGZdq{}Singularity\PYGZdq{},

    \PYGZdq{}SINGULARITY\PYGZus{}BOOTSTRAP\PYGZus{}VERSION\PYGZdq{}: \PYGZdq{}2.2.99\PYGZdq{},

    \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}FROM\PYGZdq{}: \PYGZdq{}ubuntu:latest\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}

and as outlined in the usage, you can specify to see any combination of \sphinxcode{\sphinxupquote{-{-}labels}}
, \sphinxcode{\sphinxupquote{-{-}environment}} , \sphinxcode{\sphinxupquote{-{-}runscript}} , \sphinxcode{\sphinxupquote{-{-}test}} , and \sphinxcode{\sphinxupquote{-{-}deffile}}. The quick command to see everything, in json format, would
be:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}l \PYGZhy{}r \PYGZhy{}d \PYGZhy{}t \PYGZhy{}e \PYGZhy{}j \PYGZhy{}hf ubuntu.img

\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}test\PYGZdq{}: null,

            \PYGZdq{}help\PYGZdq{}: \PYGZdq{}This is how you run the image!\PYGZbs{}n\PYGZdq{},

            \PYGZdq{}environment\PYGZdq{}: \PYGZdq{}\PYGZsh{} Custom environment shell code should follow\PYGZbs{}n\PYGZbs{}n\PYGZdq{},

            \PYGZdq{}labels\PYGZdq{}: \PYGZob{}

                \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}BOOTSTRAP\PYGZdq{}: \PYGZdq{}docker\PYGZdq{},

                \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZdq{}: \PYGZdq{}Singularity\PYGZdq{},

                \PYGZdq{}SINGULARITY\PYGZus{}BOOTSTRAP\PYGZus{}VERSION\PYGZdq{}: \PYGZdq{}2.2.99\PYGZdq{},

                \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}FROM\PYGZdq{}: \PYGZdq{}ubuntu:latest\PYGZdq{}

            \PYGZcb{},

            \PYGZdq{}deffile\PYGZdq{}: \PYGZdq{}Bootstrap:docker\PYGZbs{}nFrom:ubuntu:latest\PYGZbs{}n\PYGZdq{},

            \PYGZdq{}runscript\PYGZdq{}: \PYGZdq{}\PYGZsh{}!/bin/sh\PYGZbs{}n\PYGZbs{}nexec /bin/bash \PYGZbs{}\PYGZdq{}\PYGZdl{}@\PYGZbs{}\PYGZdq{}\PYGZdq{}

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}
\end{sphinxVerbatim}


\paragraph{Labels}
\label{\detokenize{appendix:labels}}
The default, if run without any arguments, will show you the container
labels file (located at \sphinxcode{\sphinxupquote{/.singularity.d/labels.json}} in the container. These labels are the ones that
you define in the \sphinxcode{\sphinxupquote{\%labels}} section of your bootstrap file, along with any Docker \sphinxcode{\sphinxupquote{LABEL}}
that came with an image that you imported, and other metadata about the
bootstrap. For example, here we are inspecting labels for \sphinxcode{\sphinxupquote{ubuntu.img}}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect ubuntu.img

\PYGZob{}

    \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}BOOTSTRAP\PYGZdq{}: \PYGZdq{}docker\PYGZdq{},

    \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZdq{}: \PYGZdq{}Singularity\PYGZdq{},

    \PYGZdq{}SINGULARITY\PYGZus{}BOOTSTRAP\PYGZus{}VERSION\PYGZdq{}: \PYGZdq{}2.2.99\PYGZdq{},

    \PYGZdq{}SINGULARITY\PYGZus{}DEFFILE\PYGZus{}FROM\PYGZdq{}: \PYGZdq{}ubuntu:latest\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}

This is the equivalent of both of:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}l ubuntu.img

\PYGZdl{} singularity inspect \PYGZhy{}\PYGZhy{}labels ubuntu.img
\end{sphinxVerbatim}


\paragraph{Runscript}
\label{\detokenize{appendix:runscript}}
The commands \sphinxcode{\sphinxupquote{-{-}runscript}} or \sphinxcode{\sphinxupquote{-{-}r}} will show you the runscript, which also can be shown in \sphinxcode{\sphinxupquote{-{-}json}}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}r \PYGZhy{}j ubuntu.img\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}runscript\PYGZdq{}: \PYGZdq{}\PYGZsh{}!/bin/sh\PYGZbs{}n\PYGZbs{}nexec /bin/bash \PYGZbs{}\PYGZdq{}\PYGZdl{}@\PYGZbs{}\PYGZdq{}\PYGZdq{}

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}
\end{sphinxVerbatim}

or in a human friendly, readable print to the screen:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}r ubuntu.img


\PYGZsh{}\PYGZsh{}runscript

\PYGZsh{}!/bin/sh


exec /bin/bash \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}


\paragraph{Help}
\label{\detokenize{appendix:help}}
The commands \sphinxcode{\sphinxupquote{-{-}helpfile}} or \sphinxcode{\sphinxupquote{-{-}hf}} will show you the runscript helpfile, if it exists.
With \sphinxcode{\sphinxupquote{-{-}json}} you can also see it as such:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity inspect \PYGZhy{}hf \PYGZhy{}j dino.img

\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}help\PYGZdq{}: \PYGZdq{}\PYGZbs{}n\PYGZbs{}n\PYGZbs{}nHi there! This is my image help section.\PYGZbs{}n\PYGZbs{}nUsage:\PYGZbs{}n\PYGZbs{}nboobeep doo doo\PYGZbs{}n\PYGZbs{}n \PYGZhy{}\PYGZhy{}arg/a arrrrg I\PYGZsq{}m a pirate!\PYGZbs{}n \PYGZhy{}\PYGZhy{}boo/b eeeeeuzzz where is the honey?\PYGZbs{}n\PYGZbs{}n\PYGZbs{}n\PYGZdq{}

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}
\end{sphinxVerbatim}

or in a human friendly, readable print to the screen, don’t use \sphinxcode{\sphinxupquote{-j}} or \sphinxcode{\sphinxupquote{-{-}json}}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}hf dino.img



Hi there! This is my image help section.


Usage:


boobeep doo doo


 \PYGZhy{}\PYGZhy{}arg/a arrrrg I\PYGZsq{}m a pirate!

 \PYGZhy{}\PYGZhy{}boo/b eeeeeuzzz where is the honey?
\end{sphinxVerbatim}


\paragraph{Environment}
\label{\detokenize{appendix:environment}}
The commands \sphinxcode{\sphinxupquote{-{-}environment}} and \sphinxcode{\sphinxupquote{-e}} will show you the container’s environment, again
specified by the \sphinxcode{\sphinxupquote{\%environment}} section of a bootstrap file, and other ENV labels that
might have come from a Docker import. You can again choose to see \sphinxcode{\sphinxupquote{-{-}json}} :

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}e \PYGZhy{}\PYGZhy{}json ubuntu.img

\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}environment\PYGZdq{}: \PYGZdq{}\PYGZsh{} Custom environment shell code should follow\PYGZbs{}n\PYGZbs{}n\PYGZdq{}

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}
\end{sphinxVerbatim}

or human friendly:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}e ubuntu.img


\PYGZsh{}\PYGZsh{}environment

\PYGZsh{} Custom environment shell code should follow
\end{sphinxVerbatim}

The container in the example above did not have any custom environment

variables set.


\paragraph{Test}
\label{\detokenize{appendix:test}}
The equivalent \sphinxcode{\sphinxupquote{-{-}test}} or \sphinxcode{\sphinxupquote{-t}} commands will print any test defined for the
container, which comes from the  \sphinxcode{\sphinxupquote{\%test}} section of the bootstrap specification
Singularity file. Again, we can ask for \sphinxcode{\sphinxupquote{-{-}json}} or human friendly (default):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity \PYGZhy{}\PYGZhy{}inspect \PYGZhy{}t \PYGZhy{}\PYGZhy{}json ubuntu.img

\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}test\PYGZdq{}: null

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}


\PYGZdl{} singularity inspect \PYGZhy{}t  ubuntu.img

\PYGZob{}

    \PYGZdq{}status\PYGZdq{}: 404,

    \PYGZdq{}detail\PYGZdq{}: \PYGZdq{}This container does not have any tests defined\PYGZdq{},

    \PYGZdq{}title\PYGZdq{}: \PYGZdq{}Tests Undefined\PYGZdq{}

\PYGZcb{}
\end{sphinxVerbatim}


\paragraph{Deffile}
\label{\detokenize{appendix:deffile}}
Want to know where your container came from? You can see the entire
Singularity definition file, if the container was created with a
bootstrap, by using \sphinxcode{\sphinxupquote{-{-}deffile}} or \sphinxcode{\sphinxupquote{-d}}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}d  ubuntu.img


\PYGZsh{}\PYGZsh{}deffile

Bootstrap:docker

From:ubuntu:latest
\end{sphinxVerbatim}

or with \sphinxcode{\sphinxupquote{-{-}json}} output.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity inspect \PYGZhy{}d \PYGZhy{}\PYGZhy{}json ubuntu.img

\PYGZob{}

    \PYGZdq{}data\PYGZdq{}: \PYGZob{}

        \PYGZdq{}attributes\PYGZdq{}: \PYGZob{}

            \PYGZdq{}deffile\PYGZdq{}: \PYGZdq{}Bootstrap:docker\PYGZbs{}nFrom:ubuntu:latest\PYGZbs{}n\PYGZdq{}

        \PYGZcb{},

        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}container\PYGZdq{}

    \PYGZcb{}

\PYGZcb{}
\end{sphinxVerbatim}

The goal of these commands is to bring more transparency to containers,
and to help better integrate them into common workflows by having them
expose their guts to the world! If you have feedback for how we can
improve or amend this, \sphinxhref{https://github.com/singularityware/singularity/issues}{please let us know}!


\subsection{pull}
\label{\detokenize{appendix:pull}}\label{\detokenize{appendix:pull-command}}\phantomsection\label{\detokenize{appendix:sec-pull}}
Singularity \sphinxcode{\sphinxupquote{pull}} is the command that you would want to use to communicate
with a container registry. The command does exactly as it says - there
exists an image external to my host, and I want to pull it here. We
currently support pull for both \sphinxhref{https://hub.docker.com/}{Docker} and \sphinxhref{https://singularity-hub.org/}{Singularity Hub
images}, and will review usage for both.


\subsubsection{Singularity Hub}
\label{\detokenize{appendix:singularity-hub}}
Singularity differs from Docker in that we serve entire images, as
opposed to layers. This means that pulling a Singularity Hub means
downloading the entire (compressed) container file, and then having it
extract on your local machine. The basic command is the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull shub://vsoch/hello\PYGZhy{}world

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Done. Container is at: ./vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.img
\end{sphinxVerbatim}


\paragraph{How do tags work?}
\label{\detokenize{appendix:how-do-tags-work}}
On Singularity Hub, a \sphinxcode{\sphinxupquote{tag}} coincide with a branch. So if you have a repo
called \sphinxcode{\sphinxupquote{vsoch/hello-world}} , by default the file called \sphinxcode{\sphinxupquote{Singularity}} (your build recipe file) will be
looked for in the base of the master branch. The command that we issued
above would be equivalent to doing:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull shub://vsoch/hello\PYGZhy{}world:master
\end{sphinxVerbatim}

To enable other branches to build, they must be turned on in your
collection. If you then put another Singularity file in a branch called development,
you would pull it as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull shub://vsoch/hello\PYGZhy{}world:development
\end{sphinxVerbatim}

The term \sphinxcode{\sphinxupquote{latest}} in Singularity Hub will pull, across all of your
branches, the most recent image. If \sphinxcode{\sphinxupquote{development}} is more recent than
\sphinxcode{\sphinxupquote{master}}, it would be pulled, for example.


\paragraph{Image Names}
\label{\detokenize{appendix:image-names}}
As you can see, since we didn’t specify anything special, the default
naming convention is to use the username, reponame, and the branch
(tag). You have three options for changing this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
PULL OPTIONS:

    \PYGZhy{}n/\PYGZhy{}\PYGZhy{}name   Specify a custom container name (first priority)

    \PYGZhy{}C/\PYGZhy{}\PYGZhy{}commit Name container based on GitHub commit (second priority)

    \PYGZhy{}H/\PYGZhy{}\PYGZhy{}hash   Name container based on file hash (second priority)
\end{sphinxVerbatim}


\paragraph{Custom Name}
\label{\detokenize{appendix:custom-name}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull \PYGZhy{}\PYGZhy{}name meatballs.img shub://vsoch/hello\PYGZhy{}world

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Done. Container is at: ./meatballs.img
\end{sphinxVerbatim}


\paragraph{Name by commit}
\label{\detokenize{appendix:name-by-commit}}
Each container build on Singularity Hub is associated with the GitHub
commit of the repo that was used to build it. You can specify to name
your container based on the commit with the \sphinxcode{\sphinxupquote{-{-}commit}} flag, if, for example, you
want to match containers to their build files:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull \PYGZhy{}\PYGZhy{}commit shub://vsoch/hello\PYGZhy{}world

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Done. Container is at: ./4187993b8b44cbfa51c7e38e6b527918fcdf0470.img
\end{sphinxVerbatim}


\paragraph{Name by hash}
\label{\detokenize{appendix:name-by-hash}}
If you prefer the hash of the file itself, you can do that too.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull \PYGZhy{}\PYGZhy{}hash shub://vsoch/hello\PYGZhy{}world

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Done. Container is at: ./4db5b0723cfd378e332fa4806dd79e31.img
\end{sphinxVerbatim}


\paragraph{Pull to different folder}
\label{\detokenize{appendix:pull-to-different-folder}}
For any of the above, if you want to specify a different folder for
your image, you can define the variable \sphinxcode{\sphinxupquote{SINGULARITY\_PULLFOLDER}}. By default, we will first
check if you have the \sphinxcode{\sphinxupquote{SINGULARITY\_CACHEDIR}} defined, and pull images there. If not, we look
for \sphinxcode{\sphinxupquote{SINGULARITY\_PULLFOLDER}}. If neither of these are defined, the image is pulled to the
present working directory, as we showed above. Here is an example of
pulling to \sphinxcode{\sphinxupquote{/tmp}} .

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
SINGULARITY\PYGZus{}PULLFOLDER=/tmp

singularity pull shub://vsoch/hello\PYGZhy{}world

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Done. Container is at: /tmp/vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.img
\end{sphinxVerbatim}


\paragraph{Pull by commit}
\label{\detokenize{appendix:pull-by-commit}}
You can also pull different versions of your container by using their
commit id ( \sphinxcode{\sphinxupquote{version}} ).

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull shub://vsoch/hello\PYGZhy{}world@42e1f04ed80217895f8c960bdde6bef4d34fab59

Progress \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Done. Container is at: ./vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.img
\end{sphinxVerbatim}

In this example, the first build of this container will be pulled.


\subsubsection{Docker}
\label{\detokenize{appendix:id34}}
Docker pull is similar (on the surface) to a Singularity Hub pull, and
we would do the following:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull docker://ubuntu

Initializing Singularity image subsystem

Opening image file: ubuntu.img

Creating 223MiB image

Binding image to loop

Creating file system within image

Image is done: ubuntu.img

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /home/vanessa/.singularity/docker

Importing: base Singularity environment

Importing: /home/vanessa/.singularity/docker/sha256:b6f892c0043b37bd1834a4a1b7d68fe6421c6acbc7e7e63a4527e1d379f92c1b.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:55010f332b047687e081a9639fac04918552c144bc2da4edb3422ce8efcc1fb1.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:2955fb827c947b782af190a759805d229cfebc75978dba2d01b4a59e6a333845.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:3deef3fcbd3072b45771bd0d192d4e5ff2b7310b99ea92bce062e01097953505.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:cf9722e506aada1109f5c00a9ba542a81c9e109606c01c81f5991b1f93de7b66.tar.gz

Importing: /home/vanessa/.singularity/metadata/sha256:fe44851d529f465f9aa107b32351c8a0a722fc0619a2a7c22b058084fac068a4.tar.gz

Done. Container is at: ubuntu.img
\end{sphinxVerbatim}

If you specify the tag, the image would be named accordingly (eg, \sphinxcode{\sphinxupquote{ubuntu-latest.img}}). Did
you notice that the output looks similar to if we did the following?

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity create ubuntu.img

singularity import ubuntu.img docker://ubuntu
\end{sphinxVerbatim}

this is because the same logic is happening on the back end. Thus, the
pull command with a docker uri also supports arguments \sphinxcode{\sphinxupquote{-{-}size}} and \sphinxcode{\sphinxupquote{-{-}name}} . Here is how I
would pull an ubuntu image, but make it bigger, and name it something
else.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity pull \PYGZhy{}\PYGZhy{}size 2000 \PYGZhy{}\PYGZhy{}name jellybelly.img docker://ubuntu

Initializing Singularity image subsystem

Opening image file: jellybelly.img

Creating 2000MiB image

Binding image to loop

Creating file system within image

Image is done: jellybelly.img

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /home/vanessa/.singularity/docker

Importing: base Singularity environment

Importing: /home/vanessa/.singularity/docker/sha256:b6f892c0043b37bd1834a4a1b7d68fe6421c6acbc7e7e63a4527e1d379f92c1b.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:55010f332b047687e081a9639fac04918552c144bc2da4edb3422ce8efcc1fb1.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:2955fb827c947b782af190a759805d229cfebc75978dba2d01b4a59e6a333845.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:3deef3fcbd3072b45771bd0d192d4e5ff2b7310b99ea92bce062e01097953505.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:cf9722e506aada1109f5c00a9ba542a81c9e109606c01c81f5991b1f93de7b66.tar.gz

Importing: /home/vanessa/.singularity/metadata/sha256:fe44851d529f465f9aa107b32351c8a0a722fc0619a2a7c22b058084fac068a4.tar.gz

Done. Container is at: jellybelly.img
\end{sphinxVerbatim}


\subsection{run}
\label{\detokenize{appendix:run}}\label{\detokenize{appendix:run-command}}
It’s common to want your container to “do a thing.” Singularity \sphinxcode{\sphinxupquote{run}} allows
you to define a custom action to be taken when a container is either \sphinxcode{\sphinxupquote{run}} or
executed directly by file name. Specifically, you might want it to
execute a command, or run an executable that gives access to many
different functions for the user.


\subsubsection{Overview}
\label{\detokenize{appendix:id35}}
First, how do we run a container? We can do that in one of two ways -
the commands below are identical:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run centos7.img

\PYGZdl{} ./centos7.img
\end{sphinxVerbatim}

In both cases, we are executing the container’s “runscript” (the
executable \sphinxcode{\sphinxupquote{/singularity}} at the root of the image) that is either an actual file
(version 2.2 and earlier) or a link to one (2.3 and later). For example,
looking at a 2.3 image, I can see the runscript via the path to the
link:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec centos7.img cat /singularity

\PYGZsh{}!/bin/sh


exec /bin/bash \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}

or to the actual file in the container’s metadata folder, \sphinxcode{\sphinxupquote{/.singularity.d}}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec centos7.img cat /.singularity.d/runscript

\PYGZsh{}!/bin/sh


exec /bin/bash \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}

Notice how the runscript has bash followed by \sphinxcode{\sphinxupquote{\textbackslash{}\$@}} ? This is good practice
to include in a runscript, as any arguments passed by the user will be
given to the container.


\subsubsection{Runtime Flags}
\label{\detokenize{appendix:id36}}
If you are interested in containing an environment or filesystem
locations, we highly recommend that you look at the \sphinxcode{\sphinxupquote{singularity run help}} and our
documentation on {\hyperref[\detokenize{appendix:singularity-action-flags}]{\sphinxcrossref{\DUrole{std,std-ref}{flags}}}}
to better customize this command.


\subsubsection{Examples}
\label{\detokenize{appendix:id37}}
In this example the container has a very simple runscript defined.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec centos7.img cat /singularity

\PYGZsh{}!/bin/sh


echo motorbot


\PYGZdl{} singularity run centos7.img

motorbot
\end{sphinxVerbatim}


\paragraph{Defining the Runscript}
\label{\detokenize{appendix:defining-the-runscript}}
When you first create a container, the runscript is defined using the
following order of operations:
\begin{enumerate}
\item {} 
A user defined runscript in the \sphinxcode{\sphinxupquote{\%runscript}} section of a bootstrap takes
preference over all

\item {} 
If the user has not defined a runscript and is importing a Docker
container, the Docker \sphinxcode{\sphinxupquote{ENTRYPOINT}} is used.

\item {} 
If a user has not defined a runscript and adds \sphinxcode{\sphinxupquote{IncludeCmd: yes}} to the bootstrap file,
the \sphinxcode{\sphinxupquote{CMD}} is used over the \sphinxcode{\sphinxupquote{ENTRYPOINT}}

\item {} 
If the user has not defined a runscript and the Docker container

\end{enumerate}
\begin{quote}

doesn’t have an \sphinxcode{\sphinxupquote{ENTRYPOINT}}, we look for \sphinxcode{\sphinxupquote{CMD}}, even if the user hasn’t asked for it.
\end{quote}
\begin{enumerate}
\item {} 
If the user has not defined a runscript, and there is no \sphinxcode{\sphinxupquote{ENTRYPOINT}} or \sphinxcode{\sphinxupquote{CMD}} (or we
aren’t importing Docker at all) then we default to \sphinxcode{\sphinxupquote{/bin/bash}}

\end{enumerate}

Here is how you would define the runscript section when you {\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}} an image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu:latest


\PYGZpc{}runscript

exec /usr/bin/python \PYGZdq{}\PYGZdl{}@\PYGZdq{}
\end{sphinxVerbatim}

and of course python should be installed as /usr/bin/python. The
addition of \sphinxcode{\sphinxupquote{\$@}} ensures that arguments are passed along from the user. If
you want your container to run absolutely any command given to it, and
you want to use run instead of exec, you could also just do:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap: docker

From: ubuntu:latest


\PYGZpc{}runscript

exec \PYGZdq{}\PYGZdl{}@\PYGZdq{}{}`
\end{sphinxVerbatim}

If you want different entrypoints for your image, we recommend using the
\%apprun syntax (see \DUrole{xref,std,std-ref}{apps}). Here we have two entrypoints for foo and bar:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}runscript

exec echo \PYGZdq{}Try running with \PYGZhy{}\PYGZhy{}app dog/cat\PYGZdq{}


\PYGZpc{}apprun dog

exec echo Hello \PYGZdq{}\PYGZdl{}@\PYGZdq{}, this is Dog


\PYGZpc{}apprun cat

exec echo Meow \PYGZdq{}\PYGZdl{}@\PYGZdq{}, this is Cat
\end{sphinxVerbatim}

and then running (after build of a complete recipe) would look like:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build catdog.simg Singularity


\PYGZdl{} singularity run catdog.simg

Try running with \PYGZhy{}\PYGZhy{}app dog/cat


\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}app cat catdog.simg

Meow , this is Cat

\PYGZdl{} singularity run \PYGZhy{}\PYGZhy{}app dog catdog.simg

Hello , this is Dog
\end{sphinxVerbatim}

Generally, it is advised to provide help for your container with \sphinxcode{\sphinxupquote{\%help}} or \sphinxcode{\sphinxupquote{\%apphelp}}. If
you find it easier, you can also provide help by way of a runscript that
tells your user how to use the container, and gives access to the
important executables. Regardless of your strategy. a reproducible
container is one that tells the user how to interact with it.


\subsection{shell}
\label{\detokenize{appendix:shell}}\label{\detokenize{appendix:shell-command}}
The \sphinxcode{\sphinxupquote{shell}} Singularity sub-command will automatically spawn an interactive
shell within a container. As of v2.3 the default that is spawned via the
shell command is \sphinxcode{\sphinxupquote{/bin/bash}} if it exists otherwise \sphinxcode{\sphinxupquote{/bin/sh}} is called.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell

USAGE: singularity (options) shell [container image] (options)
\end{sphinxVerbatim}

Here we can see the default shell in action:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell centos7.img

Singularity: Invoking an interactive shell within container...


Singularity centos7.img:\PYGZti{}\PYGZgt{} echo \PYGZdl{}SHELL

/bin/bash
\end{sphinxVerbatim}

Additionally any arguments passed to the Singularity command (after the
container name) will be passed to the called shell within the container,
and shell can be used across image types. Here is a quick example of
shelling into a container assembled from Docker layers. We highly
recommend that you look at the \sphinxcode{\sphinxupquote{singularity shell help}} and our documentation on {\hyperref[\detokenize{appendix:singularity-action-flags}]{\sphinxcrossref{\DUrole{std,std-ref}{flags}}}} to
better customize this command.


\subsubsection{Change your shell}
\label{\detokenize{appendix:change-your-shell}}
The \sphinxcode{\sphinxupquote{shell}} sub-command allows you to set or change the default shell using the \sphinxcode{\sphinxupquote{-{-}shell}}
argument. As of Singularity version 2.2, you can also use the
environment variable \sphinxcode{\sphinxupquote{SINGULARITY\_SHELL}} which will use that as your shell entry point into
the container.


\paragraph{Bash}
\label{\detokenize{appendix:bash}}
The correct way to do it:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
export SINGULARITY\PYGZus{}SHELL=\PYGZdq{}/bin/bash \PYGZhy{}\PYGZhy{}norc\PYGZdq{}

singularity shell centos7.img Singularity: Invoking an interactive shell within container...

Singularity centos7.img:\PYGZti{}/Desktop\PYGZgt{} echo \PYGZdl{}SHELL

/bin/bash \PYGZhy{}\PYGZhy{}norc
\end{sphinxVerbatim}

Don’t do this, it can be confusing:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} export SINGULARITY\PYGZus{}SHELL=/bin/bash

\PYGZdl{} singularity shell centos7.img

Singularity: Invoking an interactive shell within container...


\PYGZsh{} What? We are still on my Desktop? Actually no, but the uri says we are!

vanessa@vanessa\PYGZhy{}ThinkPad\PYGZhy{}T460s:\PYGZti{}/Desktop\PYGZdl{} echo \PYGZdl{}SHELL

/bin/bash
\end{sphinxVerbatim}

Depending on your shell, you might also want the \sphinxcode{\sphinxupquote{-{-}noprofile}} flag. How can you learn
more about a shell? Ask it for help, of course!


\subsubsection{Shell Help}
\label{\detokenize{appendix:shell-help}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell centos7.img \PYGZhy{}\PYGZhy{}help

Singularity: Invoking an interactive shell within container...


GNU bash, version 4.2.46(1)\PYGZhy{}release\PYGZhy{}(x86\PYGZus{}64\PYGZhy{}redhat\PYGZhy{}linux\PYGZhy{}gnu)

Usage:  /bin/bash [GNU long option] [option] ...

    /bin/bash [GNU long option] [option] script\PYGZhy{}file ...

GNU long options:

    \PYGZhy{}\PYGZhy{}debug

    \PYGZhy{}\PYGZhy{}debugger

    \PYGZhy{}\PYGZhy{}dump\PYGZhy{}po\PYGZhy{}strings

    \PYGZhy{}\PYGZhy{}dump\PYGZhy{}strings

    \PYGZhy{}\PYGZhy{}help

    \PYGZhy{}\PYGZhy{}init\PYGZhy{}file

    \PYGZhy{}\PYGZhy{}login

    \PYGZhy{}\PYGZhy{}noediting

    \PYGZhy{}\PYGZhy{}noprofile

    \PYGZhy{}\PYGZhy{}norc

    \PYGZhy{}\PYGZhy{}posix

    \PYGZhy{}\PYGZhy{}protected

    \PYGZhy{}\PYGZhy{}rcfile

    \PYGZhy{}\PYGZhy{}rpm\PYGZhy{}requires

    \PYGZhy{}\PYGZhy{}restricted

    \PYGZhy{}\PYGZhy{}verbose

    \PYGZhy{}\PYGZhy{}version

Shell options:

    \PYGZhy{}irsD or \PYGZhy{}c command or \PYGZhy{}O shopt\PYGZus{}option      (invocation only)

    \PYGZhy{}abefhkmnptuvxBCHP or \PYGZhy{}o option

Type {}`/bin/bash \PYGZhy{}c \PYGZdq{}help set\PYGZdq{}\PYGZsq{} for more information about shell options.

Type {}`/bin/bash \PYGZhy{}c help\PYGZsq{} for more information about shell builtin commands.
\end{sphinxVerbatim}

And thus we should be able to do:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell centos7.img \PYGZhy{}c \PYGZdq{}echo hello world\PYGZdq{}

Singularity: Invoking an interactive shell within container...


hello world
\end{sphinxVerbatim}


\section{Image Command Group}
\label{\detokenize{appendix:image-command-group}}

\subsection{image.export}
\label{\detokenize{appendix:image-export}}\label{\detokenize{appendix:id38}}\phantomsection\label{\detokenize{appendix:sec-imageexport}}
Export is a way to dump the contents of your container into a \sphinxcode{\sphinxupquote{.tar.gz}}, or a
stream to put into some other place. For example, you could stream
this into an in memory tar in python. Importantly, this command was
originally intended for Singularity version less than 2.4 in the case
of exporting an ext3 filesystem. For Singularity greater than 2.4, the
resulting export file is likely to be larger than the original
squashfs counterpart. An example with an ext3 image is provided.

Here we export an image into a \sphinxcode{\sphinxupquote{.tar}} file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity image.export container.img \PYGZgt{} container.tar
\end{sphinxVerbatim}

We can also specify the file with \sphinxcode{\sphinxupquote{-{-}file}}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity image.export \PYGZhy{}\PYGZhy{}file container.tar container.img
\end{sphinxVerbatim}

And here is the recommended way to compress your image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity image.export container.img \textbar{} gzip \PYGZhy{}9 \PYGZgt{} container.img.tar.gz
\end{sphinxVerbatim}


\subsection{image.expand}
\label{\detokenize{appendix:image-expand}}\label{\detokenize{appendix:id39}}\phantomsection\label{\detokenize{appendix:sec-imageexpand}}
While the squashfs filesystem means that you typically don’t need to
worry about the size of your container being built, you might find that
if you are building an ext3 image (pre Singularity 2.4) you want to
expand it.


\subsubsection{Increasing the size of an existing image}
\label{\detokenize{appendix:increasing-the-size-of-an-existing-image}}
You can increase the size of an image after it has been instantiated
by using the image.expand Singularity sub-command. In the example
below, we:
\begin{enumerate}
\item {} 
create an empty image

\item {} 
inspect it’s size

\item {} 
expand it

\item {} 
confirm it’s larger

\end{enumerate}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity image.create container.img

Creating empty 768MiB image file: container.imglarity image.create container.im

Formatting image with ext3 file system

Image is done: container.img


\PYGZdl{} ls \PYGZhy{}lh container.img

\PYGZhy{}rw\PYGZhy{}rw\PYGZhy{}r\PYGZhy{}\PYGZhy{} 1 vanessa vanessa 768M Oct  2 18:48 container.img


\PYGZdl{} singularity image.expand container.img

Expanding image by 768MB

Checking image\PYGZsq{}s file system

e2fsck 1.42.13 (17\PYGZhy{}May\PYGZhy{}2015)

Pass 1: Checking inodes, blocks, and sizes

Pass 2: Checking directory structure

Pass 3: Checking directory connectivity

Pass 4: Checking reference counts

Pass 5: Checking group summary information

container.img: 11/49152 files (0.0\PYGZpc{} non\PYGZhy{}contiguous), 7387/196608 blocks

Resizing image\PYGZsq{}s file system

resize2fs 1.42.13 (17\PYGZhy{}May\PYGZhy{}2015)

Resizing the filesystem on container.img to 393216 (4k) blocks.

The filesystem on container.img is now 393216 (4k) blocks long.

Image is done: container.img


\PYGZdl{} ls \PYGZhy{}lh container.img

\PYGZhy{}rw\PYGZhy{}rw\PYGZhy{}r\PYGZhy{}\PYGZhy{} 1 vanessa vanessa 1.5G Oct  2 18:48 container.img
\end{sphinxVerbatim}

Similar to the create sub-command, you can override the default size
increase (which is 768MiB) by using the \sphinxcode{\sphinxupquote{-{-}size}} option.


\subsection{image.import}
\label{\detokenize{appendix:image-import}}\label{\detokenize{appendix:id40}}\phantomsection\label{\detokenize{appendix:sec-imageimport}}
Singularity import is essentially taking a dump of files and folders
and adding them to your image. This works for local compressed things
(e.g., tar.gz) but also for docker image layers that you don’t have on
your system. As of version 2.3, import of docker layers includes the
environment and metadata without needing sudo. It’s generally very
intuitive.

As an example, here is a common use case: wanting to import a Docker
image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity image.import container.img docker://ubuntu:latest
\end{sphinxVerbatim}


\subsection{image.create}
\label{\detokenize{appendix:image-create}}\label{\detokenize{appendix:id41}}\phantomsection\label{\detokenize{appendix:sec-imagecreate}}
A Singularity image, which can be referred to as a “container,” is a
single file that contains a virtual file system. As of Singularity
2.4, we strongly recommend that you build (create and install) an
image using {\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}}. If you have reason to create an empty image, or use
create for any other reason, the original \sphinxcode{\sphinxupquote{create}} command is replaced with a
more specific \sphinxcode{\sphinxupquote{image.create}}. After creating an image you can install an operating
system, applications, and save meta-data with it.

Whereas Docker assembles images from layers that are stored on your
computer (viewed with the \sphinxcode{\sphinxupquote{docker history}} command), a Singularity image is just one
file that can sit on your Desktop, in a folder on your cluster, or
anywhere. Having Singularity containers housed within a single image
file greatly simplifies management tasks such as sharing, copying, and
branching your containers. It also means that standard Linux file
system concepts like permissions, ownership, and ACLs apply to the
container (e.g. I can give read only access to a colleague, or block
access completely with a simple \sphinxcode{\sphinxupquote{chmod}} command).


\subsubsection{Creating a new blank Singularity container image}
\label{\detokenize{appendix:creating-a-new-blank-singularity-container-image}}\begin{quote}

Singularity will create a default container image of 768MiB using the
following command:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity image.create container.img

Creating empty 768MiB image file: container.img

Formatting image with ext3 file system

Image is done: container.img
\end{sphinxVerbatim}

How big is it?

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} du \PYGZhy{}sh container.img

29M     container.img
\end{sphinxVerbatim}

Create will make an \sphinxcode{\sphinxupquote{ext3}} filesystem. Let’s create and import a docker base
(the pre-2.4 way with two commands), and then compare to just building
(one command) from the same base.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity create container.img

sudo singularity bootstrap container.img docker://ubuntu


...


\PYGZdl{} du \PYGZhy{}sh container.img

769M
\end{sphinxVerbatim}

Prior to 2.4, you would need to provide a \sphinxcode{\sphinxupquote{-{-}size}} to change from the default:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity create \PYGZhy{}\PYGZhy{}size 2048 container2.img

Initializing Singularity image subsystem

Opening image file: container2.img

Creating 2048MiB image

Binding image to loop

Creating file system within image

Image is done: container2.img


\PYGZdl{} ls \PYGZhy{}lh container*.img

\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x 1 user group 2.1G Apr 15 11:34 container2.img

\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x 1 user group 769M Apr 15 11:11 container.img
\end{sphinxVerbatim}

Now let’s compare to if we just built, without needing to specify a
size.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sudo singularity build container.simg docker://ubuntu


...


du \PYGZhy{}sh container.simg

45M container.simg
\end{sphinxVerbatim}
\end{quote}

Quite a difference! And one command instead of one.


\paragraph{Overwriting an image with a new one}
\label{\detokenize{appendix:overwriting-an-image-with-a-new-one}}\begin{quote}

For any commands that If you have already created an image and wish to
overwrite it, you can do so with the \sphinxcode{\sphinxupquote{-{-}force}} option.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity image.create container.img

ERROR: Image file exists, not overwriting.



\PYGZdl{} singularity image.create \PYGZhy{}\PYGZhy{}force container.img

Creating empty 768MiB image file: container.img

Formatting image with ext3 file system

Image is done: container.img
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{@GodLoveD}} has provided a nice interactive demonstration of creating an image (pre
2.4).
\end{quote}


\section{Instance Command Group}
\label{\detokenize{appendix:instance-command-group}}\label{\detokenize{appendix:id42}}

\subsection{instance.start}
\label{\detokenize{appendix:instance-start}}\label{\detokenize{appendix:sec-instances}}\phantomsection\label{\detokenize{appendix:sec-instancestart}}
New in Singularity version 2.4 you can use the \sphinxcode{\sphinxupquote{instance}} command group to run
instances of containers in the background. This is useful for running
services like databases and web servers. The \sphinxcode{\sphinxupquote{instance.start}} command lets you initiate a
named instance in the background.


\subsubsection{Overview}
\label{\detokenize{appendix:id43}}
To initiate a named instance of a container, you must call the \sphinxcode{\sphinxupquote{instance.start}} command
with 2 arguments: the name of the container that you want to start and a
unique name for an instance of that container. Once the new instance is
running, you can join the container’s namespace using a URI style syntax
like so:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell instance://\PYGZlt{}instance\PYGZus{}name\PYGZgt{}
\end{sphinxVerbatim}

You can specify options such as bind mounts, overlays, or custom
namespaces when you initiate a new instance of a container with
instance.start. These options will persist as long as the container
runs.

For a complete list of options see the output of:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity help instance.start
\end{sphinxVerbatim}


\subsubsection{Examples}
\label{\detokenize{appendix:id44}}
These examples use a container from Singularity Hub, but you can use
local containers or containers from Docker Hub as well. For a more
detailed look at \sphinxcode{\sphinxupquote{instance}} usage see {\hyperref[\detokenize{running_services:running-services}]{\sphinxcrossref{\DUrole{std,std-ref}{Running Instances}}}}.


\paragraph{Start an instance called cow1 from a container on Singularity Hub}
\label{\detokenize{appendix:start-an-instance-called-cow1-from-a-container-on-singularity-hub}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start shub://GodloveD/lolcow cow1
\end{sphinxVerbatim}


\paragraph{Start an interactive shell within the instance that you just started}
\label{\detokenize{appendix:start-an-interactive-shell-within-the-instance-that-you-just-started}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity shell instance://cow1

Singularity GodloveD\PYGZhy{}lolcow\PYGZhy{}master.img:\PYGZti{}\PYGZgt{} ps \PYGZhy{}ef

UID        PID  PPID  C STIME TTY          TIME CMD

ubuntu       1     0  0 20:03 ?        00:00:00 singularity\PYGZhy{}instance: ubuntu [cow1]

ubuntu       3     0  0 20:04 pts/0    00:00:00 /bin/bash \PYGZhy{}\PYGZhy{}norc

ubuntu       4     3  0 20:04 pts/0    00:00:00 ps \PYGZhy{}ef

Singularity GodloveD\PYGZhy{}lolcow\PYGZhy{}master.img:\PYGZti{}\PYGZgt{} exit
\end{sphinxVerbatim}


\paragraph{Execute the runscript within the instance}
\label{\detokenize{appendix:execute-the-runscript-within-the-instance}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity run instance://cow1

 \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

/ Clothes make the man. Naked people have \PYGZbs{}

\textbar{} little or no influence on society.      \textbar{}

\textbar{}                                         \textbar{}

\PYGZbs{} \PYGZhy{}\PYGZhy{} Mark Twain                           /

 \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

        \PYGZbs{}   \PYGZca{}\PYGZus{}\PYGZus{}\PYGZca{}

         \PYGZbs{}  (oo)\PYGZbs{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

            (\PYGZus{}\PYGZus{})\PYGZbs{}       )\PYGZbs{}/\PYGZbs{}

                \textbar{}\textbar{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}w \textbar{}

                \textbar{}\textbar{}     \textbar{}\textbar{}
\end{sphinxVerbatim}


\paragraph{Run a command within a running instance}
\label{\detokenize{appendix:run-a-command-within-a-running-instance}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity exec instance://cow1 cowsay \PYGZdq{}I like blending into the background\PYGZdq{}

 \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

\PYGZlt{} I like blending into the background \PYGZgt{}

 \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

        \PYGZbs{}   \PYGZca{}\PYGZus{}\PYGZus{}\PYGZca{}

         \PYGZbs{}  (oo)\PYGZbs{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

            (\PYGZus{}\PYGZus{})\PYGZbs{}       )\PYGZbs{}/\PYGZbs{}

                \textbar{}\textbar{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}w \textbar{}

                \textbar{}\textbar{}     \textbar{}\textbar{}
\end{sphinxVerbatim}


\subsection{instance.list}
\label{\detokenize{appendix:instance-list}}\phantomsection\label{\detokenize{appendix:sec-instancelist}}
New in Singularity version 2.4 you can use the \sphinxcode{\sphinxupquote{instance}} command group to run
instances of containers in the background. This is useful for running
services like databases and web servers. The \sphinxcode{\sphinxupquote{instance.list}} command lets you keep track
of the named instances running in the background.


\subsubsection{Overview}
\label{\detokenize{appendix:id45}}
After initiating one or more named instances to run in the background
with the \sphinxcode{\sphinxupquote{instance.start}} command you can list them with the \sphinxcode{\sphinxupquote{instance.list}} command.


\subsubsection{Examples}
\label{\detokenize{appendix:id46}}
These examples use a container from Singularity Hub, but you can use
local containers or containers from Docker Hub as well. For a more
detailed look at \sphinxcode{\sphinxupquote{instance}} usage see {\hyperref[\detokenize{running_services:running-services}]{\sphinxcrossref{\DUrole{std,std-ref}{Running Instances}}}}.


\paragraph{Start a few named instances from containers on Singularity Hub}
\label{\detokenize{appendix:start-a-few-named-instances-from-containers-on-singularity-hub}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start shub://GodloveD/lolcow cow1

\PYGZdl{} singularity instance.start shub://GodloveD/lolcow cow2

\PYGZdl{} singularity instance.start shub://vsoch/hello\PYGZhy{}world hiya
\end{sphinxVerbatim}


\paragraph{List running instances}
\label{\detokenize{appendix:list-running-instances}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.list

DAEMON NAME      PID      CONTAINER IMAGE

cow1             20522    /home/ubuntu/GodloveD\PYGZhy{}lolcow\PYGZhy{}master.img

cow2             20558    /home/ubuntu/GodloveD\PYGZhy{}lolcow\PYGZhy{}master.img

hiya             20595    /home/ubuntu/vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.img
\end{sphinxVerbatim}


\subsection{instance.stop}
\label{\detokenize{appendix:instance-stop}}\phantomsection\label{\detokenize{appendix:sec-instancestop}}
New in Singularity version 2.4 you can use the \sphinxcode{\sphinxupquote{instance}} command group to run
instances of containers in the background. This is useful for running
services like databases and web servers. The \sphinxcode{\sphinxupquote{instance.stop}} command lets you stop
instances once you are finished using them


\subsubsection{Overview}
\label{\detokenize{appendix:id47}}
After initiating one or more named instances to run in the background
with the \sphinxcode{\sphinxupquote{instance.start}} command you can stop them with the \sphinxcode{\sphinxupquote{instance.stop}} command.


\subsubsection{Examples}
\label{\detokenize{appendix:id48}}
These examples use a container from Singularity Hub, but you can use
local containers or containers from Docker Hub as well. For a more
detailed look at \sphinxcode{\sphinxupquote{instance}} usage see {\hyperref[\detokenize{running_services:running-services}]{\sphinxcrossref{\DUrole{std,std-ref}{Running Instances}}}}.


\paragraph{Start a few named instances from containers on Singularity Hub}
\label{\detokenize{appendix:id49}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.start shub://GodloveD/lolcow cow1

\PYGZdl{} singularity instance.start shub://GodloveD/lolcow cow2

\PYGZdl{} singularity instance.start shub://vsoch/hello\PYGZhy{}world hiya
\end{sphinxVerbatim}


\paragraph{Stop a single instance}
\label{\detokenize{appendix:stop-a-single-instance}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.stop cow1

Stopping cow1 instance of /home/ubuntu/GodloveD\PYGZhy{}lolcow\PYGZhy{}master.img (PID=20522)
\end{sphinxVerbatim}


\paragraph{Stop all running instances}
\label{\detokenize{appendix:stop-all-running-instances}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity instance.stop \PYGZhy{}\PYGZhy{}all

Stopping cow2 instance of /home/ubuntu/GodloveD\PYGZhy{}lolcow\PYGZhy{}master.img (PID=20558)

Stopping hiya instance of /home/ubuntu/vsoch\PYGZhy{}hello\PYGZhy{}world\PYGZhy{}master.img (PID=20595)
\end{sphinxVerbatim}


\section{Deprecated}
\label{\detokenize{appendix:deprecated}}

\subsection{bootstrap}
\label{\detokenize{appendix:bootstrap}}\label{\detokenize{appendix:id50}}\phantomsection\label{\detokenize{appendix:sec-bootstrap}}
Bootstrapping was the original way (for Singularity versions prior to
2.4) to install an operating system and then configure it appropriately
for a specified need. Bootstrap is very similar to build, except that it
by default uses an \sphinxhref{https://en.wikipedia.org/wiki/Ext3}{ext3} filesystem and allows for writability. The
images unfortunately are not immutable in this way, and can degrade over
time. As of 2.4, bootstrap is still supported for Singularity, however
we encourage you to use {\hyperref[\detokenize{build_a_container:build-a-container}]{\sphinxcrossref{\DUrole{std,std-ref}{build}}}} instead.


\subsubsection{Quick Start}
\label{\detokenize{appendix:quick-start}}
A bootstrap is done based on a Singularity recipe file (a text file
called Singularity) that describes how to specifically build the
container. Here we will overview the sections, best practices, and a
quick example.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity bootstrap

USAGE: singularity [...] bootstrap \PYGZlt{}container path\PYGZgt{} \PYGZlt{}definition file\PYGZgt{}
\end{sphinxVerbatim}

The \sphinxcode{\sphinxupquote{\textless{}container path\textgreater{}}} is the path to the Singularity image file, and the \sphinxcode{\sphinxupquote{\textless{}definition file\textgreater{}}} is the location
of the definition file (the recipe) we will use to create this
container. The process of building a container should always be done
by root so that the correct file ownership and permissions are
maintained. Also, so installation programs check to ensure they are
the root user before proceeding. The bootstrap process may take
anywhere from one minute to one hour depending on what needs to be
done and how fast your network connection is.

Let’s continue with our quick start example. Here is your spec file, \sphinxcode{\sphinxupquote{Singularity}} ,

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Bootstrap:docker

From:ubuntu:latest
\end{sphinxVerbatim}

You next create an image:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity image.create ubuntu.img

Initializing Singularity image subsystem

Opening image file: ubuntu.img

Creating 768MiB image

Binding image to loop

Creating file system within image

Image is done: ubuntu.img
\end{sphinxVerbatim}

and finally run the bootstrap command, pointing to your image ( \sphinxcode{\sphinxupquote{\textless{}container path\textgreater{}}} ) and
the file Singularity ( \sphinxcode{\sphinxupquote{\textless{}definition file\textgreater{}}} ).

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo singularity bootstrap ubuntu.img Singularity

Sanitizing environment

Building from bootstrap definition recipe

Adding base Singularity environment to container

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /root/.singularity/docker

[5/5] \textbar{}===================================\textbar{} 100.0\PYGZpc{}

Exploding layer: sha256:b6f892c0043b37bd1834a4a1b7d68fe6421c6acbc7e7e63a4527e1d379f92c1b.tar.gz

Exploding layer: sha256:55010f332b047687e081a9639fac04918552c144bc2da4edb3422ce8efcc1fb1.tar.gz

Exploding layer: sha256:2955fb827c947b782af190a759805d229cfebc75978dba2d01b4a59e6a333845.tar.gz

Exploding layer: sha256:3deef3fcbd3072b45771bd0d192d4e5ff2b7310b99ea92bce062e01097953505.tar.gz

Exploding layer: sha256:cf9722e506aada1109f5c00a9ba542a81c9e109606c01c81f5991b1f93de7b66.tar.gz

Exploding layer: sha256:fe44851d529f465f9aa107b32351c8a0a722fc0619a2a7c22b058084fac068a4.tar.gz

Finalizing Singularity container
\end{sphinxVerbatim}

Notice that bootstrap does require sudo. If you do an import, with a
docker uri for example, you would see a similar flow, but the calling
user would be you, and the cache your \sphinxcode{\sphinxupquote{\$HOME}}.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} singularity image.create ubuntu.img

singularity import ubuntu.img docker://ubuntu:latest

Docker image path: index.docker.io/library/ubuntu:latest

Cache folder set to /home/vanessa/.singularity/docker

Importing: base Singularity environment

Importing: /home/vanessa/.singularity/docker/sha256:b6f892c0043b37bd1834a4a1b7d68fe6421c6acbc7e7e63a4527e1d379f92c1b.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:55010f332b047687e081a9639fac04918552c144bc2da4edb3422ce8efcc1fb1.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:2955fb827c947b782af190a759805d229cfebc75978dba2d01b4a59e6a333845.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:3deef3fcbd3072b45771bd0d192d4e5ff2b7310b99ea92bce062e01097953505.tar.gz

Importing: /home/vanessa/.singularity/docker/sha256:cf9722e506aada1109f5c00a9ba542a81c9e109606c01c81f5991b1f93de7b66.tar.gz

Importing: /home/vanessa/.singularity/metadata/sha256:fe44851d529f465f9aa107b32351c8a0a722fc0619a2a7c22b058084fac068a4.tar.gz
\end{sphinxVerbatim}

For details and best practices for creating your Singularity recipe, {\hyperref[\detokenize{container_recipes:container-recipes}]{\sphinxcrossref{\DUrole{std,std-ref}{read about them here}}}}.


\chapter{Contributing}
\label{\detokenize{contributing:contributing}}\label{\detokenize{contributing::doc}}

\section{Support Singularity}
\label{\detokenize{contributing:support-singularity}}
Singularity is an open source project, meaning we have the challenge of limited resources.
We are grateful for any support that you might offer to other users in the way of helping with issues, documentation,
or code! If you haven’t already, check out some of the ways to contribute to code and docs:
\begin{itemize}
\item {} 
contribute code

\item {} 
contribute docs

\end{itemize}


\subsection{Singularity Google Group}
\label{\detokenize{contributing:singularity-google-group}}
This is a huge endeavor, and it is greatly appreciated! If you have been using Singularity and having good luck with it,
join our \sphinxhref{https://groups.google.com/a/lbl.gov/forum/\#!forum/singularity}{Google Group}  and help out other users! Post to online communities about Singularity, and request that your distribution vendor,
service provider, and system administrators include Singularity for you!


\subsection{Singularity on Slack}
\label{\detokenize{contributing:singularity-on-slack}}
Many of our users come to slack for quick help with an issue. You can find us at \sphinxhref{https://singularity-container.slack.com/}{singularity-container}.


\section{Contribute to the code}
\label{\detokenize{contributing:contribute-to-the-code}}
To contribute to the development of Singularity, you must:
\begin{itemize}
\item {} 
Own the code and/or have the right to contribute it

\item {} 
Be able to submit software under the 3 clause BSD (or equivalent) license (while other licenses are allowed to be submitted by the license, acceptance of any contribution is up to the project lead)

\item {} 
Read, understand and agree to the license

\item {} 
Have a GitHub account (this just makes it easier on me)

\end{itemize}

We use the traditional \sphinxhref{https://guides.github.com/introduction/flow/}{GitHub Flow} to develop. This means that you fork the repo and checkout a branch to make changes, you submit a pull request (PR) to the development branch with your changes, and the development branch gets merged with master for official releases.
We also have an official \sphinxhref{https://github.com/singularityware/singularity/blob/master/CONTRIBUTING.md}{CONTRIBUTING} document, which also includes a \sphinxhref{https://github.com/singularityware/singularity/blob/master/CONTRIBUTING.md\#code-of-conduct}{code of conduct}  .


\subsection{Step 1. Fork the repo}
\label{\detokenize{contributing:step-1-fork-the-repo}}
To contribute to the web based documentation, you should obtain a GitHub account and fork the \sphinxhref{https://github.com/singularityware/singularity}{Singularity} repository.
Once forked, you will want to clone the fork of the repo to your computer. Let’s say my GitHub username is vsoch, and I am using ssh:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git clone git@github.com:vsoch/singularity.git

cd singularity/
\end{sphinxVerbatim}


\subsection{Step 2. Set up your config}
\label{\detokenize{contributing:step-2-set-up-your-config}}
The GitHub config file, located at .git/config, is the best way to keep track of many different forks of a repository.
I usually open it up right after cloning my fork to add the repository that I forked as a \sphinxhref{https://help.github.com/articles/adding-a-remote/}{remote}, so I can easily get updated from it.
Let’s say my \sphinxcode{\sphinxupquote{.git/config}} first looks like this, after I clone my own branch:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[core]

    repositoryformatversion = 0

    filemode = true

    bare = false

    logallrefupdates = true

[remote \PYGZdq{}origin\PYGZdq{}]

    url = git@github.com:vsoch/singularity

    fetch = +refs/heads/*:refs/remotes/origin/*

[branch \PYGZdq{}master\PYGZdq{}]

    remote = origin

    merge = refs/heads/master
\end{sphinxVerbatim}

I would want to add the upstream repository, which is where I forked from.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[core]

    repositoryformatversion = 0

    filemode = true

    bare = false

    logallrefupdates = true

[remote \PYGZdq{}origin\PYGZdq{}]

    url = git@github.com:vsoch/singularity

    fetch = +refs/heads/*:refs/remotes/origin/*

[remote \PYGZdq{}upstream\PYGZdq{}]

    url = https://github.com/singularityware/singularity

    fetch = +refs/heads/*:refs/remotes/origin/*

[branch \PYGZdq{}master\PYGZdq{}]

    remote = origin

    merge = refs/heads/master
\end{sphinxVerbatim}

I can also add some of my colleagues, if I want to pull from their branches:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[core]

    repositoryformatversion = 0

    filemode = true

    bare = false

    logallrefupdates = true

[remote \PYGZdq{}origin\PYGZdq{}]

    url = git@github.com:vsoch/singularity

    fetch = +refs/heads/*:refs/remotes/origin/*

[remote \PYGZdq{}upstream\PYGZdq{}]

    url = https://github.com/singularityware/singularity

    fetch = +refs/heads/*:refs/remotes/origin/*

[remote \PYGZdq{}greg\PYGZdq{}]

    url = https://github.com/gmkurtzer/singularity

    fetch = +refs/heads/*:refs/remotes/origin/*

[branch \PYGZdq{}master\PYGZdq{}]

    remote = origin

    merge = refs/heads/master
\end{sphinxVerbatim}

In the GitHub flow, the master branch is the frozen, current version of the software.
Your master branch is always in sync with the upstream (our singularityware master), and the singularityware master is always the latest release of

This would mean that I can update my master branch as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git checkout master

git pull upstream master

git push origin master
\end{sphinxVerbatim}

and then I would return to working on the branch for my feature. How to do that exactly? Read on!


\subsection{Step 3. Checkout a new branch}
\label{\detokenize{contributing:step-3-checkout-a-new-branch}}
\sphinxhref{https://guides.github.com/introduction/flow//}{Branches} are a way of isolating your features. For example, if I am working on several features, I would want to keep them separate, and “submit them” (in what is called a \sphinxhref{https://help.github.com/articles/about-pull-requests/}{pull request} ) to be added to the main repository codebase. Each repository, including your fork, has a main branch, which is usually called “master”. As mentioned earlier, the master branch of a fork should always be in sync with the repository it is forked from (which I usually refer to as “upstream”) and then branches of the fork consistently updated with that master. Given that we’ve just cloned the repo, we probably want to work off of the current development branch, which has the most up to date “next version” of the software. So we can start by checking out that branch:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git checkout \PYGZhy{}b development

git pull origin development
\end{sphinxVerbatim}

At this point, you can either choose to work on this branch, push to your origin development and pull request to singularityware development, or you can checkout another branch specific to your feature. We recommend always working from, and staying in sync with development. The command below would checkout a branch called \sphinxcode{\sphinxupquote{add/my-awesome-new-feature}} from development.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} Checkout a new branch called add/my\PYGZhy{}awesome\PYGZhy{}feature

git checkout \PYGZhy{}b add/my\PYGZhy{}awesome\PYGZhy{}feature development
\end{sphinxVerbatim}

The addition of the \sphinxcode{\sphinxupquote{-b}} argument tells git that we want to make a new branch. If I want to just change branches (for example back to master) I can do the same command without \sphinxcode{\sphinxupquote{-b}}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} Change back to master

git checkout master
\end{sphinxVerbatim}

Note that you should commit changes to the branch you are working on before changing branches, otherwise they would be lost. GitHub will give you a warning and prevent you from changing branches if this is the case, so don’t worry too much about it.


\subsection{Step 4. Make your changes}
\label{\detokenize{contributing:step-4-make-your-changes}}
On your new branch, go nuts! Make changes, test them, and when you are happy with a bit of progress, commit the changes to the branch:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git commit \PYGZhy{}a
\end{sphinxVerbatim}

This will open up a little window in your default text editor that you can write a message in the first line. This commit message is important - it should describe exactly the changes that you have made. Bad commit messages are like:
\begin{itemize}
\item {} 
changed code

\item {} 
updated files

\end{itemize}

Good commit messages are like:
\begin{itemize}
\item {} 
changed function “get\_config” in functions.py to output csv to fix \#2

\item {} 
updated docs about shell to close \#10

\end{itemize}

The tags “close \#10” and “fix \#2” are referencing issues that are posted on the main repo you are going to do a pull request to. Given that your fix is merged into the master branch, these messages will automatically close the issues, and further, it will link your commits directly to the issues they intended to fix. This is very important down the line if someone wants to understand your contribution, or (hopefully not) revert the code back to a previous version.


\subsection{Step 5. Push your branch to your fork}
\label{\detokenize{contributing:step-5-push-your-branch-to-your-fork}}
When you are done with your commits, you should push your branch to your fork (and you can also continuously push commits here as you work):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git push origin add/my\PYGZhy{}awesome\PYGZhy{}feature
\end{sphinxVerbatim}

Note that you should always check the status of your branches to see what has been pushed (or not):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git status
\end{sphinxVerbatim}


\subsection{Step 6. Submit a Pull Request}
\label{\detokenize{contributing:step-6-submit-a-pull-request}}
Once you have pushed your branch, then you can go to either fork and (in the GUI) \sphinxhref{https://help.github.com/articles/creating-a-pull-request/}{submit a Pull Request}. Regardless of the name of your branch, your PR should be submit to the singularityware development branch. This will open up a nice conversation interface / forum for the developers of Singularity to discuss your contribution, likely after testing. At this time, any continuous integration that is linked with the code base will also be run. If there is an issue, you can continue to push commits to your branch and it will update the Pull Request.


\subsection{Support, helping and spreading the word!}
\label{\detokenize{contributing:support-helping-and-spreading-the-word}}
This is a huge endeavor, and it is greatly appreciated! If you have been using Singularity and having good luck with it, join our \sphinxhref{https://groups.google.com/a/lbl.gov/forum/\#!forum/singularity}{Google Group} and help out other users! Post to online communities about Singularity, and request that your distribution vendor, service provider, and system administrators include Singularity for you!


\section{Contributing to Documentation}
\label{\detokenize{contributing:contributing-to-documentation}}
We (like almost all open source software providers) have a documentation dilemma… We tend to focus on the code features and functionality before working on documentation. And there is very good reason for this, we want to share the love so nobody feels left out!

You can contribute to the documentation, by sending a \sphinxhref{https://help.github.com/articles/about-pull-requests/}{pull request} on our repository for documentation.

The current documentation is generated with:
\begin{itemize}
\item {} 
\sphinxhref{http://docutils.sourceforge.net/rst.html}{reStructured Text (RST)} and \sphinxhref{https://readthedocs.org/}{ReadTheDocs}

\end{itemize}

Other dependencies include:
\begin{itemize}
\item {} 
\sphinxhref{https://www.python.org/download/releases/2.7/}{Python 2.7}

\item {} 
\sphinxhref{https://pypi.org/project/Sphinx/}{Sphinx}

\end{itemize}

More information about contributing to the documentation and the instructions on how to install the dependencies and how to generate the files can be obtained \sphinxhref{https://github.com/singularityware/singularity-userdocs\#singularity-user-docs}{here}.


\chapter{FAQ}
\label{\detokenize{faq:faq}}\label{\detokenize{faq::doc}}

\section{General Singularity Info}
\label{\detokenize{faq:general-singularity-info}}\label{\detokenize{faq:sec-faq}}

\subsection{Why the name “Singularity”?}
\label{\detokenize{faq:why-the-name-singularity}}
A “Singularity” is an astrophysics phenomenon in which a single point becomes infinitely dense.
This type of a singularity can thus contain massive quantities of universe within it and thus encapsulating an infinite amount of data within it.

Additionally, the name “Singularity” for me (Greg) also stems back from my past experience working at a company called \sphinxhref{https://en.wikipedia.org/wiki/Linuxcare}{Linuxcare}
where the Linux Bootable Business Card (LNX-BBC) was developed. The BBC, was a Linux rescue disk which paved the way for all live CD bootable
distributions using a compressed single image file system called the “singularity”.

The name has  \sphinxstylestrong{NOTHING}  to do with Kurzweil’s (among others) prediction that artificial intelligence will abruptly have the ability to reprogram itself,
surpass that of human intelligence and take control of the planet. If you are interested in this may I suggest the movie Terminator 2: Judgment Day.


\subsection{What is so special about Singularity?}
\label{\detokenize{faq:what-is-so-special-about-singularity}}
While Singularity is a container solution (like many others), Singularity differs in it’s primary design goals and architecture:
\begin{enumerate}
\item {} 
\sphinxstylestrong{Reproducible software stacks:} These must be easily verifiable via checksum or cryptographic signature in such a manner that does not change formats (e.g. splatting a tarball out to disk). By default Singularity uses a container image file which can be checksummed, signed, and thus easily verified and/or validated.

\item {} 
\sphinxstylestrong{Mobility of compute:} Singularity must be able to transfer (and store) containers in a manner that works with standard data mobility tools (rsync, scp, gridftp, http, NFS, etc..) and maintain software and data controls compliancy (e.g. HIPPA, nuclear, export, classified, etc..)

\item {} 
\sphinxstylestrong{Compatibility with complicated architectures:} The runtime must be immediately compatible with existing HPC, scientific, compute farm and even enterprise architectures any of which maybe running legacy kernel versions (including RHEL6 vintage systems) which do not support advanced namespace features (e.g. the user namespace)

\item {} 
\sphinxstylestrong{Security model:} Unlike many other container systems designed to support trusted users running trusted containers we must support the opposite model of untrusted users running untrusted containers. This changes the security paradigm considerably and increases the breadth of use cases we can support.

\end{enumerate}


\subsection{Which namespaces are virtualized? Is that select-able?}
\label{\detokenize{faq:which-namespaces-are-virtualized-is-that-select-able}}
That is up to you!

While some namespaces, like newns (mount) and fs (file system) must be virtualized, all of the others are conditional depending on what you want to do.
For example, if you have a workflow that relies on communication between containers (e.g. MPI), it is best to not isolate any more than absolutely
necessary to avoid performance regressions. While other tasks are better suited for isolation (e.g. web and data base services).

Namespaces are selected via command line usage and system administration configuration.


\subsection{What Linux distributions are you trying to get on-board?}
\label{\detokenize{faq:what-linux-distributions-are-you-trying-to-get-on-board}}
All of them! Help us out by letting them know you want Singularity to be included!


\subsection{How do I request an installation on my resource?}
\label{\detokenize{faq:how-do-i-request-an-installation-on-my-resource}}
It’s important that your administrator have all of the resources available to him or her to make a decision to install Singularity.
We’ve prepared a {\hyperref[\detokenize{installation:installation-request}]{\sphinxcrossref{\DUrole{std,std-ref}{helpful guide}}}} that you can send to him or her to start a conversation. If there are any unanswered questions, we recommend
that you \sphinxhref{https://www.sylabs.io/contact/}{reach out}.


\section{Basic Singularity usage}
\label{\detokenize{faq:basic-singularity-usage}}

\subsection{Do you need administrator privileges to use Singularity?}
\label{\detokenize{faq:do-you-need-administrator-privileges-to-use-singularity}}
You generally do not need admin/sudo to use Singularity containers but you do however need admin/root access to install Singularity and for some
container build functions (for example, building from a recipe, or a writable image).

This then defines the work-flow to some extent. If you have a container (whether Singularity or Docker) ready to go, you can run/shell/import
without root access. If you want to build a new Singularity container image from scratch it must be built and configured on a host where you have root
access (this can be a physical system or on a VM). And of course once the container image has been configured it can be used on a system where you do not have root access as long as Singularity has been installed there.


\subsection{What if I don’t want to install Singularity on my computer?}
\label{\detokenize{faq:what-if-i-don-t-want-to-install-singularity-on-my-computer}}
If you don’t want to build your own images, \sphinxhref{https://singularity-hub.org/}{Singularity Hub} will connect to your GitHub repos with build specification files, and build the containers automatically for you.
You can then interact with them easily where Singularity is installed (e.g., on your cluster):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity shell shub://vsoch/hello\PYGZhy{}world

singularity run shub://vsoch/hello\PYGZhy{}world

singularity pull shub://vsoch/hello\PYGZhy{}world

singularity build hello\PYGZhy{}world.simg shub://vsoch/hello\PYGZhy{}world \PYGZsh{} redundant, you would already get an image
\end{sphinxVerbatim}


\subsection{Can you edit/modify a Singularity container once it has been instantiated?}
\label{\detokenize{faq:can-you-edit-modify-a-singularity-container-once-it-has-been-instantiated}}\begin{description}
\item[{We strongly advocate for reproducibility, so if you build a squashfs container, it is immutable. However, if you build with}] \leavevmode
\sphinxcode{\sphinxupquote{-{-}sandbox}} or \sphinxcode{\sphinxupquote{-{-}writable}} you can produce a writable sandbox folder or a writable ext3 image, respectively.
From a sandbox you can develop, test, and make changes, and then build or convert it into a standard image.

\end{description}

We recommend to use the default compressed, immutable format for production containers.


\subsection{Can multiple applications be packaged into one Singularity Container?}
\label{\detokenize{faq:can-multiple-applications-be-packaged-into-one-singularity-container}}
Yes! You can even create entire pipe lines and work flows using many applications, binaries, scripts, etc..
The \sphinxcode{\sphinxupquote{\%runscript}} bootstrap section is where you can define what happens when a Singularity container is run,
and with the introduction of {\hyperref[\detokenize{reproducible_scif_apps:reproducible-scif-apps}]{\sphinxcrossref{\DUrole{std,std-ref}{modular apps}}}}  you can now even define \sphinxcode{\sphinxupquote{\%apprun}} sections for different entrypoints to your container.


\subsection{How are external file systems and paths handled in a Singularity Container?}
\label{\detokenize{faq:how-are-external-file-systems-and-paths-handled-in-a-singularity-container}}
Because Singularity is based on container principals, when an application is run from within a Singularity container its default
view of the file system is different from how it is on the host system. This is what allows the environment to be portable.
This means that root (‘/’) inside the container is different from the host!

Singularity automatically tries to resolve directory mounts such that things will just work and be portable with whatever environment
you are running on. This means that \sphinxcode{\sphinxupquote{/tmp}} and \sphinxcode{\sphinxupquote{/var/tmp}} are automatically shared into the container as is \sphinxcode{\sphinxupquote{/home}}.
Additionally, if you are in a current directory that is not a system directory, Singularity will also try to bind that to your container.

There is a caveat in that a directory must already exist within your container to serve as a mount point. If that directory does not exist,
Singularity will not create it for you! You must do that. To create custom mounts at runtime, you should use the \sphinxcode{\sphinxupquote{-B}} or \sphinxcode{\sphinxupquote{-{-}bind}} argument:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
singularity run \PYGZhy{}\PYGZhy{}bind /home/vanessa/Desktop:/data container.img
\end{sphinxVerbatim}


\subsection{How does Singularity handle networking?}
\label{\detokenize{faq:how-does-singularity-handle-networking}}
As of 2.4, Singularity can support the network namespace to a limited degree. At present, we just use it for isolation,
but it will soon be more featurefull.


\subsection{Can Singularity support daemon processes?}
\label{\detokenize{faq:can-singularity-support-daemon-processes}}
Singularity has container “instance” support which allows one to start a container process, within its own namespaces, and use that instance
like it was a stand alone, isolated system.

At the moment (as above describes), the network (and UTS) namespace is not well supported, so if you spin up a process daemon, it will exist on
your host’s network. This means you can run a web server, or any other daemon, from within a container and access it directly from your host.


\subsection{Can a Singularity container be multi-threaded?}
\label{\detokenize{faq:can-a-singularity-container-be-multi-threaded}}
Yes. Singularity imposes no limitations on forks, threads or processes in general.


\subsection{Can a Singularity container be suspended or check-pointed?}
\label{\detokenize{faq:can-a-singularity-container-be-suspended-or-check-pointed}}
Yes and maybe respectively. Any Singularity application can be suspended using standard Linux/Unix signals. Check-pointing requires some preloaded
libraries to be automatically loaded with the application but because Singularity escapes the hosts library stack, the checkpoint libraries would not
be loaded. If however you wanted to make a Singularity container that can be check-pointed, you would need to install the checkpoint libraries into the Singularity container via the specfile.

On our roadmap is the ability to checkpoint the entire container process thread, and restart it. Keep an eye out for that feature!


\subsection{Are there any special requirements to use Singularity through an HPC job scheduler?}
\label{\detokenize{faq:are-there-any-special-requirements-to-use-singularity-through-an-hpc-job-scheduler}}
Singularity containers can be run via any job scheduler without any modifications to the scheduler configuration or architecture.
This is because Singularity containers are designed to be run like any application on the system, so within your job script just call Singularity as you would any other application!


\subsection{Does Singularity work in multi-tenant HPC cluster environments?}
\label{\detokenize{faq:does-singularity-work-in-multi-tenant-hpc-cluster-environments}}
Yes! HPC was one of the primary use cases in mind when Singularity was created.

Most people that are currently integrating containers on HPC resources do it by creating virtual clusters within the physical host cluster.
This precludes the virtual cluster from having access to the host cluster’s high performance fabric, file systems and other investments which make an HPC system high performance.

Singularity on the other hand allows one to keep the high performance in High Performance Computing by containerizing applications and supporting
a runtime which seamlessly interfaces with the host system and existing environments.


\subsection{Can I run X11 apps through Singularity?}
\label{\detokenize{faq:can-i-run-x11-apps-through-singularity}}
Yes. This works exactly as you would expect it to.


\subsection{Can I containerize my MPI application with Singularity and run it properly on an HPC system?}
\label{\detokenize{faq:can-i-containerize-my-mpi-application-with-singularity-and-run-it-properly-on-an-hpc-system}}
Yes! HPC was one of the primary use cases in mind when Singularity was created.

While we know for a fact that Singularity can support multiple MPI implementations, we have spent a considerable effort working with Open MPI
as well as adding a Singularity module into Open MPI (v2) such that running at extreme scale will be as efficient as possible.

note: We have seen no major performance impact from running a job in a Singularity container.


\subsection{Why do we call ‘mpirun’ from outside the container (rather than inside)?}
\label{\detokenize{faq:why-do-we-call-mpirun-from-outside-the-container-rather-than-inside}}
With Singularity, the MPI usage model is to call ‘mpirun’ from outside the container, and reference the container from your ‘mpirun’ command. Usage would look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mpirun \PYGZhy{}np 20 singularity exec container.img /path/to/contained\PYGZus{}mpi\PYGZus{}prog
\end{sphinxVerbatim}

By calling ‘mpirun’ outside the container, we solve several very complicated work-flow aspects. For example, if ‘mpirun’ is called from within the container it must have a method for spawning processes on remote nodes. Historically ssh is used for this which means that there must be an sshd running within the container on the remote nodes, and this sshd process must not conflict with the sshd running on that host! It is also possible for the resource manager to launch the job and (in Open MPI’s case) the Orted processes on the remote system, but that then requires resource manager modification and container awareness.

In the end, we do not gain anything by calling ‘mpirun’ from within the container except for increasing the complexity levels and possibly losing out on some added performance benefits (e.g. if a container wasn’t built with the proper OFED as the host).

See the Singularity on HPC page for more details.


\subsection{Does Singularity support containers that require GPUs?}
\label{\detokenize{faq:does-singularity-support-containers-that-require-gpus}}
Yes. Many users run GPU-dependent code within Singularity containers. The experimental \sphinxcode{\sphinxupquote{-{-}nv}} option allows you to leverage host GPUs without installing system level drivers into your container. See the {\hyperref[\detokenize{appendix:exec-command}]{\sphinxcrossref{\DUrole{std,std-ref}{exec}}}} command for an example.


\section{Container portability}
\label{\detokenize{faq:container-portability}}

\subsection{Are Singularity containers kernel-dependent?}
\label{\detokenize{faq:are-singularity-containers-kernel-dependent}}
No, never. But sometimes yes.

Singularity is using standard container principals and methods so if you are leveraging any kernel version specific or external patches/module functionality (e.g. OFED), then yes there maybe kernel dependencies you will need to consider.

Luckily most people that would hit this are people that are using Singularity to inter-operate with an HPC (High Performance Computing) system where there are highly tuned interconnects and file systems you wish to make efficient use of. In this case, See the documentation of MPI with Singularity.

There is also some level of glibc forward compatibility that must be taken into consideration for any container system. For example, I can take a Centos-5 container and run it on Centos-7, but I can not take a Centos-7 container and run it on Centos-5.

note: If you require kernel-dependent features, a container platform is probably not the right solution for you.


\subsection{Can a Singularity container resolve GLIBC version mismatches?}
\label{\detokenize{faq:can-a-singularity-container-resolve-glibc-version-mismatches}}
Yes. Singularity containers contain their own library stack (including the Glibc version that they require to run).


\subsection{What is the performance trade off when running an application native or through Singularity?}
\label{\detokenize{faq:what-is-the-performance-trade-off-when-running-an-application-native-or-through-singularity}}
So far we have not identified any appreciable regressions of performance (even in parallel applications running across nodes with InfiniBand).
There is a small start-up cost to create and tear-down the container, which has been measured to be anywhere from 10 - 20 thousandths of a second.


\section{Misc}
\label{\detokenize{faq:misc}}
The following are miscellaneous questions.


\subsection{Are there any special security concerns that Singularity introduces?}
\label{\detokenize{faq:are-there-any-special-security-concerns-that-singularity-introduces}}
No and yes.

While Singularity containers always run as the user launching them, there are some aspects of the container execution which requires escalation of privileges. This escalation is achieved via a SUID portion of code. Once the container environment has been instantiated, all escalated privileges are dropped completely, before running any programs within the container.

Additionally, there are precautions within the container context to mitigate any escalation of privileges. This limits a user’s ability to gain root control once inside the container.

You can read more about the Singularity {\hyperref[\detokenize{introduction:security-and-priviledge-escalation}]{\sphinxcrossref{\DUrole{std,std-ref}{security overview here}}}}.



\renewcommand{\indexname}{Index}
\printindex
\end{document}